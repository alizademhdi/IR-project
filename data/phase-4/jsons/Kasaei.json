[
    {
        "URL": "https://www.semanticscholar.org/paper/The-Eighth-Visual-Object-Tracking-VOT2020-Challenge-Kristan-Leonardis/12508951ba96b7d4c0906ed95542287d3ebdfd95",
        "ID": "12508951ba96b7d4c0906ed95542287d3ebdfd95",
        "Title": "The Eighth Visual Object Tracking VOT2020 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2020 is the eighth annual tracker benchmarking activity organized by the VOT initiative. Results of 58 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The VOT2020 challenge was composed of five sub-challenges focusing on different tracking domains: (i) VOT-ST2020 challenge focused on short-term tracking in RGB, (ii) VOT-RT2020 challenge focused on \u201creal-time\u2026\u00a0",
        "Publication Year": "23 August 2020",
        "Citation Count": "144",
        "Reference Count": "88",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Joni-Kristian K{\\&quot;a}m{\\&quot;a}r{\\&quot;a}inen",
            "Martin Danelljan",
            "Luka Cehovin Zajc",
            "Alan Luke{\\vz}i{\\vc}",
            "Ondrej Drbohlav",
            "Linbo He",
            "Yushan Zhang",
            "Song Yan",
            "Jinyu Yang",
            "Gustavo Javier Fernandez",
            "Alexander G. Hauptmann",
            "Alireza Memarmoghadam",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andreas Robinson",
            "Anton Yuriiovych Varfolomieiev",
            "Awet Haileslassie Gebrehiwot",
            "Bedirhan Uzun",
            "Bin Yan",
            "Bing Li",
            "Chen Qian",
            "Chi-Yi Tsai",
            "Christian Micheloni",
            "Dong Wang",
            "Fei Wang",
            "Fei Xie",
            "Felix J{\\&quot;a}remo Lawin",
            "Fredrik K. Gustafsson",
            "Gian Luca Foresti",
            "Goutam Bhat",
            "Guang-Gui Chen",
            "Haibin Ling",
            "Haitao Zhang",
            "Hakan Cevikalp",
            "Haojie Zhao",
            "Haoran Bai",
            "Hari Chandana Kuchibhotla",
            "Hasan Saribas",
            "Heng Fan",
            "Hossein Ghanei-Yakhdan",
            "Houqiang Li",
            "Houwen Peng",
            "Huchuan Lu",
            "Hui Li",
            "Javad Khaghani",
            "Jes{\\&#x27;u}s Besc{\\&#x27;o}s",
            "Jianhua Li",
            "Jianlong Fu",
            "Jiaqian Yu",
            "Jingtao Xu",
            "Josef Kittler",
            "Jun Yin",
            "Junhyun Lee",
            "Kaicheng Yu",
            "Kaiwen Liu",
            "Kang Yang",
            "Kenan Dai",
            "Li Cheng",
            "Li Zhang",
            "Lijun Wang",
            "Linyuan Wang",
            "Luc Van Gool",
            "Luca Bertinetto",
            "Matteo Dunnhofer",
            "Miao Cheng",
            "Mohana Murali Dasari",
            "Ning Wang",
            "Pengyu Zhang",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Radu Timofte",
            "Rama Krishna Sai Subrahmanyam Gorthi",
            "Seokeon Choi",
            "Seyed Mojtaba Marvasti-Zadeh",
            "Shao-Chuan Zhao",
            "Shohreh Kasaei",
            "Shoumeng Qiu",
            "Shuhao Chen",
            "Thomas Bo Sch{\\&quot;o}n",
            "Tianyang Xu",
            "Wei Lu",
            "Weiming Hu",
            "Wen-gang Zhou",
            "Xi Qiu",
            "Xiao Ke",
            "Xiaojun Wu",
            "Xiaolin Zhang",
            "Xiaoyun Yang",
            "Xuefeng Zhu",
            "Yingjie Jiang",
            "Yingming Wang",
            "Yiwei Chen",
            "Yu Ye",
            "Yuezhou Li",
            "Yuncon Yao",
            "Yunsung Lee",
            "Yuzhang Gu",
            "Zezhou Wang",
            "Zhangyong Tang",
            "Zhenhua Feng",
            "Zhijun Mai",
            "Zhipeng Zhang",
            "Zhirong Wu",
            "Ziang Ma"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "786577081e00d69eeac8e9612eaf2dad59765e73",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Deep-Learning-for-Visual-Tracking%3A-A-Comprehensive-Marvasti-Zadeh-Cheng/1fbb4201af091aef55360f113ba35814063923e4",
        "ID": "1fbb4201af091aef55360f113ba35814063923e4",
        "Title": "Deep Learning for Visual Tracking: A Comprehensive Survey",
        "Abstract": "Visual target tracking is one of the most sought-after yet challenging research topics in computer vision. Given the ill-posed nature of the problem and its popularity in a broad range of real-world scenarios, a number of large-scale benchmark datasets have been established, on which considerable methods have been developed and demonstrated with significant progress in recent years \u2013 predominantly by recent deep learning (DL)-based methods. This survey aims to systematically investigate the\u2026\u00a0",
        "Publication Year": "2 December 2019",
        "Citation Count": "156",
        "Reference Count": "281",
        "Authors": [
            "Seyed Mojtaba Marvasti-Zadeh",
            "Li Cheng",
            "Hossein Ghanei-Yakhdan",
            "Shohreh Kasaei"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "26e2ca763087be09e3799ad294302aa91077942d",
            "021d0c7013da519b508610064f264c76d768fdf1",
            "0a400fd7f0ee28694889baaa4faef150b6912dfa",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "388d29f001411ff80650f80cf197afc440d98b51",
            "f24015a365ea2454391c285cd30b8ae723dbb05e",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "1855818c492d5f42dbe14814e4dd9b5733d54790",
            "e2e34b202363e4a46a14cd35fd4088d88b2e650e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Ninth-Visual-Object-Tracking-VOT2021-Challenge-Kristan-Matas/f1d53e9c301d78e0b148e2f91adfc4fde2621ee5",
        "ID": "f1d53e9c301d78e0b148e2f91adfc4fde2621ee5",
        "Title": "The Ninth Visual Object Tracking VOT2021 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2021 is the ninth annual tracker benchmarking activity organized by the VOT initiative. Results of 71 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in recent years. The VOT2021 challenge was composed of four sub-challenges focusing on different tracking domains: (i) VOT-ST2021 challenge focused on short-term tracking in RGB, (ii) VOT-RT2021 challenge focused on \"real-time\" short\u2026\u00a0",
        "Publication Year": "1 October 2021",
        "Citation Count": "47",
        "Reference Count": "70",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "J. K{\\&quot;a}m{\\&quot;a}r{\\&quot;a}inen",
            "Hyung Jin Chang",
            "Martin Danelljan",
            "Luka Cehovin Zajc",
            "Alan Luke{\\vz}i{\\vc}",
            "Ondrej Drbohlav",
            "Jani K{\\&quot;a}pyl{\\&quot;a}",
            "Gustav H{\\&quot;a}ger",
            "Song Yan",
            "Jinyu Yang",
            "Zhongqun Zhang",
            "Gustavo Javier Fernandez",
            "Mohamed H. Abdelpakey",
            "Goutam Bhat",
            "Llukman Cerkezi",
            "Hakan \u00c7evikalp",
            "Shengyong Chen",
            "Xin Chen",
            "Miao Cheng",
            "Ziyi Cheng",
            "Yu-Chen Chiu",
            "Ozgun Cirakman",
            "Yutao Cui",
            "Kenan Dai",
            "Mohana Murali Dasari",
            "Qili Deng",
            "Xingping Dong",
            "Daniel K. Du",
            "Matteo Dunnhofer",
            "Zhenhua Feng",
            "Zhiyong Feng",
            "Z. Fu",
            "Shiming Ge",
            "Rama Krishna Sai Subrahmanyam Gorthi",
            "Yuzhang Gu",
            "Bilge Gunsel",
            "Qing Guo",
            "Filiz Gurkan",
            "Wencheng Han",
            "Yanyan Huang",
            "Felix J{\\&quot;a}remo Lawin",
            "Shang-Jhih Jhang",
            "Rongrong Ji",
            "Cheng Jiang",
            "Yingjie Jiang",
            "Felix Juefei-Xu",
            "Yin Jun",
            "Xiaolong Ke",
            "Fahad Shahbaz Khan",
            "Byeong Hak Kim",
            "Josef Kittler",
            "Xiangyuan Lan",
            "Jun Ha Lee",
            "Bastian Leibe",
            "Hui Li",
            "Jianhua Li",
            "Xianxian Li",
            "Yuezhou Li",
            "Bo Liu",
            "Chang Liu",
            "Jingen Liu",
            "Li Liu",
            "Qingjie Liu",
            "Huchuan Lu",
            "Wei Lu",
            "Jonathon Luiten",
            "Jie Ma",
            "Ziang Ma",
            "Niki Martinel",
            "Christoph Mayer",
            "Alireza Memarmoghadam",
            "Christian Micheloni",
            "Yuzhen Niu",
            "Danda Pani Paudel",
            "Houwen Peng",
            "Shoumeng Qiu",
            "Aravindh Rajiv",
            "Muhammad Abid Rana",
            "Andreas Robinson",
            "Hasan Saribas",
            "Ling Shao",
            "Mohamed S. Shehata",
            "Furao Shen",
            "Jianbing Shen",
            "Kristian Simonato",
            "Xiaoning Song",
            "Zhangyong Tang",
            "Radu Timofte",
            "Philip H. S. Torr",
            "Chi-Yi Tsai",
            "Bedirhan Uzun",
            "Luc Van Gool",
            "Paul Voigtlaender",
            "Dong Wang",
            "Guangting Wang",
            "Liangliang Wang",
            "Lijun Wang",
            "Limin Wang",
            "Linyuan Wang",
            "Yong Wang",
            "Yunhong Wang",
            "Chenyang Wu",
            "Gangshan Wu",
            "Xiaojun Wu",
            "Fei Xie",
            "Tianyang Xu",
            "Xiang Xu",
            "Wanli Xue",
            "Bin Yan",
            "Wankou Yang",
            "Xiaoyun Yang",
            "Yu Ye",
            "J. Yin",
            "Chengwei Zhang",
            "Chunhui Zhang",
            "Haitao Zhang",
            "Kaihua Zhang",
            "Kangkai Zhang",
            "Xiaohan Zhang",
            "Xiaolin Zhang",
            "Xinyu Zhang",
            "Zhibing Zhang",
            "Shao-Chuan Zhao",
            "Mingmin Zhen",
            "Bineng Zhong",
            "Jiawen Zhu",
            "Xuefeng Zhu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "12508951ba96b7d4c0906ed95542287d3ebdfd95",
            "786577081e00d69eeac8e9612eaf2dad59765e73",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "f202feae9ca7b3766e072b6af657beed2236a93c",
            "0f50914e86b6010586f1772308858de9a418fb9f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-term-Visual-Tracking%3A-Review-and-Experimental-Liu-Chen/2d4713ce1df60f771b65e900fd02352989df82ef",
        "ID": "2d4713ce1df60f771b65e900fd02352989df82ef",
        "Title": "Long-term Visual Tracking: Review and Experimental Comparison",
        "Abstract": "As a fundamental task in computer vision, visual object tracking has received much attention in recent years. Most studies focus on short-term visual tracking which addresses shorter videos and always-visible targets. However, long-term visual tracking is much closer to practical applications with more complicated challenges. There exists a longer duration such as minute-level or even hour-level in the long-term tracking task, and the task also needs to handle more frequent target disappearance\u2026\u00a0",
        "Publication Year": "7 November 2022",
        "Citation Count": "3",
        "Reference Count": "100",
        "Authors": [
            "Chang Liu",
            "Xiao-Fan Chen",
            "Chunjuan Bo",
            "Dong Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "23f8927f996d56f3b5076d8993a70bcfc70182a1",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "12508951ba96b7d4c0906ed95542287d3ebdfd95",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "1ae15ff20d54d9ffd2a45a9c124c77ad2b419ae3",
            "786577081e00d69eeac8e9612eaf2dad59765e73",
            "894e4376750b83b63649cc518b121f345ca0df83",
            "913cebc279c363fb9476496f096519e27212b3d5"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Switch-and-Refine%3A-A-Long-Term-Tracking-and-Xu-Zhao/ef61778d85357bdab8c71cf79cf5e0024f5b39c5",
        "ID": "ef61778d85357bdab8c71cf79cf5e0024f5b39c5",
        "Title": "Switch and Refine: A Long-Term Tracking and Segmentation Framework",
        "Abstract": "In long-term video object tracking (VOT) tasks, most long-term trackers are modified from short-term trackers, which contain more and more machine learning modules to improve their performance. However, we empirically find that more modules do not necessarily lead to better results. In this paper, we make the long-term tracking framework simple by carefully selecting the cutting-edge trackers. Specifically, we propose a new long-term VOT framework that combines the benefits of two mainstream\u2026\u00a0",
        "Publication Year": "1 March 2023",
        "Citation Count": "One",
        "Reference Count": "76",
        "Authors": [
            "Xiang Xu",
            "Jian Zhao",
            "Jianmin Wu",
            "Furao Shen"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "f1c9f81ce054619f30b5c27fd97579f7216d7048",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "f6186788541d332af19a96183787e01ef9080fb0",
            "3985382474245388bbc73e2c849e783010901775"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Multi-modal-Visual-Tracking%3A-Review-and-Comparison-Zhang-Wang/d884af3933148cef3b50fd38c810f5a7763d0fc9",
        "ID": "d884af3933148cef3b50fd38c810f5a7763d0fc9",
        "Title": "Multi-modal Visual Tracking: Review and Experimental Comparison",
        "Abstract": "Visual object tracking, as a fundamental task in computer vision, has drawn much attention in recent years. To extend trackers to a wider range of applications, researchers have introduced information from multiple modalities to handle specific scenes, which is a promising research prospect with emerging methods and benchmarks. To provide a thorough review of multi-modal track-ing, we summarize the multi-modal tracking algorithms, especially visible-depth (RGB-D) tracking and visible-thermal\u2026\u00a0",
        "Publication Year": "8 December 2020",
        "Citation Count": "5",
        "Reference Count": "126",
        "Authors": [
            "Pengyu Zhang",
            "Dong Wang",
            "Huchuan Lu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "1975bee228ac228df235d20777e32331bb21566d",
            "f202feae9ca7b3766e072b6af657beed2236a93c",
            "d8d847b085e9af12eeafc0af8df95ff2a1a98fb5",
            "bc40c09be4d74a0665f507447982d226fcd8f18d",
            "487eb86379e979a72ebfef67db6eb8f048d1d258",
            "5f2ff21932fec3882c4c85c474a1be4645bfd92b",
            "d10861d377be150b1e03cb942deb8763095de88f",
            "761a9b5d8750eb63a9717650c4aaca53ce36a364",
            "d49ba5146ab759be3b257228d7095649b3d48b57",
            "3fbf32a428db505e0bb45177016e8851d9b31e97"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/CoCoLoT%3A-Combining-Complementary-Trackers-in-Visual-Dunnhofer-Micheloni/23409262ddcfc2f66fe999711a1fd9f7c700a1e2",
        "ID": "23409262ddcfc2f66fe999711a1fd9f7c700a1e2",
        "Title": "CoCoLoT: Combining Complementary Trackers in Long-Term Visual Tracking",
        "Abstract": "How to combine the complementary capabilities of an ensemble of different algorithms has been of central interest in visual object tracking. A significant progress on such a problem has been achieved, but considering short-term tracking scenarios. Instead, long-term tracking settings have been substantially ignored by the solutions. In this paper, we explicitly consider long-term tracking scenarios and provide a framework, named CoCoLoT, that combines the characteristics of complementary visual\u2026\u00a0",
        "Publication Year": "9 May 2022",
        "Citation Count": "2",
        "Reference Count": "47",
        "Authors": [
            "Matteo Dunnhofer",
            "Christian Micheloni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508",
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "bd4f219ce6bc5c22f9da71959d5192cf0b0141fe",
            "ca97f741f331b5b43d0577a46c05984f0785a8fa",
            "c734274f43575bc5f4bcf8719f0be55a5e89be5e",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "5b73cd259a3fa72f95e8bac9e520250b950acf3a",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "eb00b8453b23d4f6f142378e2fb0f0a9e6f9c5e2",
            "19d6b9725a59f4b624205829d5f03ac893ca1367"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Is-First-Person-Vision-Challenging-for-Object-Dunnhofer-Furnari/ca97f741f331b5b43d0577a46c05984f0785a8fa",
        "ID": "ca97f741f331b5b43d0577a46c05984f0785a8fa",
        "Title": "Is First Person Vision Challenging for Object Tracking?",
        "Abstract": "Understanding human-object interactions is fundamental in First Person Vision (FPV). Tracking algorithms which follow the objects manipulated by the camera wearer can provide useful cues to effectively model such interactions. Visual tracking solutions available in the computer vision literature have significantly improved their performance in the last years for a large variety of target objects and tracking scenarios. However, despite a few previous attempts to exploit trackers in FPV\u2026\u00a0",
        "Publication Year": "24 November 2020",
        "Citation Count": "12",
        "Reference Count": "106",
        "Authors": [
            "Matteo Dunnhofer",
            "Antonino Furnari",
            "Giovanni Maria Farinella",
            "Christian Micheloni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "50c60583dc0ef09484358deab329f82ee22c2b66",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "44990f618f46f02da321b1043a64e72d5f7c0486",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "d1e61fa7824709cae37fb59483dd0772e3101c08",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "9559f0b77932a3c5f17aeb8564b400430d173ec7"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Object-Tracking-With-Discriminative-Filters-Javed-Danelljan/0530cbeb847f5e5002d1183c482759dff5f8c439",
        "ID": "0530cbeb847f5e5002d1183c482759dff5f8c439",
        "Title": "Visual Object Tracking With Discriminative Filters and Siamese Networks: A Survey and Outlook",
        "Abstract": "Accurate and robust visual object tracking is one of the most challenging and fundamental computer vision problems. It entails estimating the trajectory of the target in an image sequence, given only its initial location, and segmentation, or its rough approximation in the form of a bounding box. Discriminative Correlation Filters (DCFs) and deep Siamese Networks (SNs) have emerged as dominating tracking paradigms, which have led to significant progress. Following the rapid evolution of visual\u2026\u00a0",
        "Publication Year": "6 December 2021",
        "Citation Count": "27",
        "Reference Count": "181",
        "Authors": [
            "Sajid Javed",
            "Martin Danelljan",
            "Fahad Shahbaz Khan",
            "Muhammad Haris Khan",
            "Michael Felsberg",
            "Jiri Matas"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "cce1fecc800d2782da638f3060d5b2e887739f74",
            "19476caeb9305540faf84adba9a0bb12bd2c29a8",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "738165f33c50b059e87b14d8b4a129230e14eacd",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "be412c7c7128cf91455233b652d6c94a6001a7c8",
            "2bcf2bd59219d89f335cbc8d1dd4f431076b4c4c",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Object-Tracking-in-First-Person-Vision-Dunnhofer-Furnari/c89da5aa9697ab9d5366353ec29b3e9c1b610469",
        "ID": "c89da5aa9697ab9d5366353ec29b3e9c1b610469",
        "Title": "Visual Object Tracking in First Person Vision",
        "Abstract": "The understanding of human-object interactions is fundamental in First Person Vision (FPV). Visual tracking algorithms which follow the objects manipulated by the camera wearer can provide useful information to effectively model such interactions. In the last years, the computer vision community has significantly improved the performance of tracking algorithms for a large variety of target objects and scenarios. Despite a few previous attempts to exploit trackers in the FPV domain, a methodical\u2026\u00a0",
        "Publication Year": "27 September 2022",
        "Citation Count": "7",
        "Reference Count": "122",
        "Authors": [
            "Matteo Dunnhofer",
            "Antonino Furnari",
            "Giovanni Maria Farinella",
            "Christian Micheloni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ce1da08be62183845cac70b7236ee9de5f2dde43",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "9559f0b77932a3c5f17aeb8564b400430d173ec7",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "b90010d61509bcacff64003b7e31e817487ea018",
            "50c60583dc0ef09484358deab329f82ee22c2b66",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Global-Tracking-via-Ensemble-of-Local-Trackers-Zhou-Chen/ef19859f204048cc83bed9d3eeaa74f75e2fbabc",
        "ID": "ef19859f204048cc83bed9d3eeaa74f75e2fbabc",
        "Title": "Global Tracking via Ensemble of Local Trackers",
        "Abstract": "The crux of long-term tracking lies in the difficulty of tracking the target with discontinuous moving caused by out-of-view or occlusion. Existing long-term tracking methods follow two typical strategies. The first strategy employs a local tracker to perform smooth tracking and uses another re-detector to detect the target when the target is lost. While it can exploit the temporal context like historical appearances and locations of the target, a potential limitation of such strategy is that\u2026\u00a0",
        "Publication Year": "30 March 2022",
        "Citation Count": "7",
        "Reference Count": "48",
        "Authors": [
            "Zikun Zhou",
            "Jianqiu Chen",
            "Wenjie Pei",
            "Kaige Mao",
            "Hongpeng Wang",
            "Zhenyu He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "48c6ca17f17038ff9933dca86a23f8516168a3ea",
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "ae066f27f2edc1c51847ce4cb21b6e1a3db44fa2",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "811ffb185bc90ac5d02d6dbfbcdb6173756b52ef",
            "16cf8225d1b86c54a18b917a9475bfbd68b46306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Seventh-Visual-Object-Tracking-VOT2019-Results-Kristan-Matas/786577081e00d69eeac8e9612eaf2dad59765e73",
        "ID": "786577081e00d69eeac8e9612eaf2dad59765e73",
        "Title": "The Seventh Visual Object Tracking VOT2019 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed\u2026\u00a0",
        "Publication Year": "1 October 2019",
        "Citation Count": "323",
        "Reference Count": "111",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Joni-Kristian",
            "K{\\&quot;a}m{\\&quot;a}r{\\&quot;a}inen",
            "Luka Cehovin Zajc",
            "Ondrej Drbohlav",
            "Alan Luke{\\vz}i{\\vc}",
            "Amanda Berg",
            "Abdelrahman",
            "Eldesokey",
            "Jani K{\\&quot;a}pyl{\\&quot;a}",
            "Gustavo Javier Fernandez",
            "Abel Gonzalez-Garcia",
            "Alireza",
            "Memarmoghadam",
            "Andong Lu",
            "Anfeng He",
            "Anton Yuriiovych Varfolomieiev",
            "Antoni B. Chan",
            "Ardhendu Shekhar",
            "Tripathi",
            "Arnold W. M. Smeulders",
            "Bala Suraj Pedasingu",
            "Bao Xin Chen",
            "Baopeng Zhang",
            "Baoyuan Wu",
            "Bi",
            "Li",
            "Bin He",
            "Bin Yan",
            "Bing Bai",
            "Bing Li",
            "Bo Li",
            "Byeong Hak Kim",
            "Chao Ma",
            "Chen Fang",
            "Chen",
            "Qian",
            "Cheng Chen",
            "Chenglong Li",
            "Chengquan Zhang",
            "Chi-Yi Tsai",
            "Chong Luo",
            "Christian",
            "Micheloni",
            "Chunhui Zhang",
            "Dacheng Tao",
            "Deepak Gupta",
            "Dejia Song",
            "Dong Wang",
            "Efstratios",
            "Gavves",
            "Eunu Yi",
            "Fahad Shahbaz Khan",
            "Fangyi Zhang",
            "Fei Wang",
            "Fei Zhao",
            "George De",
            "Ath",
            "Goutam Bhat",
            "Guang-Gui Chen",
            "Guangting Wang",
            "Guoxuan Li",
            "Hakan \u00c7evikalp",
            "Hao Du",
            "Haojie",
            "Zhao",
            "Hasan Saribas",
            "Ho Min Jung",
            "Hongliang Bai",
            "Hongyuan Yu",
            "Houwen Peng",
            "Huchuan",
            "L\u01d4",
            "Hui Li",
            "Jia-Ke Li",
            "Jianhua Li",
            "Jianlong Fu",
            "Jie Chen",
            "Jie Gao",
            "Jie Zhao",
            "Jin Tang",
            "Jing",
            "Jingjing Wu",
            "Jingtuo Liu",
            "Jinqiao Wang",
            "Jinqing Qi",
            "Jinyue Zhang",
            "John Tsotsos",
            "Jong Hyuk Jong Hyuk",
            "Lee",
            "Joost van de Weijer",
            "Josef Kittler",
            "Jun Ha Lee",
            "Junfei Zhuang",
            "Kangkai Zhang",
            "Kangkang",
            "Wang",
            "Kenan Dai",
            "Lei Chen",
            "Lei Liu",
            "Leida Guo",
            "Li Zhang",
            "Liang Wang",
            "Liang Wang",
            "Lichao",
            "Zhang",
            "Lijun Wang",
            "Lijun Zhou",
            "Linyu Zheng",
            "Litu Rout",
            "Luc Van Gool",
            "Luca Bertinetto",
            "Martin",
            "Danelljan",
            "Matteo Dunnhofer",
            "Meng Ni",
            "Min Young Kim",
            "Ming Tang",
            "Ming-Hsuan Yang",
            "Naveen",
            "Paluru",
            "Niki Martinel",
            "Pengfei Xu",
            "Pengfei Zhang",
            "Pengkun Zheng",
            "Pengyu Zhang",
            "S. PhilipH.",
            "Torr",
            "Qi Zhang Qiang Wang",
            "Qing Guo",
            "Radu Timofte",
            "Rama Krishna Sai Subrahmanyam Gorthi",
            "Richard",
            "Everson",
            "Ruize Han",
            "Ruohan Zhang",
            "Shan You",
            "Shao-Chuan Zhao",
            "Shengwei Zhao",
            "Shihu",
            "Shikun Li",
            "Shiming Ge",
            "Shuai Bai",
            "Shuosen Guan",
            "Tengfei Xing",
            "Tianyang Xu",
            "Tianyu",
            "Yang",
            "Ting Zhang",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Wei Feng",
            "Wei Hu",
            "Weizhao Wang",
            "Wenjie Tang",
            "Wenjun",
            "Zeng",
            "Wenyu Liu",
            "Xi Chen",
            "Xi Qiu",
            "Xiang Bai",
            "Xiaojun Wu",
            "Xiaoyun Yang",
            "Xier",
            "Xin Li",
            "Xingyuan Sun",
            "Xingyu Chen",
            "Xinmei Tian",
            "Xuwen Tang",
            "Xuefeng Zhu",
            "Yan-ping Huang",
            "Yanan",
            "Yanchao Lian",
            "Yang Gu",
            "Yang Ming Liu",
            "Yanjie Chen",
            "Yi Zhang",
            "Yinda Xu",
            "Yingming",
            "Yingping Li",
            "Yu Zhou",
            "Yuan Dong",
            "Yufei Xu",
            "Yunhua Zhang",
            "Yunkun Li",
            "Zeyu Zhao",
            "Luo",
            "Zhaoliang Zhang",
            "Zhenhua Feng",
            "Zhenyu He",
            "Zhichao Song",
            "Zhihao Chen",
            "Zhipeng",
            "Zhirong Wu",
            "Zhiwei Xiong",
            "Zhongjian Huang",
            "Zhu Teng",
            "Zihan Ni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "6179ac06f1a8fd1ac6b693b02824948dff438d54",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "23f8927f996d56f3b5076d8993a70bcfc70182a1",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "320d05db95ab42ade69294abe46cd1aca6aca602"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Sixth-Visual-Object-Tracking-VOT2018-Challenge-Kristan-Leonardis/219e9a4527110baf1feb3df20db12064eeafdfb7",
        "ID": "219e9a4527110baf1feb3df20db12064eeafdfb7",
        "Title": "The Sixth Visual Object Tracking VOT2018 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2018 is the sixth annual tracker benchmarking activity organized by the VOT initiative. Results of over eighty trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis and a \u201creal-time\u201d experiment simulating a situation where a tracker processes images as if provided\u2026\u00a0",
        "Publication Year": "8 September 2018",
        "Citation Count": "588",
        "Reference Count": "100",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Goutam Bhat",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "{\\&#x27;A}lvaro Iglesias-Arias",
            "Aydin Alatan",
            "Abel Gonzalez-Garcia",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea Vedaldi",
            "Andrej Muhic",
            "Anfeng He",
            "Arnold W. M. Smeulders",
            "Asanka G. Perera",
            "Bo Li",
            "Boyu Chen",
            "Changick Kim",
            "Changsheng Xu",
            "Changzhen Xiong",
            "Cheng Tian",
            "Chong Luo",
            "Chong Sun",
            "Cong Hao",
            "Daijin Kim",
            "Deepak Mishra",
            "Deming Chen",
            "Dong Wang",
            "Dongyoon Wee",
            "Efstratios Gavves",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Fan Yang",
            "Fei Zhao",
            "Feng Li",
            "Francesco Battistone",
            "George De Ath",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Haibin Ling",
            "Hamed Kiani Galoogahi",
            "Hankyeol Lee",
            "Haojie Li",
            "Haojie Zhao",
            "Heng Fan",
            "Honggang Zhang",
            "Horst Possegger",
            "Houqiang Li",
            "Huchuan Lu",
            "Hui Zhi",
            "Huiyun Li",
            "Hyemin Lee",
            "Hyung Jin Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jaime Spencer Martin",
            "Javaan Singh Chahl",
            "Jin Young Choi",
            "Jing Li",
            "Jinqiao Wang",
            "Jinqing Qi",
            "Jinyoung Sung",
            "Joakim Johnander",
            "Jo{\\~a}o F. Henriques",
            "Jongwon Choi",
            "Joost van de Weijer",
            "Jorge Rodr{\\&#x27;i}guez Herranz",
            "Jos{\\&#x27;e} Mar{\\&#x27;i}a Mart{\\&#x27;i}nez Sanchez",
            "Josef Kittler",
            "Junfei Zhuang",
            "Junyu Gao",
            "Klemen Grm",
            "Lichao Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Litu Rout",
            "Liu Si",
            "Luca Bertinetto",
            "Lutao Chu",
            "Manqiang Che",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Ming-Hsuan Yang",
            "Mohamed H. Abdelpakey",
            "Mohamed S. Shehata",
            "Myung Gu Kang",
            "Namhoon Lee",
            "Ning Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "Pablo Vicente-Mo{\\~n}ivar",
            "Pedro Senna",
            "Peixia Li",
            "Philip H. S. Torr",
            "Priya Mariam Raju",
            "Ruihe Qian",
            "Qiang Wang",
            "Qin Zhou",
            "Qing Guo",
            "Rafael Martin Nieto",
            "Rama Krishna Sai Subrahmanyam Gorthi",
            "Ran Tao",
            "R. Bowden",
            "Richard M. Everson",
            "Runling Wang",
            "Sangdoo Yun",
            "Seokeon Choi",
            "Sergio Vivas",
            "Shuai Bai",
            "Shuangping Huang",
            "Sihang Wu",
            "Simon Hadfield",
            "Siwen Wang",
            "Stuart Golodetz",
            "Ming Tang",
            "Tianyang Xu",
            "Tianzhu Zhang",
            "Tobias Fischer",
            "Vincenzo Santopietro",
            "Vitomir {\\vS}truc",
            "Wei Wang",
            "Wangmeng Zuo",
            "Wei Feng",
            "Wei Wu",
            "Wei Zou",
            "Weiming Hu",
            "Wen-gang Zhou",
            "Wen Jun Zeng",
            "Xiaofan Zhang",
            "Xiaohe Wu",
            "Xiaojun Wu",
            "Xinmei Tian",
            "Yan Li",
            "Yan Lu",
            "Yee Wei Law",
            "Yi Wu",
            "Y. Demiris",
            "Yicai Yang",
            "Yifan Jiao",
            "Yuhong Li",
            "Yunhua Zhang",
            "Yuxuan Sun",
            "Zheng Zhang",
            "Zhengyu Zhu",
            "Zhenhua Feng",
            "Zhihui Wang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2017-Challenge-Kristan-Leonardis/350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "ID": "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "Title": "The Visual Object Tracking VOT2017 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \"real-time\" experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the\u2026\u00a0",
        "Publication Year": "1 October 2017",
        "Citation Count": "429",
        "Reference Count": "132",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andrej Muhic",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea Vedaldi",
            "Antoine Manzanera",
            "Antoine Tran",
            "Aydin Alatan",
            "Bogdan Cosmin Mocanu",
            "Boyu Chen",
            "Chang Huang",
            "Changsheng Xu",
            "Chong Sun",
            "Dalong Du",
            "Dafan Zhang",
            "Dawei Du",
            "Deepak Mishra",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Francesco Battistone",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Goutam Bhat",
            "Guan Huang",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Hongliang Zhang",
            "Houqiang Li",
            "Huchuan Lu",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jaeil Cho",
            "Jae-Y. Lee",
            "Jana Noskova",
            "Jianke Zhu",
            "Jin Gao",
            "Jingyu Liu",
            "Ji-Wan Kim",
            "Jo{\\~a}o F. Henriques",
            "Jos{\\&#x27;e} Mar{\\&#x27;i}a Mart{\\&#x27;i}nez Sanchez",
            "Junfei Zhuang",
            "Junliang Xing",
            "Junyu Gao",
            "Kai Chen",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Kris Kitani",
            "Lei Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh Poostchi",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Ming-Hsuan Yang",
            "Nianhao Xie",
            "Ning Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "Pallavi M. Venugopal",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Qifeng Yu",
            "Qingming Huang",
            "Rafael Martin Nieto",
            "R. Bowden",
            "Risheng Liu",
            "Ruxandra Tapu",
            "Simon Hadfield",
            "Siwei Lyu",
            "Stuart Golodetz",
            "Sunglok Choi",
            "Tianzhu Zhang",
            "Titus B. Zaharia",
            "Vincenzo Santopietro",
            "Wei Zou",
            "Weiming Hu",
            "Wenbing Tao",
            "Wenbo Li",
            "Wen-gang Zhou",
            "Xianguo Yu",
            "Xiao Bian",
            "Yang Li",
            "Yifan Xing",
            "Yingruo Fan",
            "Zhengyu Zhu",
            "Zhipeng Zhang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2015-Challenge-Kristan-Matas/047ea298464b041a90c4ab4e716356c019d613ab",
        "ID": "047ea298464b041a90c4ab4e716356c019d613ab",
        "Title": "The Visual Object Tracking VOT2015 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 predecessor are: (i) a new VOT2015 dataset twice\u2026\u00a0",
        "Publication Year": "7 December 2015",
        "Citation Count": "398",
        "Reference Count": "84",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Luka Cehovin",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Georg Nebehay",
            "Roman P. Pflugfelder",
            "Zhe Chen"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "17f16b89edaed5d16867287ed8a85e917304b4ba",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "7b75da6f5edac80575d9dcf63db164ce24933907"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2016-Challenge-Kristan-Leonardis/966aad492f75b17f698e981e008b73b51816c6aa",
        "ID": "966aad492f75b17f698e981e008b73b51816c6aa",
        "Title": "The Visual Object Tracking VOT2016 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a\u2026\u00a0",
        "Publication Year": "8 October 2016",
        "Citation Count": "705",
        "Reference Count": "112",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Gustavo Javier Fernandez",
            "Abhinav Kumar Gupta",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Andrea Vedaldi",
            "Andreas Robinson",
            "Andy Jinhua Ma",
            "Anton Yuriiovych Varfolomieiev",
            "A. Aydin Alatan",
            "Aykut Erdem",
            "Bernard Ghanem",
            "Bin Liu",
            "Bohyung Han",
            "Brais Mart{\\&#x27;i}nez",
            "Chang-Ming Chang",
            "Changsheng Xu",
            "Chong Sun",
            "Daijin Kim",
            "Dapeng Chen",
            "Dawei Du",
            "Deepak Mishra",
            "D. Y. Yeung",
            "Erhan Gundogdu",
            "Erkut Erdem",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Fei Zhao",
            "Filiz Bunyak",
            "Francesco Battistone",
            "Gao Zhu",
            "Giorgio Roffo",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Henry Medeiros",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst Possegger",
            "Huchuan Lu",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Hyung Jin Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Y. Lee",
            "Jianke Zhu",
            "Jiayi Feng",
            "Jin Gao",
            "Jin Young Choi",
            "Jingjing Xiao",
            "Ji-Wan Kim",
            "Jiyeoup Jeong",
            "Jo{\\~a}o F. Henriques",
            "Jochen Lang",
            "Jongwon Choi",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Junliang Xing",
            "Junyu Gao",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Krystian Mikolajczyk",
            "Lei Qin",
            "Lijun Wang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Madan Kumar Rapuru",
            "Mahdieh Poostchi",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel F. Valstar",
            "Ming Tang",
            "Mooyeol Baek",
            "Muhammad Haris Khan",
            "Naiyan Wang",
            "Nana Fan",
            "Noor M. Al-Shakarji",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Osman Akin",
            "Payman Moallem",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Pong Chi Yuen",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan Pelapur",
            "Richard Bowden",
            "Robert Lagani{\\`e}re",
            "R. Stolkin",
            "Ryan Walsh",
            "Sebastian Bernd Krah",
            "Shengkun Li",
            "Shengping Zhang",
            "Shizeng Yao",
            "Simon Hadfield",
            "Simone Melzi",
            "Siwei Lyu",
            "Siyi Li",
            "Stefan Becker",
            "Stuart Golodetz",
            "Sumithra Kakanuru",
            "Sunglok Choi",
            "Tao Hu",
            "Thomas Mauthner",
            "Tianzhu Zhang",
            "Tony P. Pridmore",
            "Vincenzo Santopietro",
            "Weiming Hu",
            "Wenbo Li",
            "Wolfgang H{\\&quot;u}bner",
            "Xiangyuan Lan",
            "Xiaomeng Wang",
            "Xin Li",
            "Yang Li",
            "Y. Demiris",
            "Yifan Wang",
            "Yuankai Qi",
            "Zejian Yuan",
            "Zexiong Cai",
            "Zhan Xu",
            "Zhenyu He",
            "Zhizhen Chi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d",
            "6b175816b1f81127f5e2a2fe998df99d62290a1c",
            "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5",
            "16be98fa5924131816bc991a2c7ed91b8c69eaaa"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2013-Challenge-Kristan-Matas/4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "ID": "4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "Title": "The Visual Object Tracking VOT2013 Challenge Results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) workshop was organized in\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "333",
        "Reference Count": "137",
        "Authors": [
            "Matej Kristan",
            "Juan E. Sala Matas",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Luka Cehovin",
            "Georg Nebehay",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustavo Javier Fernandez",
            "Alan Luke{\\vz}i{\\vc}",
            "Aleksandar Dimitriev",
            "Alfredo Petrosino",
            "Amir Saffari",
            "Bo Li",
            "Bohyung Han",
            "Cherkeng Heng",
            "Christophe Garcia",
            "Dominik Pangersic",
            "Gustav H{\\&quot;a}ger",
            "Fahad Shahbaz Khan",
            "Franc Oven",
            "Horst Possegger",
            "Horst Bischof",
            "Hyeonseob Nam",
            "Jianke Zhu",
            "Jijia Li",
            "Jin Young Choi",
            "Jinwoo Choi",
            "Jo{\\~a}o F. Henriques",
            "Joost van de Weijer",
            "Jorge Batista",
            "Karel Lebeda",
            "Kristoffer {\\&quot;O}fj{\\&quot;a}ll",
            "Kwang Moo Yi",
            "Lei Qin",
            "Longyin Wen",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Michael Felsberg",
            "Ming-Ming Cheng",
            "Philip H. S. Torr",
            "Qingming Huang",
            "R. Bowden",
            "Sam Hare",
            "Samantha YueYing Lim",
            "Seunghoon Hong",
            "Shengcai Liao",
            "Simon Hadfield",
            "S. Li",
            "Stefan Duffner",
            "Stuart Golodetz",
            "Thomas Mauthner",
            "Vibhav Vineet",
            "Weiyao Lin",
            "Yang Li",
            "Yuankai Qi",
            "Zhen Lei",
            "Zhi Heng Niu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "e3c433ab9608d7329f944552ba1721e277a42d74",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-term-Tracking-in-the-Wild%3A-A-Benchmark-Valmadre-Bertinetto/ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
        "ID": "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
        "Title": "Long-term Tracking in the Wild: A Benchmark",
        "Abstract": "We introduce the OxUvA dataset and benchmark for evaluating single-object tracking algorithms. Benchmarks have enabled great strides in the field of object tracking by defining standardized evaluations on large sets of diverse videos. However, these works have focused exclusively on sequences that are just tens of seconds in length and in which the target is always visible. Consequently, most researchers have designed methods tailored to this \u201cshort-term\u201d scenario, which is poorly\u2026\u00a0",
        "Publication Year": "26 March 2018",
        "Citation Count": "144",
        "Reference Count": "35",
        "Authors": [
            "Jack Valmadre",
            "Luca Bertinetto",
            "Jo{\\~a}o F. Henriques",
            "Ran Tao",
            "Andrea Vedaldi",
            "Arnold W. M. Smeulders",
            "Philip H. S. Torr",
            "Efstratios Gavves"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "d3d36c3caa255053877a7e3250d47d906eec81d2",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/D3S-%E2%80%93-A-Discriminative-Single-Shot-Segmentation-Luke%C5%BEi%C4%8D-Matas/45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "ID": "45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "Title": "D3S \u2013 A Discriminative Single Shot Segmentation Tracker",
        "Abstract": "Template-based discriminative trackers are currently the dominant tracking paradigm due to their robustness, but are restricted to bounding box tracking and a limited range of transformation models, which reduces their localization accuracy. We propose a discriminative single-shot segmentation tracker - D3S, which narrows the gap between visual object tracking and video object segmentation. A single-shot network applies two target models with complementary geometric properties, one invariant to\u2026\u00a0",
        "Publication Year": "20 November 2019",
        "Citation Count": "138",
        "Reference Count": "53",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "b3249763ac9ecc4df6ef96721c8c7410e0f0468a",
            "8b74008565b575f9ab7a0962ca5f6955d64db045",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "4a70c20ad66e5f3bb12fccd84c63ba619053c811"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-enhancement-of-mammogram-images-for-breast-using-Patel-Hadia/f3eb7b753cf2a9569a1d9fdd11618bce28b1ef46",
        "ID": "f3eb7b753cf2a9569a1d9fdd11618bce28b1ef46",
        "Title": "An enhancement of mammogram images for breast cancer classification using artificial neural networks",
        "Abstract": "Breast cancer is the most driving reason for death in women in both developed and developing nations. For the plan of effective classification of a system, the selection of features method must be used to decrease irregularity part in mammogram images. The proposed approach is used to crop the region of interests (ROIs) manually. Based on that number of features are extracted. In this proposed method a novel hybrid optimum feature selection (HOFS) method is used to find out the significant\u2026\u00a0",
        "Publication Year": "1 June 2021",
        "Citation Count": "7",
        "Reference Count": "43",
        "Authors": [
            "Jalpa J. Patel",
            "Sarman K. Hadia"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b7cd3daaf49d0d68579015680d123044683d70ee",
            "b06a69cf5663829d4f4f8168d820b2f7baf88918",
            "dd7282d139c163df0243f7cb508c7be979aa9fda",
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "4a0c851fbffcfdd4d191cff4b38ac42e1d4d6fc9",
            "95bb0ee471480da79e41ae196bb4da02abe52a27",
            "d592e7ed372adffd2d2d8f5c72565d71e911237e",
            "1ca488cbbc84138e12e405661a2db7fcc9f2e4f1",
            "ca30be76395ba443b24d20d7df5d3b5372df55ff",
            "0fc4a247cce443bc2a3d64818d8981ab8586bb32"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Segmentation-and-classification-of-breast-cancer-Ramesh-Sasikala/8e75f635dd7578926aa7ae19ff29a8fc5c3911ae",
        "ID": "8e75f635dd7578926aa7ae19ff29a8fc5c3911ae",
        "Title": "Segmentation and classification of breast cancer using novel deep learning architecture",
        "Abstract": "Breast cancer is one of the most frequent cancers in women, and it has a higher mortality rate than other cancers. As a result, early detection is critical. In computer-assisted disease diagnosis, accurate segmentation of the region of interest is a vital concept. The segmentation techniques have been widely used by doctors and physicians to locate the pathology, identify the abnormality, compute the tissue volume, analyze the anatomical structures, and provide treatment. Cancer diagnostic\u2026\u00a0",
        "Publication Year": "25 May 2022",
        "Citation Count": "10",
        "Reference Count": "68",
        "Authors": [
            "Shashank Ramesh",
            "S. Sasikala",
            "S. Gomathi",
            "V. Geetha",
            "V. Anbumani"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "95cdb70035d13910f2bb7d76ad29d67f619e01d2",
            "18aed16d53bfd0570d40d0be0f3b35338d1c9ead",
            "f7cbb1b2a56d4c74ce4920e353619103098a886e",
            "7c66be06a11210b10afe5dddde51f7c355b98b14",
            "160befefc99d88390d40910b8cd77a5b4d4e310a",
            "ea98b9481ec6943b799a89f0647becafa303066f",
            "b845188382aa1eaaecea4879f41e78f6e0ef03df",
            "542f7bd9c6853d69561e090a8ff82829bf1691f7",
            "3d119f56d43d3d14f4e790da3936b17bac96bab0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Classification-of-Mammograms-Using-Convolutional-Debelee-Amirian/156733fbf757d4e8a333537518c8961163c4fbf7",
        "ID": "156733fbf757d4e8a333537518c8961163c4fbf7",
        "Title": "Classification of Mammograms Using Convolutional Neural Network Based Feature Extraction",
        "Abstract": "Breast cancer is the most common cause of death among women in the entire world and the second cause of death after lung cancer. The use of automatic breast cancer detection and classification might possibly enhance the survival rate of the patients through starting early treatment. In this paper, the convolutional Neural Networks (CNN) based feature extraction method is proposed. The features dimensionality was reduced using Principal Component Analysis (PCA). The reduced features are given to\u2026\u00a0",
        "Publication Year": "25 September 2017",
        "Citation Count": "26",
        "Reference Count": "29",
        "Authors": [
            "Taye Girma Debelee",
            "Mohammadreza Amirian",
            "Achim Ibenthal",
            "G{\\&quot;u}nther Palm",
            "Friedhelm Schwenker"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "8271f755d7cea799600e25662dd3f2ac8d23aeb1",
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "95bb0ee471480da79e41ae196bb4da02abe52a27",
            "d38eeb88a928c1a1c6e1fdd18d504669b112ed8b",
            "2c5db1c44dddf0d8e6ea667f3f7afb13032ea386",
            "4592b296b02a97ce7c49e7ef53bfa5e809bb548e",
            "eb8f6f8c48e6b61ea35e7294f26f7cfbbc3dd833",
            "a4360f362168a6107e1014b7fc61bed32038fc70",
            "0003a45ae653fcccb568b90dbb339cf5811a18bf",
            "2415fc06de82ab41ad8b9615162247afb02974af"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Machine-learning-based-computer-aided-diagnosis-for-Singh-Sharma/6e69f7ea9f63b651ebd676d51d6cca1a483cb2ec",
        "ID": "6e69f7ea9f63b651ebd676d51d6cca1a483cb2ec",
        "Title": "Machine learning based computer aided diagnosis system for classification of breast masses in mammograms",
        "Abstract": "Breast cancer continues to be the most common cancer in the fastest developing and the developed nations. Early detection by using mammography has been proven as the best prognosis. Computer Aided Diagnosis (CAD) systems are being used as second reader for the analysis and interpretation of mammogram images. In the last two decades, although breast cancer incidence has increased by many folds but unfortunately the progress in this field has almost stagnated. Therefore, the CAD systems need to\u2026\u00a0",
        "Publication Year": "1 May 2022",
        "Citation Count": "One",
        "Reference Count": "26",
        "Authors": [
            "Harmandeep Singh",
            "Vipul Sharma",
            "Damanpreet Singh"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c0cdec8e8149ab2e7d185893e3f18eb0089a0f2f",
            "76389ebb7c1496239e66fd663b0e7e43d391bca9",
            "662d927da3c17bfde61da5dbc24c037dce30ce25",
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "9bf32a68edfea8b8c072bcd3ee0d696687bab403",
            "da4237818523ea3e3d44dbe18c261afc6d6d404f",
            "f0a4d96b5d7f6668d607512f8744e07dbe1c9b27",
            "db480b3f22244151cfeaa4beedc406a5137d1a4e",
            "037587b28682886bb02d87a150028ed931f967a4",
            "0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Hierarchical-Classification-Method-for-Breast-Mohammadpoor-Shoeibi/4d7ef4f116a535750529e2853c181d5d3b678646",
        "ID": "4d7ef4f116a535750529e2853c181d5d3b678646",
        "Title": "A Hierarchical Classification Method for Breast Tumor Detection",
        "Abstract": "Introduction Breast cancer is the second cause of mortality among women. Early detection of it can enhance the chance of survival. Screening systems such as mammography cannot perfectly differentiate between patients and healthy individuals. Computer-aided diagnosis can help physicians make a more accurate diagnosis. Materials and Methods Regarding the importance of separating normal and abnormal cases in screening systems, a hierarchical classification system is defined in this paper. The\u2026\u00a0",
        "Publication Year": "1 December 2016",
        "Citation Count": "22",
        "Reference Count": "14",
        "Authors": [
            "Mojtaba Mohammadpoor",
            "Afshin Shoeibi",
            "H. Zare",
            "H. Shojaee"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "82917b65ec0e7fa1bbdc0ba08642fd8c336196a1",
            "46c409dd878e643271ef63f1817ded8b57abc01e",
            "ba6b8c2852be77702ff1765cefde34004da9d4b5",
            "74b5ce5b484a5bd714cab5dd4424a26cbdabbb35",
            "22d4b480e03e7d068356860d8c4485b41a0acfeb",
            "643afbfd187a020cb19bad103176e055821e1bb9",
            "8d7bc6a0af5c063c457a88561bcf8f895c9f7392",
            "d2c0761e849f656a8933f2c75b8ff8a10713684f",
            "442a7613e992da09758482b035204ac2184ec7da"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Breast-MRI-Tumor-Automatic-Segmentation-and-Breast-Guo-Huang/b4ae16a6f020e12062f426781ef3971c82f7f455",
        "ID": "b4ae16a6f020e12062f426781ef3971c82f7f455",
        "Title": "Breast MRI Tumor Automatic Segmentation and Triple-Negative Breast Cancer Discrimination Algorithm Based on Deep Learning",
        "Abstract": "Background Breast cancer is a kind of cancer that starts in the epithelial tissue of the breast. Breast cancer has been on the rise in recent years, with a younger generation developing the disease. Magnetic resonance imaging (MRI) plays an important role in breast tumor detection and treatment planning in today's clinical practice. As manual segmentation grows more time-consuming and the observed topic becomes more diversified, automated segmentation becomes more appealing. Methodology. For\u2026\u00a0",
        "Publication Year": "31 August 2022",
        "Citation Count": "4",
        "Reference Count": "44",
        "Authors": [
            "Ying Guo",
            "Yinhui Huang",
            "Yi Wang",
            "Jing Huang",
            "Qingquan Lai",
            "Yuan-Fang Li"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "d35b1cfb76b29e03bdef563fce3fa72174ff5d73",
            "eadce7b941e72118f41bb5ccf1671da7e33d4a6f",
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "0eb654b40506a5893183ade17a733a33ded0473e",
            "bb37534000314b5174aa902f58f053218cf2a7a3",
            "9a5bc8c67d7a675981cdda5e73f55aeb6d68fc5d",
            "710168b731ffc565512bf81bf8d45fc0771c9b5e",
            "bf83da36e91c4d2b6fff467c518d79ab14adc25b",
            "2346b458b1079f9e9216f46df851f1f76f73e5d8",
            "850b01c04c130c281e04eb17d2f0fe46507cf632"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-adaptive-region-growing-algorithm-for-breast-in-Cao-Hao/3c948ca247c6f55ef994400e713412b5f845dd40",
        "ID": "3c948ca247c6f55ef994400e713412b5f845dd40",
        "Title": "An adaptive region growing algorithm for breast masses in mammograms",
        "Abstract": "This study attempted to accurately segment the mammographic masses and distinguish malignant from benign tumors. An adaptive region growing algorithm with hybrid assessment function combined with maximum likelihood analysis and maximum gradient analysis was developed in this paper. In order to accommodate different situations of masses, the likelihood and the edge gradients of segmented masses were weighted adaptively by the use of information entropy. 106 benign and 110 malignant tumors were\u2026\u00a0",
        "Publication Year": "13 May 2010",
        "Citation Count": "25",
        "Reference Count": "31",
        "Authors": [
            "Ying Cao",
            "Xin Hao",
            "Xiaoen Zhu",
            "Shun-ren Xia"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3f116f1763a3604275b06c6ccf0dcd65910d13b5",
            "7642ea8a5bd70c3eede1c1c9bf8b666bf4c5c0a3",
            "5e99438461ae96f4a5816e37a9e01f9d9ae6ab4e",
            "c909583f2560864a2650dc25dbcd09da8eb96fbd",
            "e3f3ff00759dca433cf5740b38dd8dce25ee45a0",
            "a23937d6345c6e707cf17509ec27c76fef4ce7cc",
            "34c44883a6152c5298f2c452670c1127072400e6",
            "a277fe4df26e09a6c375e32d77472ae2c9a7632d",
            "931d0f894fd46ada2051e2b451c1b3ee675a397c",
            "0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Building-an-ensemble-system-for-diagnosing-masses-Zhang-Tomuro/d0059280e3f69b8fd07ce036e7d2407e3ebcff9e",
        "ID": "d0059280e3f69b8fd07ce036e7d2407e3ebcff9e",
        "Title": "Building an ensemble system for diagnosing masses in mammograms",
        "Abstract": "PurposeClassification of a suspicious mass (region of interest, ROI) in a mammogram as malignant or benign may be achieved using mass shape features. An ensemble system was built for this purpose and tested.MethodsMultiple contours were generated from a single ROI using various parameter settings of the image enhancement functions for the segmentation. For each segmented contour, the mass shape features were computed. For classification, the dataset was partitioned into four subsets based on\u2026\u00a0",
        "Publication Year": "1 March 2012",
        "Citation Count": "48",
        "Reference Count": "33",
        "Authors": [
            "Yu Zhang",
            "Noriko Tomuro",
            "Jacob D. Furst",
            "Daniela Stan Raicu"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "995a9f5653e95ff874e39da5d2d0beeb36aaa950",
            "a9761b957e9e00dfe99b41c36afbf68e4dd6e5c8",
            "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba",
            "7577f9d9beecb8b5f97822cbcb9742f97afa9cd4",
            "9c4424874d34e511373e6daefd3630faa3921a80",
            "34c44883a6152c5298f2c452670c1127072400e6",
            "0ff3cefb443e5e0f168d8b3be38435848d8a93a1",
            "0db9038edba073a75014870b486981b8b8ed9050",
            "b5ec7cb440fc82239b940fbe02d21d9e94483d4f",
            "cc3a4e8bcb49ae31977cc3d99549529596e36fe7"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-ranklet-based-image-representation-for-mass-in-Masotti/483f0f12feb8ac1c396349e5526a7552b6b067cd",
        "ID": "483f0f12feb8ac1c396349e5526a7552b6b067cd",
        "Title": "A ranklet-based image representation for mass classification in digital mammograms.",
        "Abstract": "Regions of interest (ROIs) found on breast radiographic images are classified as either tumoral mass or normal tissue by means of a support vector machine classifier. Classification features are the coefficients resulting from the specific image representation used to encode each ROI. Pixel and wavelet image representations have already been discussed in one of our previous works. To investigate the possibility of improving classification performances, a novel nonparametric, orientation\u2026\u00a0",
        "Publication Year": "1 October 2006",
        "Citation Count": "46",
        "Reference Count": "33",
        "Authors": [
            "Matteo Masotti"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ca75aca02d71ae1c2242024daf664d5753e32efa",
            "3a54399b141999271e49c652979f65fcd968daa9",
            "f876d2b733ed1e307c81df3008d10ffa60675f0b",
            "34856bb7b455a317126787076be40f4f57154273",
            "e764d70b416fa5fee1fd76ed21d64e26ef187bb9",
            "29dab22d41369fe0af3dd6bca85e0c5aa6859ded",
            "931d0f894fd46ada2051e2b451c1b3ee675a397c",
            "38f7c8cfb6b52df515c1cb29a2e42f6673e7a377",
            "413bb48a77c0730693ea8217d89cab28a686e7a3",
            "eddad94fd10693fb0cf3340792f11af15232b49c"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Bayesian-System-And-Copula-For-Event-Detection-And-Patil/662df45afea0d80922a86a4af431eb80ede87da2",
        "ID": "662df45afea0d80922a86a4af431eb80ede87da2",
        "Title": "Bayesian System And Copula For Event Detection And Summarization Of Soccer Videos",
        "Abstract": "Event detection is a standout amongst the most key parts for distinctive sorts of area applications of video data framework. Recently, it has picked up an extensive interest of experts and in scholastics from different zones. While detecting video event has been the subject of broad study efforts recently, impressively less existing methodology has considered multimodel data and issues related efficiency. Start of soccer matches different doubtful circumstances rise that can't be effectively\u2026\u00a0",
        "Publication Year": "2015",
        "Citation Count": "3",
        "Reference Count": "38",
        "Authors": [
            "Dhanuja S Patil"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73",
            "b5a23310cdc5b492175325ba90af69ecda3dc377",
            "5055097cd7279bc3cd16474e1629cf0c24ed7249",
            "d6151de801659937574c3efe13c2d207e9e2f2cd",
            "5a7571db7df03cca52c48f89595c4abefeb51e5c",
            "cc85119fdac7f6e9b0afa5e5a87983f6bca2f1c9",
            "d804cdf4f348a3f4ef782f8818064f0dc17c62d7",
            "c7967ff0c51732110e0e1470975fe0a974fa8a2e",
            "63ddcd8ffd48628df02c7cbe5ede83d35af2f0c6",
            "c51d7cbfb95ee370d1eddb4e0ff03290b8bb479a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Event-detection-in-soccer-videos-using-shot-focus-Zhao-Lu/0a89745435b38291f0f2f17173f33ccb5d3a826b",
        "ID": "0a89745435b38291f0f2f17173f33ccb5d3a826b",
        "Title": "Event detection in soccer videos using shot focus identification",
        "Abstract": "This paper presents an automatic event detection system fusing low and mid level features for soccer videos. We first employ an improved approach for Shot Boundary Detection with color and our mean-gradient feature. Then we classify the shots into two view types. We also perform a template-based replay detection for each shot. Play-break sequences are then generated using a rule-based method. We devise a novel method to locate the spatial position of event occurrence accurately using shot focus\u2026\u00a0",
        "Publication Year": "1 November 2015",
        "Citation Count": "5",
        "Reference Count": "15",
        "Authors": [
            "Wei Zhao",
            "Yao Lu",
            "Haohao Jiang",
            "Wei Huang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "99fef30f1afa7e8c485e40aac74f7d8923dc892f",
            "3e4643c9c1e8707ab6e2a1db1fc0e2bab2967538",
            "aa7e4bedb68abc0891e1e4d0fc58873e25c34751",
            "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73",
            "1e03756ae8f456d0026308347e24712d9702dd40",
            "0cca81f3b2928f6d4005e1a8b617960e2fb14d3e",
            "a322bf3be4118a4d787bd4f9cb77df48e5b6ce3d",
            "85434dcdf128c2e667d0a05a8799fe205d52e742",
            "fa77b359b9ceb014a6e5a528de24d3d725017b36",
            "d71c84fbaff0d7f2cbcf2f03630e189c58939a4a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-survey-on-event-detection-based-video-for-cricket-Raval-Goyani/828f9424abab6fd3e48df5025bef4ff5d56c4295",
        "ID": "828f9424abab6fd3e48df5025bef4ff5d56c4295",
        "Title": "A survey on event detection based video summarization for cricket",
        "Abstract": "Nowadays, sports video analysis is gaining a lot of traction. Cricket is an exciting team sport to watch. Cricket is becoming more popular, but due to the game\u2019s length and intricacy, computerized cricket video analysis is difficult. This motivates us to conduct surveys that will aid in the advancement of cricket research. We reviewed event detection-based cricket video summarizing strategies in this article. We give an overview of the automatic cricket video analysis technique and its\u2026\u00a0",
        "Publication Year": "2 April 2022",
        "Citation Count": "2",
        "Reference Count": "81",
        "Authors": [
            "Khushali R. Raval",
            "Mahesh M. Goyani"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "43ef35c36e61e7db6b0ef35ef28314bf8fc29827",
            "8177d4a1f289979d6dcca3536b739925a9552b79",
            "fa0fd2f20c36d5668d3044da903d1549a04a8550",
            "9aeb307f1095e7109ecfb51b5489b36f82138d82",
            "fa1594ecf4bd4b6a76d6e4670ea11593171e9a4d",
            "132369a5df9eb8ee57867dd116792a5ad6c3b180",
            "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73",
            "084e58343d5783bfb6f0ede987ecb5b3701ff21c",
            "005bc35240c1a306ac897ab42b611675ab565582",
            "b66b45ba5d12490f7101cc314d7c6c066455fe72"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Replay-and-key-events-detection-for-sports-video-Javed-Irtaza/b66b45ba5d12490f7101cc314d7c6c066455fe72",
        "ID": "b66b45ba5d12490f7101cc314d7c6c066455fe72",
        "Title": "Replay and key-events detection for sports video summarization using confined elliptical local ternary patterns and extreme learning machine",
        "Abstract": "Sports broadcasters generate enormous amount of video content viewed all over the world. To capture the user interests in the rebroadcasted content, the sports videos are summarized that need the manual inspection and analysis. However, the huge repository and long duration of videos make manual analysis and summarization a laborious and time-consuming job. To overcome this problem, efforts have been made for automatic video summarization. In this paper, a novel framework to summarize sports\u2026\u00a0",
        "Publication Year": "12 February 2019",
        "Citation Count": "20",
        "Reference Count": "43",
        "Authors": [
            "Ali Javed",
            "Aun Irtaza",
            "Yasmeen Khaliq",
            "Hafiz Malik",
            "Muhammad Tariq Mahmood"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c39184b1cd6e7eeee5f451f1f6b7f199a76ce27c",
            "b41fdd4780e91f23652e7bb80046b960fad3caf4",
            "1c4b043e1e458f3cb6bcd5c47edbef6816383674",
            "5727fdb06696f92d406adb81459dd2e56da1dfeb",
            "0258f2cfe8a788078e269dc2fe9d23592d5fffc1",
            "aa7e4bedb68abc0891e1e4d0fc58873e25c34751",
            "2f269fddf637b71e9ee074e13a1c95f709fdf29a",
            "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73",
            "f5917f8507fd498ee55cc4e7af5c6583a745e229",
            "87f19a58a7739e7c11e3638b5b32d1f51632284f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Video-Summarization%3A-Survey-on-Event-Detection-and-Khan-Pawar/92b1bf710340ecbf5f40005d88f9005d6882325f",
        "ID": "92b1bf710340ecbf5f40005d88f9005d6882325f",
        "Title": "Video Summarization: Survey on Event Detection and Summarization in Soccer Videos",
        "Abstract": "In today's world, the rapid development of digital video and editing technology has led to fast growing of video data, creating the need for effective and advanced techniques for analysis and video retrieval, as multimedia repositories have made browsing, delivery of contents (video) and video retrieval very slow. Hence, video summarization proposes various ways for faster browsing among a large amount of data and also for content indexing. Many people spend their free time to watch or play\u2026\u00a0",
        "Publication Year": "2015",
        "Citation Count": "16",
        "Reference Count": "21",
        "Authors": [
            "Yasmin S. Khan",
            "Soudamini Pawar"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f",
            "88acfe06f45d0c623ee0a757894b695c03b1c10c",
            "e8463f44930ab9ab85f2ab7c986c3008e02e12d7",
            "2a5b66c1d18382a2be4035f5af03683d6c0bb83c",
            "dc8177ff75f0f9125c63a04d71e06d37480c457e",
            "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73",
            "33ee7e142456166bb2ae29c7ab5125202072482b",
            "33ac99240737c9e2c47647c445978207a9697f32",
            "d50f0e87357c6ee909eb6322f892e4641666fdfb",
            "0cca81f3b2928f6d4005e1a8b617960e2fb14d3e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-decision-tree-framework-for-shot-classification-Javed-Malik/c3c70ec1636e9cbb271cdf84e6b6125894c38cfb",
        "ID": "c3c70ec1636e9cbb271cdf84e6b6125894c38cfb",
        "Title": "A decision tree framework for shot classification of field sports videos",
        "Abstract": "Automated approaches to analyze sports video content have been heavily explored in the last few decades to develop more informative and effective solutions for replay detection, shot classification, key-events detection, and summarization. Shot transition detection and classification are commonly applied to perform temporal segmentation for video content analysis. Accurate shot classification is an indispensable requirement to precisely detect the key-events and generate more informative\u2026\u00a0",
        "Publication Year": "16 January 2020",
        "Citation Count": "12",
        "Reference Count": "38",
        "Authors": [
            "Ali Javed",
            "Khalid Mahmood Malik",
            "Aun Irtaza",
            "Hafiz Malik"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b66b45ba5d12490f7101cc314d7c6c066455fe72",
            "2f1f9717c3257fb2a264548ee69130c43e61795b",
            "d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f",
            "31e12ef5fb856bc1ede9afa8750fed4141efac37",
            "b41fdd4780e91f23652e7bb80046b960fad3caf4",
            "5b54b9de58ee8a38489b8bd48843e2da13afa92c",
            "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73",
            "2f5bedd7f5a9381c4a59ec73132ca405bf3bb4b9",
            "0b1e432fd1852d797417b4cbd317c44ce01f5a66",
            "084e58343d5783bfb6f0ede987ecb5b3701ff21c"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Soccer-Video-Structure-Analysis-by-Parallel-Feature-Fani-Yazdi/0b1e432fd1852d797417b4cbd317c44ce01f5a66",
        "ID": "0b1e432fd1852d797417b4cbd317c44ce01f5a66",
        "Title": "Soccer Video Structure Analysis by Parallel Feature Fusion Network and Hidden-to-Observable Transferring Markov Model",
        "Abstract": "Automated analysis of broadcast soccer game video is a challenging computer vision problem. Prior to performing high-level analysis (such as event detection), accurate classification of shot views and play\u2013break segmentation are required to analyze the structure of soccer video. A novel deep network called parallel feature fusion network (PFF-Net) combines local and full-scene features to produce accurate shot view classification based on camera zoom and out-of-field status. Then, a novel\u2026\u00a0",
        "Publication Year": "2 November 2017",
        "Citation Count": "15",
        "Reference Count": "37",
        "Authors": [
            "Mehrnaz Fani",
            "Mehran Yazdi",
            "David A Clausi",
            "Alexander Wong"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "a0b6c6f8a8b12b843ca1b7c3430b2f0494ec84c2",
            "d16db59f20593fb90e0bc467afddfdb7d71d8dce",
            "d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f",
            "d71c84fbaff0d7f2cbcf2f03630e189c58939a4a",
            "f7b4fcc9dbb97997dc1793d7a366cba274f53134",
            "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73",
            "d8b96b08758238de7b901737c824c4694186ae9e",
            "cf90380f93f2b67128e0c8e2816481f601c01845",
            "96d642aac3a930cc1b37100130a9f1c0ad8c9a01",
            "2e991717e4e0b6fafb19f3e048886fce9d2058c1"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Structural-Approach-for-Event-Resolution-in-Cricket-Premaratne-Jayaratne/cc810ccea173885c7630e159409be23a2fdd028c",
        "ID": "cc810ccea173885c7630e159409be23a2fdd028c",
        "Title": "Structural Approach for Event Resolution in Cricket Videos",
        "Abstract": "Classification of multimedia big data today has become a serious issue for organizations. Therefore, new concepts to mine of multimedia big have emerged and people are doing numerous researches on how to effectively handle different types of multimedia data also known as multi model data. In our research, we focus on how to effectively extract and classify data from a multimedia data related to sports videos and draw conclusions considering all media present in the content. We specifically\u2026\u00a0",
        "Publication Year": "27 December 2017",
        "Citation Count": "5",
        "Reference Count": "12",
        "Authors": [
            "S. C. Premaratne",
            "K. L. Jayaratne"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "8177d4a1f289979d6dcca3536b739925a9552b79",
            "7770f803c514ae706980d505a7b7cb39d914c2ce",
            "e52d518aeb1160a80f4f4a402dbcfe4f7f26d3f4",
            "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73",
            "99963f66cc2716ba5d42fab0454fff3dbf6bfef9",
            "85155400c474d70cf781a4ab1f8e16684846d7de",
            "099b13b46bfa87f105680444eb4dc158fe3b6d52",
            "31ee214486b6cff48c98a9ca39a22c23ac69b897",
            "24ef175324d153b5d98420213c5b200ea7a3e0b0",
            "e77f4abb48bde5e48a2a80e69b5b710f0c90b2ee"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Soccer-Video-Event-Detection-Based-on-Deep-Learning-Yu-Lei/168ebf77527329bc2dbd0ce82bddb9905c3aa7ee",
        "ID": "168ebf77527329bc2dbd0ce82bddb9905c3aa7ee",
        "Title": "Soccer Video Event Detection Based on Deep Learning",
        "Abstract": "Automatically identifying the most interesting content in a long video remains a challenging task. Event detection is an important aspect of soccer game research. In this paper, we propose a model that is able to detect events in long soccer games with a single pass through the video. Combined with replay detection, we generate story clips, which contain more complete temporal context, meeting audiences\u2019 needs. We also introduce a soccer game dataset that contains 222 broadcast soccer videos\u2026\u00a0",
        "Publication Year": "11 December 2018",
        "Citation Count": "21",
        "Reference Count": "37",
        "Authors": [
            "Junqing Yu",
            "Aiping Lei",
            "Yangliu Hu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "5365268588793b93a3ef2873c2abc3135e6c6ad6",
            "97398356607115f78d677663a682363eec3302d7",
            "195df1106f4d7aff0e9cb609358abbf80f54a716",
            "3de050d1707524512eeab99780df3cbdee09670c",
            "3970dd4fec08c807930404650a94c4e780ce9f6c",
            "96dd1fc39a368d23291816d57763bc6eb4f7b8d6",
            "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73",
            "10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f",
            "317eaf94573857bec786bbf030605ccdb0fd624d",
            "1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Automatic-Soccer-Video-Analysis-and-Summarization-Ekin-Tekalp/d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f",
        "ID": "d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f",
        "Title": "Automatic Soccer Video Analysis and Summarization",
        "Abstract": "We propose a fully automatic and computationally efficient framework for analysis and summarization of soccer videos using cinematic and object-based features. The proposed framework includes some novel low-level soccer video processing algorithms, such as dominant color region detection, robust shot boundary detection, and shot classification, as well as some higher-level algorithms for goal detection, referee detection, and penalty-box detection. The system can output three types of summaries\u2026\u00a0",
        "Publication Year": "10 January 2003",
        "Citation Count": "904",
        "Reference Count": "40",
        "Authors": [
            "Ahmet Ekin",
            "A. Murat Tekalp"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d6151de801659937574c3efe13c2d207e9e2f2cd",
            "339acc20ebbf3c08c797373f873e4e6b9f2f9c9a",
            "7b068d9ff88588a15d6d5fa8e7932d4e635cd252",
            "564649846003db680733697947f974a1ef03c4ea",
            "5a7571db7df03cca52c48f89595c4abefeb51e5c",
            "a3a7a3fe0fc54665d5e22461a27e2aa2816666a8",
            "832f48f5c28956e892e0ece93e2802f4501036ab",
            "f0bafbf9cf2dfb1fd7e439e2336f1dd3af19478c",
            "5055097cd7279bc3cd16474e1629cf0c24ed7249",
            "c8de9f939f497d430c15d5bfa54174e38d4ac681"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Semantic-analysis-of-soccer-video-using-dynamic-Huang-Shih/d71c84fbaff0d7f2cbcf2f03630e189c58939a4a",
        "ID": "d71c84fbaff0d7f2cbcf2f03630e189c58939a4a",
        "Title": "Semantic analysis of soccer video using dynamic Bayesian network",
        "Abstract": "Video semantic analysis is formulated based on the low-level image features and the high-level knowledge which is encoded in abstract, nongeometric representations. This paper introduces a semantic analysis system based on Bayesian network (BN) and dynamic Bayesian network (DBN). It is validated in the particular domain of soccer game videos. Based on BN/DBN, it can identify the special events in soccer games such as goal event, corner kick event, penalty kick event, and card event. The video\u2026\u00a0",
        "Publication Year": "1 August 2006",
        "Citation Count": "162",
        "Reference Count": "26",
        "Authors": [
            "Chung-Lin Huang",
            "Huang-Chia Shih",
            "Chung-Yuan Chao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f",
            "b5a23310cdc5b492175325ba90af69ecda3dc377",
            "5055097cd7279bc3cd16474e1629cf0c24ed7249",
            "c51d7cbfb95ee370d1eddb4e0ff03290b8bb479a",
            "cc85119fdac7f6e9b0afa5e5a87983f6bca2f1c9",
            "3dcd7ed1905e94b06b0c8f087007f00951b030ab",
            "d6151de801659937574c3efe13c2d207e9e2f2cd",
            "54e04284d0d33fabcd7be961ff29af2223638dee",
            "5a7571db7df03cca52c48f89595c4abefeb51e5c",
            "c7967ff0c51732110e0e1470975fe0a974fa8a2e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Event-Detection-of-Broadcast-Baseball-Videos-Hung-Hsieh/43eb2d80721daa318cc19e4cce405122934e88f2",
        "ID": "43eb2d80721daa318cc19e4cce405122934e88f2",
        "Title": "Event Detection of Broadcast Baseball Videos",
        "Abstract": "This paper presents an effective and efficient event detection system for broadcast baseball videos. It integrates midlevel cues including scoreboard information and shot transition patterns into event classification rules. First, a simple scoreboard detection and recognition scheme is developed to extract the game status from videos. Then, a shot transition classifier is designed to obtain the shot transition patterns, which contains several novel schemes including adaptive playfield\u2026\u00a0",
        "Publication Year": "1 December 2008",
        "Citation Count": "38",
        "Reference Count": "16",
        "Authors": [
            "Mao-Hsiung Hung",
            "Chaur-Heh Hsieh"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d0ec6dee3f7cd0c1571d179d756afc823cda636b",
            "8268944e509094df7eda14e3963d1add1db87528",
            "ed9456c605c18aeb9b0aff5eaae4038ef4adb564",
            "a0b6c6f8a8b12b843ca1b7c3430b2f0494ec84c2",
            "3dcd7ed1905e94b06b0c8f087007f00951b030ab",
            "e89332600d8abd393bcd8020d69c6a7a3298a966",
            "d71c84fbaff0d7f2cbcf2f03630e189c58939a4a",
            "5727fdb06696f92d406adb81459dd2e56da1dfeb",
            "263eb915898a9e79ff1cb4d234dacd6b2ea72be3",
            "ce8883dbe8c695d8ef770eefe34e48efe7c0cf64"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Knowledge-Discounted-Event-Detection-in-Sports-Tjondronegoro-Chen/0cca81f3b2928f6d4005e1a8b617960e2fb14d3e",
        "ID": "0cca81f3b2928f6d4005e1a8b617960e2fb14d3e",
        "Title": "Knowledge-Discounted Event Detection in Sports Video",
        "Abstract": "Automatic events annotation is an essential requirement for constructing an effective sports video summary. Researchers worldwide have actively been seeking the most robust and powerful solutions to detect and classify key events (or highlights) in different sports. Most of the current and widely used approaches have employed rules that model the typical pattern of audiovisual features within particular sport events. These rules are mainly based on manual observation and heuristic knowledge\u2026\u00a0",
        "Publication Year": "1 May 2010",
        "Citation Count": "89",
        "Reference Count": "37",
        "Authors": [
            "Dian Tjondronegoro",
            "Yi-Ping Phoebe Chen"
        ],
        "Related Topics": [
            "Education"
        ],
        "References": [
            "c7bc06203ee09cf2066b47c3ac1fa444dfa8d878",
            "217478d6a95a5bceef11d7846895b57718d63e73",
            "ad31e976cfa5cba56b84a2f7e05adceee99366df",
            "8e0f60b718fa19c2ed10bd93401796683af79512",
            "cb6742b271ae81baa217d2d6391ead067f6e7018",
            "cc8756e654c8c3016c1e86189b76fe6b8a08773a",
            "ba73512ff40f576a4ab6a8f1be6de08256fdf038",
            "77eba439796f8482a1f36be31dfddbae7536d792",
            "5a7571db7df03cca52c48f89595c4abefeb51e5c",
            "5727fdb06696f92d406adb81459dd2e56da1dfeb"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-semantic-event-detection-approach-and-its-to-in-Haering-Qian/0365c1382924394e200cb627e59cb9c21f8e75bd",
        "ID": "0365c1382924394e200cb627e59cb9c21f8e75bd",
        "Title": "A semantic event-detection approach and its application to detecting hunts in wildlife vide",
        "Abstract": "We propose a three-level video-event detection methodology and apply it to animal-hunt detection in wildlife documentaries. The first level extracts color, texture, and motion features, and detects shot boundaries and moving object blobs. The mid-level employs a neural network to determine the object class of the moving object blobs. This level also generates shot descriptors that combine features from the first level and inferences from the mid-level. The shot descriptors are then used by the\u2026\u00a0",
        "Publication Year": "1 September 2000",
        "Citation Count": "130",
        "Reference Count": "44",
        "Authors": [
            "Niels C. Haering",
            "Richard J. Qian",
            "M. Ibrahim Sezan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "e7bd444bbe813273dee084e9efc67d95f411cc19",
            "93954c1e3cee3039d2b6b53c61ff6137e9e335bd",
            "3eeebdce6255b997c4ced11d9d45d5bef421b2c6",
            "54ecdf01c1bbbe8106cd27a35aed672c3564ef34",
            "3a8ce1bcf4a092761246d99f0cde788f1804577f",
            "dc185ecd84439165d6cfe90001997cab9b202736",
            "eea56eadd6be66cff71748ef7d9ab54b61033bd8",
            "9895be389b31013b477e3bb48a006ad5c73f3a14",
            "19c8dc7b4acdeecf092526d767156ac8950c02d8",
            "edea2f25d705d43ce90f725eed62f7dba6fbd50f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Integrated-Mining-of-Visual-Features%2C-Speech-and-Tseng-Su/c9edc10d5c22ae62a700c37a41bb0ea22961a0aa",
        "ID": "c9edc10d5c22ae62a700c37a41bb0ea22961a0aa",
        "Title": "Integrated Mining of Visual Features, Speech Features, and Frequent Patterns for Semantic Video Annotation",
        "Abstract": "To support effective multimedia information retrieval, video annotation has become an important topic in video content analysis. Existing video annotation methods put the focus on either the analysis of low-level features or simple semantic concepts, and they cannot reduce the gap between low-level features and high-level concepts. In this paper, we propose an innovative method for semantic video annotation through integrated mining of visual features, speech features, and frequent semantic\u2026\u00a0",
        "Publication Year": "1 February 2008",
        "Citation Count": "63",
        "Reference Count": "26",
        "Authors": [
            "Vincent S. Tseng",
            "Ja-Hwung Su",
            "Jhih-Hong Huang",
            "Chih-Jen Chen"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "a544b12d39c059a1a9ba7da3d5fe78747c9cabaa",
            "0d10531bea859670320ff1fbfd882af8dcf9abf3",
            "e7afd8e942e370e7fdaf3f395492c4aba0b8080b",
            "30ee51ff3120051bc30d64b2a80cc7edcba7d511",
            "3a8ce1bcf4a092761246d99f0cde788f1804577f",
            "fad43474e4fa71eb2527ef30adfa7bb7870baa83",
            "933faea49491113927c18d6739ed24fc5d8624eb",
            "ba4e1089e2c5a1c12e9f6c2686e9c8d1870c718e",
            "09460c5170f5b65e0772cd8d18491accfd9d78d9",
            "ed7368b4c65d872f6886260271b9b94c2fa2b89b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Using-Webcast-Text-for-Semantic-Event-Detection-in-Xu-Zhang/90fbd777cf57096e9292601dfe0dbab30198d40f",
        "ID": "90fbd777cf57096e9292601dfe0dbab30198d40f",
        "Title": "Using Webcast Text for Semantic Event Detection in Broadcast Sports Video",
        "Abstract": "Sports video semantic event detection is essential for sports video summarization and retrieval. Extensive research efforts have been devoted to this area in recent years. However, the existing sports video event detection approaches heavily rely on either video content itself, which face the difficulty of high-level semantic information extraction from video content using computer vision and image processing techniques, or manually generated video ontology, which is domain specific and\u2026\u00a0",
        "Publication Year": "1 November 2008",
        "Citation Count": "162",
        "Reference Count": "44",
        "Authors": [
            "Changsheng Xu",
            "Yifan Zhang",
            "Guangyu Zhu",
            "Yong Rui",
            "Hanqing Lu",
            "Qingming Huang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "7eb16b3e160622fbf58836b2fb884af30a2b19b5",
            "cc8756e654c8c3016c1e86189b76fe6b8a08773a",
            "e891530c62ab431de4330693ed5dbda8509802ce",
            "d993c5d2a62242c9a20550587379c15f6d4ce860",
            "d0ec6dee3f7cd0c1571d179d756afc823cda636b",
            "833deab2d9f7bde03848c58b5d8066d153ee60af",
            "20b253b8846814b5e06007cb337785b963633308",
            "217478d6a95a5bceef11d7846895b57718d63e73",
            "99009072d31cf16cd817dffd0aac6b134d71ddb5",
            "7b29d588cf0d910f867f8eeee3d0a2b0e183e0c8"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Event-detection-in-field-sports-video-using-and-a-Sadlier-O'Connor/8e0f60b718fa19c2ed10bd93401796683af79512",
        "ID": "8e0f60b718fa19c2ed10bd93401796683af79512",
        "Title": "Event detection in field sports video using audio-visual features and a support vector Machine",
        "Abstract": "In this paper, we propose a novel audio-visual feature-based framework for event detection in broadcast video of multiple different field sports. Features indicating significant events are selected and robust detectors built. These features are rooted in characteristics common to all genres of field sports. The evidence gathered by the feature detectors is combined by means of a support vector machine, which infers the occurrence of an event based on a model generated during a training phase\u2026\u00a0",
        "Publication Year": "1 October 2005",
        "Citation Count": "258",
        "Reference Count": "45",
        "Authors": [
            "David A. Sadlier",
            "Noel E. O&#x27;Connor"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "6a9a5667b7595bf06290665f7b32f540e60dbbc3",
            "5a7571db7df03cca52c48f89595c4abefeb51e5c",
            "1248d51ccfbcbc89f5682774f5f9f88da4f68611",
            "e2beed07f3841bc6f97efa2fa65b232d15f6e9d2",
            "217478d6a95a5bceef11d7846895b57718d63e73",
            "d203dbaf6047ac6e1cdfecb8b753bd2593f1023b",
            "c51d7cbfb95ee370d1eddb4e0ff03290b8bb479a",
            "0ba6ab976e3ec7650df31642ea58759d8bae46f5",
            "20b253b8846814b5e06007cb337785b963633308",
            "278dc8bce9b16b135a26a1651db7e3f43eb289ac"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Video-Event-Detection-and-Mining-Framework-Guler-Liang/c2f8178ce89a6cc1ad0e1dd5db4bf155d5a80620",
        "ID": "c2f8178ce89a6cc1ad0e1dd5db4bf155d5a80620",
        "Title": "A Video Event Detection and Mining Framework",
        "Abstract": "We present a video event mining framework that consists of comprehensive set of tools for event detection, annotation, content browsing and a video analysis database. Central to our framework is the video analysis database and the VideoViews database browser that supports both top-down and bottom-up analysis of the video data. to support event mining. We present two methods for video event detection, namely an expert system (CLIPS) rules based approach and a 2-level Hidden Markov Model built\u2026\u00a0",
        "Publication Year": "16 June 2003",
        "Citation Count": "18",
        "Reference Count": "15",
        "Authors": [
            "Sadiye Guler",
            "Winnie H. Liang",
            "Ian A. Pushee"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ecab8d10ca24b53eca2bf1580e8cd03fe7984676",
            "1bfe26fac93ad96c81cf1a580b9e7744477f56aa",
            "518597d91ed49c28f5cf3f0a0b05609568b7e084",
            "bc4b948b1a0f91525bc3d47e9e192b392bf790ed",
            "3ff52ba9498b2ac084c9d8bbf637c343679df402",
            "87cc226aa060db976fbf6ac3a07969b33b544b96",
            "824aac4970a4d149b35c19a9d2d2dec4c994688e",
            "18b02beb27288f6bd9d4376ca41e70655a698084",
            "1c99600451dedd42dcdc02ed6cfcaa81e70e9899",
            "9fd7f3022db657ef5e9619209962e5525ffdce4e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Color-transfer-based-on-multiscale-gradient-aware-Su-Deng/24dccf31b0347d138cdca66d71d9cb264e7498b1",
        "ID": "24dccf31b0347d138cdca66d71d9cb264e7498b1",
        "Title": "Color transfer based on multiscale gradient-aware decomposition and color distribution mapping",
        "Abstract": "Automatic global color transfer is a challenging problem in image editing. In this paper, we propose a novel color transfer method, which is based on the gradient-aware decomposition and the color distribution mapping. Firstly, a gradient-aware decomposition model is established to separate the target image into the base and detail layers. Then, the colors of each separated base layer are enforced to match those of a given reference image by Pitie's multi-dimensional probability density\u2026\u00a0",
        "Publication Year": "29 October 2012",
        "Citation Count": "7",
        "Reference Count": "17",
        "Authors": [
            "Zhuohan Su",
            "Daiguo Deng",
            "Xue Yang",
            "Xiaonan Luo"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "93b26a24b0b6cc4a92232874f04c75bc8f44c84b",
            "7fd89d13508e4bba173eaf08f71ba2fa86e3e5ca",
            "53fc0415e0d00f9691994a49b8232a1cc2dfad5f",
            "7c2517f714a9015cf1673f9f7d2e024cb2be7230",
            "85683b702e59eddacef2d3fd82c9deab0b26ba8f",
            "6fe1789ca63598aec095df3c57c9607ac3b46dc7",
            "9a200182547f0b761e29258fa2459f63b5b64e2e",
            "fe2dcdb4c39fd519c7a44bb29a7655237475f91f",
            "787874fedd7384be5b04530bf9334cb58e0c1bd1",
            "000b9a90bbea62e4222704c616c0c2ee65609aa7"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/PRINCIPAL-COLOR-AND-ITS-APPLICATION-TO-COLOR-IMAGE-Abadpour-Kasaei/be6a3fb065281fe3f27bd99d61ef28e41635e575",
        "ID": "be6a3fb065281fe3f27bd99d61ef28e41635e575",
        "Title": "PRINCIPAL COLOR AND ITS APPLICATION TO COLOR IMAGE SEGMENTATION",
        "Abstract": "Color image segmentation is a primitive operation in many image processing and computer \nvision applications. Accordingly, there exist numerous segmentation approaches in the literature, \nwhich might be misleading for a researcher who is looking for a practical algorithm. While many \nresearchers are still using the tools which belong to the old color space paradigm, there is evidence \nin the research established in the eighties that a proper descriptor of color vectors should act \nlocally in\u2026\u00a0",
        "Publication Year": "1 April 2008",
        "Citation Count": "6",
        "Reference Count": "21",
        "Authors": [
            "Arash Abadpour",
            "Shohreh Kasaei"
        ],
        "Related Topics": [
            "Mathematics"
        ],
        "References": [
            "2139c25553efc916c57fa98f9204105b56ece75d",
            "a2882b8b0c9635d39d15a28138e3f47907f3177b",
            "0c2ced886708cc3aea4705f8765d152cd3f69cd2",
            "05f63bdf9e60d0a299cfe5e8d7ba043904f1fea1",
            "fa4dce7d484da0d91d872261e0c41006521e732f",
            "53fc0415e0d00f9691994a49b8232a1cc2dfad5f",
            "1e48105dd2b6d4a21be627040fa6e2074a576bef",
            "d7c0b4473110541613c91fed2bc11c0def55b8f1",
            "1186c8e998b2a1c3dd87e55400929d753877bd19",
            "a34c9af1897c779be9aee293ac43e1dca097a33c"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Survey-on-Color-Transfer-Methods-Alappatt-Paul/44175dc6641b3a389a81bd457d4d4deb7d5d3e08",
        "ID": "44175dc6641b3a389a81bd457d4d4deb7d5d3e08",
        "Title": "A Survey on Color Transfer Methods",
        "Abstract": "Color mapping or color transfer methods aim to recolor a given image or video by deriving a mapping between that image and another image serving as a reference. This class of methods has received considerable attention in recent years, both in academic literature and in industrial applications. Methods for recoloring images have often appeared under the labels of color correction, color transfer or color balancing, to name a few, but their goal is always the same: mapping the colors of one\u2026\u00a0",
        "Publication Year": "2016",
        "Citation Count": "One",
        "Reference Count": "24",
        "Authors": [
            "Evline J Alappatt",
            "Vince Paul"
        ],
        "Related Topics": [
            "Art"
        ],
        "References": [
            "93b26a24b0b6cc4a92232874f04c75bc8f44c84b",
            "54e8f504c3fc6b8e8e27c9a9cd7285698272c81d",
            "40d1e1f71c50d20690784be9ebdeff02552adb1a",
            "53fc0415e0d00f9691994a49b8232a1cc2dfad5f",
            "aa7df77672b87debed9683e6c831d83bc757e853",
            "85683b702e59eddacef2d3fd82c9deab0b26ba8f",
            "7d88404adf4cd7be5c80f540b0ffd957e24bea6a",
            "61d0af20ad1d80a453f87dba8d1f791fbff8c10c",
            "fe2dcdb4c39fd519c7a44bb29a7655237475f91f",
            "e0bd9ee4f46589a7c731a4e6bbbecda3f6d21479"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Dark-Image-Enhancement-Using-Perceptual-Color-Cepeda-Negrete-S%C3%A1nchez-Y%C3%A1%C3%B1ez/a53b9a81fc16016355975215fd9d130c08c441ab",
        "ID": "a53b9a81fc16016355975215fd9d130c08c441ab",
        "Title": "Dark Image Enhancement Using Perceptual Color Transfer",
        "Abstract": "In this paper, we introduce an image enhancing approach for transforming dark images into lightened scenes, and we evaluate such method in different perceptual color spaces, in order to find the best-suited for this particular task. Specifically, we use a classical color transfer method where we obtain first-order statistics from a target image and transfer them to a dark input, modifying its hue and brightness. Two aspects are particular to this paper, the application of color transfer on dark\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "17",
        "Reference Count": "53",
        "Authors": [
            "Jonathan Cepeda-Negrete",
            "Ra{\\&#x27;u}l Enrique S{\\&#x27;a}nchez-Y{\\&#x27;a}{\\~n}ez",
            "Fernando E. Correa-Tome",
            "Rocio A. Lizarraga-Morales"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "17b0873bab6b5fe7e3203c22514c2b418524529d",
            "562255ae115492717da2ce486e913c0a3d24d187",
            "5c054c99a59f9db3f06dc43ff8b77140876af7a2",
            "ab9fae8f69ec117d74218365352025bc82400a9f",
            "5f2586556999e9d7ec3b79a54adc0c41208edf9c",
            "3584d31719ab35db9d9cbe5353f069bea1b9ad9d",
            "7e8f44a0298ebfe8020e385a8f3f5d1a239cffdd",
            "d5986548cac9950f6837e71272da94e9178b9618",
            "6327caf546ef6e47b9b05735cc5ec572733cb756",
            "24295f6dfa2f2d1b32faf3548f49e86539af1d12"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Color-fusion-algorithm-for-visible-and-infrared-on-Wang-Shi/c4e047007c9ca9c1755698442bc2fe1f211a2922",
        "ID": "c4e047007c9ca9c1755698442bc2fe1f211a2922",
        "Title": "Color fusion algorithm for visible and infrared images based on color transfer in YUV color space",
        "Abstract": "Color fusion algorithm for visible and infrared(IR) images based on color transfer in YUV color space under trees, lawn, or land background is presented. Considering the red color will alert observers to possible interested target or danger, this paper aims at working on an algorithm that emphasizes hot targets in IR image with intense red, and the background details in visible image present natural color similar to a color day-time image. V component of YUV space represents the difference\u2026\u00a0",
        "Publication Year": "15 November 2007",
        "Citation Count": "17",
        "Reference Count": "16",
        "Authors": [
            "Lingxue Wang",
            "Shiming Shi",
            "Weiqi Jin",
            "Yuanmeng Zhao"
        ],
        "Related Topics": [
            "Physics"
        ],
        "References": [
            "746d5ec819b74c0d59a8be42fc8823235e1bcd75",
            "787effd0978356f963ee2c69fbb96860d4ca5c1e",
            "53fc0415e0d00f9691994a49b8232a1cc2dfad5f",
            "f6866aaea2ead5c75df22ecc66a0484732aef2be",
            "b097c6544ab28e5f4b3ec42fd0b8a95d4b0f6ad5",
            "a6f488da1048492128fb2b931e4ff2a8eb68e654",
            "9459e29a00dd8697bbc73d77d6aa37410889783a",
            "27ac80fee3d770f3fdf1088a8a07b67ae711ffdc",
            "66dd57213790aac7bcf6d2f3422f2bd93491025c",
            "4866151c742245ddefe5a5a464cc173d4d50c4cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Optimizing-color-transfer-using-color-similarity-Chen-Huang/b98e227f6fd632c95806828116378d04782bac24",
        "ID": "b98e227f6fd632c95806828116378d04782bac24",
        "Title": "Optimizing color transfer using color similarity measurement",
        "Abstract": "Color transfer algorithms alter the color appearance in the source image by borrowing colors from the target image. In this paper, we present a simple yet effective generalized color transfer algorithm, taking into consideration the influences contributed from both the source and target images. We introduce the Gaussian membership function as our first color similarity measurement. This function aims at balancing the degree of similarity of color distributions between source and resultant\u2026\u00a0",
        "Publication Year": "1 June 2016",
        "Citation Count": "2",
        "Reference Count": "33",
        "Authors": [
            "Wei-Sung Chen",
            "Ming-Long Huang",
            "Chung-Ming Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "8de9fd36e1fe69466cc76a82b7a432dc2eb10861",
            "10fb269f1121e958631e402a99d006d9e20b35ca",
            "7e8f44a0298ebfe8020e385a8f3f5d1a239cffdd",
            "eb55a884b2bc117480d2c376111ac70d610d83e1",
            "54e8f504c3fc6b8e8e27c9a9cd7285698272c81d",
            "22c5a5c9031f8f1464b9a88eef99e500f744903e",
            "7071b4af499486757cce6f687d158b0f1260ac4e",
            "c0afe85ed91447dee1811f5a825eeb407919a974",
            "53fc0415e0d00f9691994a49b8232a1cc2dfad5f",
            "6f1d7d584b39b423151488832b98880c6c7391cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-optimized-region-based-color-transfer-method-for-Zaveri-Zaveri/e9be22d7ec8756c432729b2c21c1bec911fbdc4c",
        "ID": "e9be22d7ec8756c432729b2c21c1bec911fbdc4c",
        "Title": "An optimized region-based color transfer method for night vision application",
        "Abstract": "Modern night-vision systems like image intensifiers and thermal cameras enable operations at night and in adverse weather conditions. Modern night vision camera provides false-colored fused image as an output which is unnatural in appearance and it is therefore hard to interpret. In this paper, a region-based natural color mapping method for night vision imagery is presented. The proposed method colorizes the night vision imagery by using a combined framework consisting of hill-climbing\u2026\u00a0",
        "Publication Year": "1 December 2010",
        "Citation Count": "8",
        "Reference Count": "20",
        "Authors": [
            "Tanish Hemalbhai Zaveri",
            "Mukesh A. Zaveri",
            "Ishit Makwana",
            "Harshit Mehta"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2ad3927e656867ecb47c694b3197806b1143faa7",
            "ff85aa39c86b57e045e045537ac32813522375fd",
            "d5986548cac9950f6837e71272da94e9178b9618",
            "6327caf546ef6e47b9b05735cc5ec572733cb756",
            "45816243ca4f26be099e14d09744a7d906e8b5c9",
            "5deb3a34a773e9a620eee09136a163fd4c253ee3",
            "05f62d07ad886cb9b7beea3da28ea807cb67160f",
            "9b80d7498e1197870e72da035c8079a76d3e58a6",
            "53fc0415e0d00f9691994a49b8232a1cc2dfad5f",
            "d5c6edb53dc41f298f145041cd2c53e40e3acf2b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/New-Principle-Component-Analysis-Based-Colorizing-Abadpour-Kasaei/d93e4e77e2baba98f1af7f23d47fbf9b46be4df5",
        "ID": "d93e4e77e2baba98f1af7f23d47fbf9b46be4df5",
        "Title": "New Principle Component Analysis Based Colorizing Method",
        "Abstract": "Although many modern imaging systems are still producing grayscale images, colored-images are more preferred for the larger amount of information they are carrying. Computing the grayscale representation of a color image is a straightforward task, while the inverse problem has no objective solution. The search through out literature has not revealed much history of the past works. In this paper, after a brief review of related research, a new dimensionreduction method is proposed for natural\u2026\u00a0",
        "Publication Year": "5 November 2004",
        "Citation Count": "6",
        "Reference Count": "18",
        "Authors": [
            "Arash Abadpour",
            "Shohreh Kasaei"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d5c6edb53dc41f298f145041cd2c53e40e3acf2b",
            "ab67b9d0da50e251a4f7e42370540547b891ceb1",
            "b5bd72d8bc9f51dae65c15842f0ab443c3b437e3",
            "cc470d34b6d76518ef4435b627ba1ec01ac55c03",
            "95a057bf3b2b7af6778e30847ad8177191ec43c9",
            "3cf04e19e55cf6d2d18157c136885a042ab578d1",
            "577d19a115f9ef6f002483fcf88adbb3b5479556",
            "8d946c3eb1d1db376a89ad9342282163b5ae0930",
            "1061dea79f8c5e55bf11f7873b9de109c51cbc67",
            "f3a11158e9d8bdfdf07dca756335c084fce0123e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-new-FPCA-based-fast-segmentation-method-for-color-Abodpour-Kasaei/0c2ced886708cc3aea4705f8765d152cd3f69cd2",
        "ID": "0c2ced886708cc3aea4705f8765d152cd3f69cd2",
        "Title": "A new FPCA-based fast segmentation method for color images",
        "Abstract": "Fuzzy objective function-based clustering methods are proved to be fast tools for classification and segmentation purposes. Unfortunately, most of the available fuzzy clustering methods are using the spherical or ellipsoidal distances, which are proved to result in spurious clusters, when working on color data. In this paper, a general case of clustering is discussed and a general method is proposed and its convergence is proved. Also, it is proved that the FCM and the FCV methods are special\u2026\u00a0",
        "Publication Year": "18 December 2004",
        "Citation Count": "12",
        "Reference Count": "41",
        "Authors": [
            "A. Abodpour",
            "Shohreh Kasaei"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "5ac1bbc582e591e2560d1a3167f30fd5a9073b25",
            "2377b94096298613d0f06f7c8110a5303bc09f53",
            "4debea4d29ca203433c830a1dd1c0c1bb4828b6c",
            "253b74d147ba829b9b1926c478815f1d904f9e36",
            "1186c8e998b2a1c3dd87e55400929d753877bd19",
            "1380bcf86538fef43dd2356d71b64523867b58c0",
            "a34c9af1897c779be9aee293ac43e1dca097a33c",
            "d738b2654fcdc4569d036fbd958b8151eab4ba19",
            "fd3828d1465baf3719195ad98971fad66162ce67",
            "989af4dd904c1958e5f9a6f08f70572259303425"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Color-Segmentation-Based-on-Separate-Anisotropic-of-Lucchese-Mitra/4a6c5c9b1fb106f7d82508ae593d30e207c8ea45",
        "ID": "4a6c5c9b1fb106f7d82508ae593d30e207c8ea45",
        "Title": "Color Segmentation Based on Separate Anisotropic Diffusion of Chromatic and Achromatic Channels",
        "Abstract": "The paper presents a new technique for segmenting images only on the basis of colour information. It is shown how segmentation can benefit from splitting colour signals into chromatic and achromatic channels and separately smoothing them through anisotropic diffusion. Operatively, this is accomplished through two independent diffusion processes: one involves only the chromatic information, conveniently embedded in a complex function, while the other affects the lightness information. The\u2026\u00a0",
        "Publication Year": "1 June 2001",
        "Citation Count": "34",
        "Reference Count": "31",
        "Authors": [
            "Luca Lucchese",
            "Sanjit K. Mitra"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "251a7ee2ecd78aff6e83318c92b01a55bf6a762f",
            "f566985a7df1dcd6af66b019a50338aeea5f1cf2",
            "496c3d75b81b336411e53da1ac632a8139655604",
            "3a15aa74d7db2004b8895ee822170231f95a0b6c",
            "674285f115841d8a237a68e55b4e651cc558bf9d",
            "fa4dce7d484da0d91d872261e0c41006521e732f",
            "8854a69749b2a02afbf880a413f77988eaacbfde",
            "e9e42f0079b6d9ab86857e418a7d5157e381928a",
            "d077f1a275c922e288cda1e3fa949154316503cf",
            "a9b9866314054a7c8386bd44362e9034a0690007"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/GRAYSCALE-IMAGE-MATTING-AND-COLORIZATION-Chen-Wang/ed7e166f65bcecc522c6c4bbb29fcf8048010873",
        "ID": "ed7e166f65bcecc522c6c4bbb29fcf8048010873",
        "Title": "GRAYSCALE IMAGE MATTING AND COLORIZATION",
        "Abstract": "This paper presents a novel approach to grayscale image matting and colorization. The first part of this approach is an efficient grayscale image matting algorithm in Bayesian framework. The foreground and background color distributions, and the alpha\u2019s distribution are modelled with spatially varying sets of Gaussians. The major novelties of this matting algorithm are the introduction of alpha\u2019s distribution and gradient into the Bayesian framework and an efficient optimization scheme. This\u2026\u00a0",
        "Publication Year": "2004",
        "Citation Count": "63",
        "Reference Count": "18",
        "Authors": [
            "Tongbo Chen",
            "Yan Wang",
            "Volker Schillings",
            "Christoph Meinel"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d5c6edb53dc41f298f145041cd2c53e40e3acf2b",
            "03b2a8c90b9e5068bb05bfc885588e647f97356d",
            "61a1c4ae4dbc182e2923c495339466bb0812f53d",
            "8fd18a0f65134b1abfbb1adf8653ebba63bb2c0e",
            "923562d216386a88947d40da310d94bbb1376a41",
            "46c20018841c0ae8226e7cb5d7107ff30742f8f5",
            "41093fe0f19cb37b239a62adb5f2c0cd058fec83",
            "64ce3c02fde4157458d84b977dc74a3bd7eda50d",
            "ec5ece85d618d71bffa9e6d655fe2f38416a4e9d",
            "69a28cf71d454b06eed2aed3c7a48114ea969455"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Adaptive-exploitation-of-pre-trained-deep-neural-Marvasti-Zadeh-Ghanei-Yakhdan/3aaf88163e9e502daf5be57917470c30c63da6a6",
        "ID": "3aaf88163e9e502daf5be57917470c30c63da6a6",
        "Title": "Adaptive exploitation of pre-trained deep convolutional neural networks for robust visual tracking",
        "Abstract": "Due to the automatic feature extraction procedure via multi-layer nonlinear transformations, the deep learning-based visual trackers have recently achieved a great success in challenging scenarios for visual tracking purposes. Although many of those trackers utilize the feature maps from pre-trained convolutional neural networks (CNNs), the effects of selecting different models and exploiting various combinations of their feature maps are still not compared completely. To the best of our\u2026\u00a0",
        "Publication Year": "29 August 2020",
        "Citation Count": "3",
        "Reference Count": "70",
        "Authors": [
            "Seyed Mojtaba Marvasti-Zadeh",
            "Hossein Ghanei-Yakhdan",
            "Shohreh Kasaei"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0",
            "1131c53b9baaa740a4deef4c1282821b23d18687",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "511b6263795b8921e9f980b0ac7be5f6282337f6",
            "4b39e8494cf031b2b87c6bd5c65c2a2dfb02c531",
            "5c8a6874011640981e4103d120957802fa28f004",
            "503bafe063e410050c174fcc741e39b3b1e0eb22",
            "f233c16a87d518bfe9f923ea7af48ed3eb6bb7d5",
            "26e2ca763087be09e3799ad294302aa91077942d",
            "ed84a17bd753d1ba9404131cff5186db4da6edd8"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Siamese-Attentional-Cascade-Keypoints-Network-for-Wang-Wang/45bde350082fe5ee366c8f1b761429d2277fbcca",
        "ID": "45bde350082fe5ee366c8f1b761429d2277fbcca",
        "Title": "Siamese Attentional Cascade Keypoints Network for Visual Object Tracking",
        "Abstract": "Visual object tracking is urgent yet challenging work since it requires the simultaneous and effective classification and estimation of a target. Thus, research on tracking has been attracting a considerable amount of attention despite the limitations of existing trackers owing to deformation, occlusion and motion. For most current tracking methods, researchers have proposed various ways to adopt a multi-scale search or anchors for estimation, but these methods always need prior knowledge and\u2026\u00a0",
        "Publication Year": "2021",
        "Citation Count": "4",
        "Reference Count": "78",
        "Authors": [
            "Ershen Wang",
            "Donglei Wang",
            "Yufeng Huang",
            "Gang Tong",
            "Song Xu",
            "Tao Pang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "fce3655dc22a783b1f82f09190410f070c7bf42c",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "6683442ae358ae4261fdcde0164f83dd1ccd621b",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "4b1965a54a064ac9145b1ce404fe33f0120c8ae3",
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "93874b197f48562fc410b3c351edb9f26da8c123",
            "1fbb4201af091aef55360f113ba35814063923e4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Improving-Object-Tracking-by-Added-Noise-and-Fiaz-Mahmood/93742493c26652d4a95627de699869795698a554",
        "ID": "93742493c26652d4a95627de699869795698a554",
        "Title": "Improving Object Tracking by Added Noise and Channel Attention",
        "Abstract": "CNN-based trackers, especially those based on Siamese networks, have recently attracted considerable attention because of their relatively good performance and low computational cost. For many Siamese trackers, learning a generic object model from a large-scale dataset is still a challenging task. In the current study, we introduce input noise as regularization in the training data to improve generalization of the learned model. We propose an Input-Regularized Channel Attentional Siamese (IRCA\u2026\u00a0",
        "Publication Year": "1 July 2020",
        "Citation Count": "5",
        "Reference Count": "81",
        "Authors": [
            "Mustansar Fiaz",
            "A. Mahmood",
            "Ki Yeol Baek",
            "Sehar Shahzad Farooq",
            "Soon Ki Jung"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "e085fb462789a8bca7933b5e1c7e9aa0ded8a711",
            "fdb98f5a7015de0956ef8d4e468257dc3079b5e5",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "6683442ae358ae4261fdcde0164f83dd1ccd621b",
            "5cc27ba9ea61c3240eb249fc9b56dd42b7fb86e3",
            "deaaa383bb9291bc77a70a22b70d2683673ba76f",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "e972436110b4f2c102d938311beff98ece7b6da7",
            "09769e80cdf027db32a1fcb695a1aa0937214763"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/COMET%3A-Context-Aware-IoU-Guided-Network-for-Small-Marvasti-Zadeh-Khaghani/842451bbece5958301283c9398139130643dcb73",
        "ID": "842451bbece5958301283c9398139130643dcb73",
        "Title": "COMET: Context-Aware IoU-Guided Network for Small Object Tracking",
        "Abstract": "We consider the problem of tracking an unknown small target from aerial videos of medium to high altitudes. This is a challenging problem, which is even more pronounced in unavoidable scenarios of drastic camera motion and high density. To address this problem, we introduce a context-aware IoU-guided tracker (COMET) that exploits a multitask two-stream network and an offline reference proposal generation strategy. The proposed network fully exploits target-related information by multi-scale\u2026\u00a0",
        "Publication Year": "4 June 2020",
        "Citation Count": "15",
        "Reference Count": "79",
        "Authors": [
            "Seyed Mojtaba Marvasti-Zadeh",
            "Javad Khaghani",
            "Hossein Ghanei-Yakhdan",
            "Shohreh Kasaei",
            "Li Cheng"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "7f75d4b462bd883f290461cdd8984f8cee6013ea",
            "65c9b4b1d49f46b3f8f64a5f617acfc14f85d031",
            "27d52bf3265bea0f9929980f6ffb4c2009eecfee",
            "43eb56d0dfdb1d5c78a0d2acb43b436f2d5c4ecf",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "456b8ae5dd6f8316c1fda46c5a8b4204c10ae320",
            "243cfd8867ce54ab3f1291489ac5fb0e7bcff554"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/CRACT%3A-Cascaded-Regression-Align-Classification-for-Fan-Ling/6e0442456b3a475e1d836d7e345fdce98ef5ad26",
        "ID": "6e0442456b3a475e1d836d7e345fdce98ef5ad26",
        "Title": "CRACT: Cascaded Regression-Align-Classification for Robust Visual Tracking",
        "Abstract": "High quality object proposals are crucial in visual tracking algorithms that utilize region proposal network (RPN). Refinement of these proposals, typically by box regression and classification in parallel, has been popularly adopted to boost tracking performance. However, it still meets problems when dealing with complex and dynamic background. Thus motivated, in this paper we introduce an improved proposal refinement module, Cascaded Regression-Align-Classification (CRAC), which yields new\u2026\u00a0",
        "Publication Year": "25 November 2020",
        "Citation Count": "5",
        "Reference Count": "57",
        "Authors": [
            "Heng Fan",
            "Haibin Ling"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "738165f33c50b059e87b14d8b4a129230e14eacd",
            "cce1fecc800d2782da638f3060d5b2e887739f74",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "f98be9a91dbf00b52a494720bd36be9c73a1210e",
            "2088d93e7f4fa27b8498428d2ed64f144ab8cf3e",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "059282edacac41b220f295b5ee1d376aa19871d8"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Multiple-Pedestrians-and-Vehicles-Tracking-in-A-Azimi-Kraus/005da5074bada2c7fa81ba3ecd9be2721b1d69a2",
        "ID": "005da5074bada2c7fa81ba3ecd9be2721b1d69a2",
        "Title": "Multiple Pedestrians and Vehicles Tracking in Aerial Imagery: A Comprehensive Study",
        "Abstract": "In this paper, we address various challenges in multi-pedestrian and vehicle tracking in high-resolution aerial imagery by intensive evaluation of a number of traditional and Deep Learning based Single- and Multi-Object Tracking methods. We also describe our proposed Deep Learning based Multi-Object Tracking method AerialMPTNet that fuses appearance, temporal, and graphical information using a Siamese Neural Network, a Long Short-Term Memory, and a Graph Convolutional Neural Network module for\u2026\u00a0",
        "Publication Year": "19 October 2020",
        "Citation Count": "2",
        "Reference Count": "76",
        "Authors": [
            "Seyed Majid Azimi",
            "Maximilian Kraus",
            "Reza Bahmanyar",
            "Peter Reinartz"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "1fbb4201af091aef55360f113ba35814063923e4",
            "3227b933d917c73902746ac2c36a72927064a3c0",
            "58cf45b4c1bc070535c2f3c1004b2fdc6fe8c907",
            "65a7aca24d6358b3e57368688856a10833ecd062",
            "719b816653c43cd0b0298d1092bb1479a1049fdb",
            "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "7ba993bc50efa96fa36e9704c1e5190d5815b1bb",
            "c70d7dd6c4c9a7a091b76d9d94b5d122a4179e8c",
            "e5f68e7af6fff8b9a73ba58d5258fcf9437fa08a",
            "894252730324f233b474bae1d6fe0b77d988ae83"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Towards-Accurate-Pixel-wise-Object-Tracking-by-Zhang-Li/171c292989d4d34163b59bd5e5cc1a383db9c0ab",
        "ID": "171c292989d4d34163b59bd5e5cc1a383db9c0ab",
        "Title": "Towards Accurate Pixel-wise Object Tracking by Attention Retrieval",
        "Abstract": "The encoding of the target in object tracking moves from the coarse bounding-box to fine-grained segmentation map recently. Revisiting de facto real-time approaches that are capable of predicting mask during tracking, we observed that they usually fork a light branch from the backbone network for segmentation. Although efficient, directly fusing backbone features without considering the negative influence of background clutter tends to introduce false-negative predictions, lagging the\u2026\u00a0",
        "Publication Year": "6 August 2020",
        "Citation Count": "7",
        "Reference Count": "55",
        "Authors": [
            "Zhipeng Zhang",
            "Bing Li",
            "Weiming Hu",
            "Houwen Peng"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "842b24b04ef2b142d655c7b50cd6ab0835d89330",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "1190e0210430e8b743af24cdc43efdeef407b669",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "27d52bf3265bea0f9929980f6ffb4c2009eecfee",
            "ccb9ffa26b28dffc4f7d613821d1a9f0d60ea3f4",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "d710777495f51144c5b9f0a7372d16e3843e1b25"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Long-Term-Tracking-With-Dai-Zhang/adacccd99a42c3145ec6392a1a6b08878376e38b",
        "ID": "adacccd99a42c3145ec6392a1a6b08878376e38b",
        "Title": "High-Performance Long-Term Tracking With Meta-Updater",
        "Abstract": "Long-term visual tracking has drawn increasing attention because it is much closer to practical applications than short-term tracking. Most top-ranked long-term trackers adopt the offline-trained Siamese architectures, thus,they cannot benefit from great progress of short-term trackers with online update. However, it is quite risky to straightforwardly introduce online-update-based trackers to solve the long-term problem, due to long-term uncertain and noisy observations. In this work, we\u2026\u00a0",
        "Publication Year": "1 April 2020",
        "Citation Count": "118",
        "Reference Count": "55",
        "Authors": [
            "Kenan Dai",
            "Yunhua Zhang",
            "Dong Wang",
            "Jianhua Li",
            "Huchuan Lu",
            "Xiaoyun Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "50c60583dc0ef09484358deab329f82ee22c2b66",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "383e67e0de2fdac787976543ba38bada48d046fc",
            "834baad9db5a1de1bfe993ff4a55a8a957eb9e0a",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Real-Time-Deep-Tracking-via-Corrective-Domain-Li-Wang/021d0c7013da519b508610064f264c76d768fdf1",
        "ID": "021d0c7013da519b508610064f264c76d768fdf1",
        "Title": "Real-Time Deep Tracking via Corrective Domain Adaptation",
        "Abstract": "Visual tracking is one of the fundamental problems in computer vision. Recently, some deep-learning-based tracking algorithms have been illustrating record-breaking performances. However, due to the high complexity of neural networks, most deep trackers suffer from low tracking speed and are, thus, impractical in many real-world applications. Some recently proposed deep trackers with smaller network structure achieve high efficiency while at the cost of significant decrease in precision. In\u2026\u00a0",
        "Publication Year": "19 June 2019",
        "Citation Count": "12",
        "Reference Count": "44",
        "Authors": [
            "Hanxi Li",
            "Xinyu Wang",
            "Fumin Shen",
            "Yi Li",
            "Fatih Murat Porikli",
            "Mingwen Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2ac7ab669a56af6ada5cc1459f2c7e93dcdb025a",
            "b2180fc4f5cb46b5b5394487842399c501381d67",
            "f24015a365ea2454391c285cd30b8ae723dbb05e",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "2e195a4edeae8d6be0885d7fd9cb7c70f365a326",
            "1b3a107739e7f7e05c50999a3d79b8225746f662",
            "9cf3c67529085d31c646091b97be1a1e3dc191f2",
            "e3c433ab9608d7329f944552ba1721e277a42d74",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-In-Depth-Analysis-of-Visual-Tracking-with-Neural-Pflugfelder/0a400fd7f0ee28694889baaa4faef150b6912dfa",
        "ID": "0a400fd7f0ee28694889baaa4faef150b6912dfa",
        "Title": "An In-Depth Analysis of Visual Tracking with Siamese Neural Networks",
        "Abstract": "This survey presents a deep analysis of the learning and inference capabilities in nine popular trackers. It is neither intended to study the whole literature nor is it an attempt to review all kinds of neural networks proposed for visual tracking. We focus instead on Siamese neural networks which are a promising starting point for studying the challenging problem of tracking. These networks integrate efficiently feature learning and the temporal matching and have so far shown state-of-the-art\u2026\u00a0",
        "Publication Year": "3 July 2017",
        "Citation Count": "17",
        "Reference Count": "129",
        "Authors": [
            "Roman P. Pflugfelder"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "388d29f001411ff80650f80cf197afc440d98b51",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "26e2ca763087be09e3799ad294302aa91077942d",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "b2180fc4f5cb46b5b5394487842399c501381d67",
            "ca302b4d7e2d50cb4a4970b78fc237a1294ade40",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "5b4b43f10c5779d67ccee15d8d0be10ed036971b",
            "a3a4471e82260f573d240cc34aeff431cf236571",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Good-Features-to-Correlate-for-Visual-Tracking-Gundogdu-Alatan/388d29f001411ff80650f80cf197afc440d98b51",
        "ID": "388d29f001411ff80650f80cf197afc440d98b51",
        "Title": "Good Features to Correlate for Visual Tracking",
        "Abstract": "During the recent years, correlation filters have shown dominant and spectacular results for visual object tracking. The types of the features that are employed in this family of trackers significantly affect the performance of visual tracking. The ultimate goal is to utilize the robust features invariant to any kind of appearance change of the object, while predicting the object location as properly as in the case of no appearance change. As the deep learning based methods have emerged, the\u2026\u00a0",
        "Publication Year": "20 April 2017",
        "Citation Count": "150",
        "Reference Count": "73",
        "Authors": [
            "Erhan Gundogdu",
            "A. Aydin Alatan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "5404718135548b01516a668e0c022c5cb22b422e",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "1b3a107739e7f7e05c50999a3d79b8225746f662",
            "5c8a6874011640981e4103d120957802fa28f004",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "f5dbe4550d24d5374d9e10fce44a35b105c7ee07",
            "084bd219dd239dc4c9a02621a5333d3bc1446566",
            "000178cd12c8a6e5da8215b6365fae03c20fd18d",
            "b4035bb1dc4514a72f069d911011ab5845ca1591"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Deep-tracking-with-objectness-Wang-Li/f24015a365ea2454391c285cd30b8ae723dbb05e",
        "ID": "f24015a365ea2454391c285cd30b8ae723dbb05e",
        "Title": "Deep tracking with objectness",
        "Abstract": "Visual tracking is a fundamental problem in computer vision. However, due to the (sometimes) ambiguous target information given at the first frame, it has also been criticized as less well-posed compared with other tasks with clearly-defined targets, such as object detection and semantic segmentation. In this paper, we try to evaluate the importance of object category in visual tracking by tracking objects with known object types. The proposed algorithm, termed Deep-Track with Objectness (DTO\u2026\u00a0",
        "Publication Year": "1 September 2017",
        "Citation Count": "6",
        "Reference Count": "24",
        "Authors": [
            "Xinyu Wang",
            "Hanxi Li",
            "Yi Li",
            "Fatih Murat Porikli",
            "Mingwen Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b2180fc4f5cb46b5b5394487842399c501381d67",
            "5b9ace65f7368f6dc6907c8f6f7c3b0c248d9bc4",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "5c8a6874011640981e4103d120957802fa28f004",
            "421bf4eeba623f722bf98340d71e3d229881e92d",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "1b3a107739e7f7e05c50999a3d79b8225746f662",
            "9d57723b4908397654fb1846d37db403d8b2b56a",
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Learning-Dynamic-Siamese-Network-for-Visual-Object-Guo-Feng/7574b7e5a75fdd338c27af5aeb77ab79460c4437",
        "ID": "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
        "Title": "Learning Dynamic Siamese Network for Visual Object Tracking",
        "Abstract": "How to effectively learn temporal variation of target appearance, to exclude the interference of cluttered background, while maintaining real-time response, is an essential problem of visual object tracking. Recently, Siamese networks have shown great potentials of matching based trackers in achieving balanced accuracy and beyond realtime speed. However, they still have a big gap to classification & updating based trackers in tolerating the temporal changes of objects and imaging conditions. In\u2026\u00a0",
        "Publication Year": "1 October 2017",
        "Citation Count": "610",
        "Reference Count": "36",
        "Authors": [
            "Qing Guo",
            "Wei Feng",
            "Ce Zhou",
            "Rui Huang",
            "Liang Wan",
            "Song Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "5c8a6874011640981e4103d120957802fa28f004",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "0f12a3aaf3851078d93a9bba4e3ebece6d4bcfe5",
            "3dc60732c1c08165c9d4e7b334ce66e511474bb2",
            "3d5fe9ef560c08f0c56249360247c7d4b40ce023",
            "c46b08850b9c458704a3ca69172e6a0d40a6cb7f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Visual-Tracking-with-Siamese-Li-Yan/320d05db95ab42ade69294abe46cd1aca6aca602",
        "ID": "320d05db95ab42ade69294abe46cd1aca6aca602",
        "Title": "High Performance Visual Tracking with Siamese Region Proposal Network",
        "Abstract": "Visual object tracking has been a fundamental topic in recent years and many deep learning based trackers have achieved state-of-the-art performance on multiple benchmarks. However, most of these trackers can hardly get top performance with real-time speed. In this paper, we propose the Siamese region proposal network (Siamese-RPN) which is end-to-end trained off-line with large-scale image pairs. Specifically, it consists of Siamese subnetwork for feature extraction and region proposal\u2026\u00a0",
        "Publication Year": "1 June 2018",
        "Citation Count": "1,566",
        "Reference Count": "41",
        "Authors": [
            "Bo Li",
            "Junjie Yan",
            "Wei Wu",
            "Zheng Zhu",
            "Xiaolin Hu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "1131c53b9baaa740a4deef4c1282821b23d18687",
            "7ccbb845829234548bfa9b24c61297b4f0cd678e",
            "5404718135548b01516a668e0c022c5cb22b422e",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "dda27eb7ddc4510f94cac0e5134b5d56aa77b075",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Densely-Connected-Discriminative-Correlation-for-Peng-Liu/1855818c492d5f42dbe14814e4dd9b5733d54790",
        "ID": "1855818c492d5f42dbe14814e4dd9b5733d54790",
        "Title": "Densely Connected Discriminative Correlation Filters for Visual Tracking",
        "Abstract": "Discriminative Correlation Filters (DCFs)-based approaches have recently achieved competitive performance in visual tracking. However, such conventional DCF-based trackers often lack the discriminative ability due to the shallow architecture. As a result, they can hardly tackle drastic appearance variations and easily drift when the target suffers heavy occlusions. To address this issue, a novel densely connected DCFs framework is proposed for visual tracking. We incorporate multiple nested\u2026\u00a0",
        "Publication Year": "15 May 2018",
        "Citation Count": "3",
        "Reference Count": "41",
        "Authors": [
            "Cheng Peng",
            "Fanghui Liu",
            "Jie Yang",
            "Nikola K. Kasabov"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "49a5aeefcb257ca92652acf4f875efbad5a2b00d",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "5c8a6874011640981e4103d120957802fa28f004",
            "ece7625a346edbc5f6fab541c0c246ec06939121",
            "b16a583ee173f222c690242aaff7925838893fe8",
            "0cae491292feccbc9ad1d864cf8b7144923ce6de",
            "0f12a3aaf3851078d93a9bba4e3ebece6d4bcfe5",
            "096710211d9e4eb77dc2d0f11a7ff818c8acc5ff",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "000178cd12c8a6e5da8215b6365fae03c20fd18d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Tracking-via-Auto-Encoder-Pair-Correlation-Cheng-Zhang/e2e34b202363e4a46a14cd35fd4088d88b2e650e",
        "ID": "e2e34b202363e4a46a14cd35fd4088d88b2e650e",
        "Title": "Visual Tracking via Auto-Encoder Pair Correlation Filter",
        "Abstract": "Robust visual tracking is one of the most challenging problems in computer vision applications. However, the limited training data and the computational complexity have severely affected tracking performance. In this paper, we propose an auto-encoder pair model for visual tracking which is composed of source domain network and target domain network to help a more accurate localization. We adopt the dense circular samples of the object state to increase the number of training samples and prevent\u2026\u00a0",
        "Publication Year": "1 April 2020",
        "Citation Count": "14",
        "Reference Count": "54",
        "Authors": [
            "Xu Cheng",
            "Yifeng Zhang",
            "Lin Zhou",
            "Yuhui Zheng"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "b4035bb1dc4514a72f069d911011ab5845ca1591",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "6410c97ae03d356e14544c8e95f5367fb7ebb6e6",
            "b2180fc4f5cb46b5b5394487842399c501381d67",
            "6683442ae358ae4261fdcde0164f83dd1ccd621b",
            "7069a994c150b0228c4e471ca48ed55d7646bc62",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-term-Visual-Tracking%3A-Review-and-Experimental-Liu-Chen/2d4713ce1df60f771b65e900fd02352989df82ef",
        "ID": "2d4713ce1df60f771b65e900fd02352989df82ef",
        "Title": "Long-term Visual Tracking: Review and Experimental Comparison",
        "Abstract": "As a fundamental task in computer vision, visual object tracking has received much attention in recent years. Most studies focus on short-term visual tracking which addresses shorter videos and always-visible targets. However, long-term visual tracking is much closer to practical applications with more complicated challenges. There exists a longer duration such as minute-level or even hour-level in the long-term tracking task, and the task also needs to handle more frequent target disappearance\u2026\u00a0",
        "Publication Year": "7 November 2022",
        "Citation Count": "3",
        "Reference Count": "100",
        "Authors": [
            "Chang Liu",
            "Xiao-Fan Chen",
            "Chunjuan Bo",
            "Dong Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "23f8927f996d56f3b5076d8993a70bcfc70182a1",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "12508951ba96b7d4c0906ed95542287d3ebdfd95",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "1ae15ff20d54d9ffd2a45a9c124c77ad2b419ae3",
            "786577081e00d69eeac8e9612eaf2dad59765e73",
            "894e4376750b83b63649cc518b121f345ca0df83",
            "913cebc279c363fb9476496f096519e27212b3d5"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Switch-and-Refine%3A-A-Long-Term-Tracking-and-Xu-Zhao/ef61778d85357bdab8c71cf79cf5e0024f5b39c5",
        "ID": "ef61778d85357bdab8c71cf79cf5e0024f5b39c5",
        "Title": "Switch and Refine: A Long-Term Tracking and Segmentation Framework",
        "Abstract": "In long-term video object tracking (VOT) tasks, most long-term trackers are modified from short-term trackers, which contain more and more machine learning modules to improve their performance. However, we empirically find that more modules do not necessarily lead to better results. In this paper, we make the long-term tracking framework simple by carefully selecting the cutting-edge trackers. Specifically, we propose a new long-term VOT framework that combines the benefits of two mainstream\u2026\u00a0",
        "Publication Year": "1 March 2023",
        "Citation Count": "One",
        "Reference Count": "76",
        "Authors": [
            "Xiang Xu",
            "Jian Zhao",
            "Jianmin Wu",
            "Furao Shen"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "f1c9f81ce054619f30b5c27fd97579f7216d7048",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "f6186788541d332af19a96183787e01ef9080fb0",
            "3985382474245388bbc73e2c849e783010901775"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/CoCoLoT%3A-Combining-Complementary-Trackers-in-Visual-Dunnhofer-Micheloni/23409262ddcfc2f66fe999711a1fd9f7c700a1e2",
        "ID": "23409262ddcfc2f66fe999711a1fd9f7c700a1e2",
        "Title": "CoCoLoT: Combining Complementary Trackers in Long-Term Visual Tracking",
        "Abstract": "How to combine the complementary capabilities of an ensemble of different algorithms has been of central interest in visual object tracking. A significant progress on such a problem has been achieved, but considering short-term tracking scenarios. Instead, long-term tracking settings have been substantially ignored by the solutions. In this paper, we explicitly consider long-term tracking scenarios and provide a framework, named CoCoLoT, that combines the characteristics of complementary visual\u2026\u00a0",
        "Publication Year": "9 May 2022",
        "Citation Count": "2",
        "Reference Count": "47",
        "Authors": [
            "Matteo Dunnhofer",
            "Christian Micheloni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508",
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "bd4f219ce6bc5c22f9da71959d5192cf0b0141fe",
            "ca97f741f331b5b43d0577a46c05984f0785a8fa",
            "c734274f43575bc5f4bcf8719f0be55a5e89be5e",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "5b73cd259a3fa72f95e8bac9e520250b950acf3a",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "eb00b8453b23d4f6f142378e2fb0f0a9e6f9c5e2",
            "19d6b9725a59f4b624205829d5f03ac893ca1367"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Object-Tracking-in-First-Person-Vision-Dunnhofer-Furnari/c89da5aa9697ab9d5366353ec29b3e9c1b610469",
        "ID": "c89da5aa9697ab9d5366353ec29b3e9c1b610469",
        "Title": "Visual Object Tracking in First Person Vision",
        "Abstract": "The understanding of human-object interactions is fundamental in First Person Vision (FPV). Visual tracking algorithms which follow the objects manipulated by the camera wearer can provide useful information to effectively model such interactions. In the last years, the computer vision community has significantly improved the performance of tracking algorithms for a large variety of target objects and scenarios. Despite a few previous attempts to exploit trackers in the FPV domain, a methodical\u2026\u00a0",
        "Publication Year": "27 September 2022",
        "Citation Count": "7",
        "Reference Count": "122",
        "Authors": [
            "Matteo Dunnhofer",
            "Antonino Furnari",
            "Giovanni Maria Farinella",
            "Christian Micheloni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ce1da08be62183845cac70b7236ee9de5f2dde43",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "9559f0b77932a3c5f17aeb8564b400430d173ec7",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "b90010d61509bcacff64003b7e31e817487ea018",
            "50c60583dc0ef09484358deab329f82ee22c2b66",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/RGBD-Object-Tracking%3A-An-In-depth-Review-Yang-Li/dc9a66e0f329de8054f4ab845331fb7183987418",
        "ID": "dc9a66e0f329de8054f4ab845331fb7183987418",
        "Title": "RGBD Object Tracking: An In-depth Review",
        "Abstract": "\u2014RGBD object tracking is gaining momentum in computer vision research thanks to the development of depth sensors. Although numerous RGBD trackers have been pro- posed with promising performance, an in-depth review for comprehensive understanding of this area is lacking. In this paper, we \ufb01rstly review RGBD object trackers from different perspectives, including RGBD fusion, depth usage, and tracking framework. Then, we summarize the existing datasets and the evaluation metrics. We benchmark a\u2026\u00a0",
        "Publication Year": "26 March 2022",
        "Citation Count": "2",
        "Reference Count": "75",
        "Authors": [
            "Jinyu Yang",
            "Zhe Li",
            "Song Yan",
            "Feng Zheng",
            "Alevs Leonardis",
            "Joni-Kristian Kamarainen",
            "Ling Shao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "625aec94369715717158843c3ee288869cbe098f",
            "f33b4ba5efdef921383bde48ed1ed4edff86edb9",
            "487eb86379e979a72ebfef67db6eb8f048d1d258",
            "d884af3933148cef3b50fd38c810f5a7763d0fc9",
            "6290d7a7e353fbfe77e21e4d1086143f5e66312b",
            "f202feae9ca7b3766e072b6af657beed2236a93c",
            "c06ecdf5b149c322db0381adb6b3fd5ccb31a720",
            "7681f4c80774c6661980c5a76ffab357cca5f5cf",
            "3f02406b9b59d6f966c735953930fede1d751d0d",
            "761a9b5d8750eb63a9717650c4aaca53ce36a364"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Object-Tracking-on-Multi-modal-RGB-D-Videos%3A-Zhu-Xu/903509c17cf0e013df71f2534ac3527719faa555",
        "ID": "903509c17cf0e013df71f2534ac3527719faa555",
        "Title": "Visual Object Tracking on Multi-modal RGB-D Videos: A Review",
        "Abstract": "The development of visual object tracking has continued for decades. Recent years, as the wide accessibility of the low-cost RGBD sensors, the task of visual object tracking on RGB-D videos has drawn much attention. Compared to conventional RGB-only tracking, the RGB-D videos can provide more information that facilitates objecting tracking in some complicated scenarios. The goal of this review is to summarize the relative knowledge of the research filed of RGB-D tracking. To be specific, we\u2026\u00a0",
        "Publication Year": "23 January 2022",
        "Citation Count": "3",
        "Reference Count": "48",
        "Authors": [
            "Xuefeng Zhu",
            "Tianyang Xu",
            "Xiaojun Wu"
        ],
        "Related Topics": [
            "Computer Science",
            "Physics"
        ],
        "References": [
            "3f02406b9b59d6f966c735953930fede1d751d0d",
            "f202feae9ca7b3766e072b6af657beed2236a93c",
            "625aec94369715717158843c3ee288869cbe098f",
            "d10861d377be150b1e03cb942deb8763095de88f",
            "487eb86379e979a72ebfef67db6eb8f048d1d258",
            "611a9bd2c19bcbf5f3083e30523f55a813ac9d2f",
            "3b75cf84255fce6bdc1fe998761a115437c84c77",
            "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914",
            "62cf427d9c89099139b5e9a79d43b7495367740d",
            "1bc9dd7ebe2d9f90f719de241db6d13a77a6c3a1"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Seventh-Visual-Object-Tracking-VOT2019-Results-Kristan-Matas/786577081e00d69eeac8e9612eaf2dad59765e73",
        "ID": "786577081e00d69eeac8e9612eaf2dad59765e73",
        "Title": "The Seventh Visual Object Tracking VOT2019 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed\u2026\u00a0",
        "Publication Year": "1 October 2019",
        "Citation Count": "323",
        "Reference Count": "111",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Joni-Kristian",
            "K{\\&quot;a}m{\\&quot;a}r{\\&quot;a}inen",
            "Luka Cehovin Zajc",
            "Ondrej Drbohlav",
            "Alan Luke{\\vz}i{\\vc}",
            "Amanda Berg",
            "Abdelrahman",
            "Eldesokey",
            "Jani K{\\&quot;a}pyl{\\&quot;a}",
            "Gustavo Javier Fernandez",
            "Abel Gonzalez-Garcia",
            "Alireza",
            "Memarmoghadam",
            "Andong Lu",
            "Anfeng He",
            "Anton Yuriiovych Varfolomieiev",
            "Antoni B. Chan",
            "Ardhendu Shekhar",
            "Tripathi",
            "Arnold W. M. Smeulders",
            "Bala Suraj Pedasingu",
            "Bao Xin Chen",
            "Baopeng Zhang",
            "Baoyuan Wu",
            "Bi",
            "Li",
            "Bin He",
            "Bin Yan",
            "Bing Bai",
            "Bing Li",
            "Bo Li",
            "Byeong Hak Kim",
            "Chao Ma",
            "Chen Fang",
            "Chen",
            "Qian",
            "Cheng Chen",
            "Chenglong Li",
            "Chengquan Zhang",
            "Chi-Yi Tsai",
            "Chong Luo",
            "Christian",
            "Micheloni",
            "Chunhui Zhang",
            "Dacheng Tao",
            "Deepak Gupta",
            "Dejia Song",
            "Dong Wang",
            "Efstratios",
            "Gavves",
            "Eunu Yi",
            "Fahad Shahbaz Khan",
            "Fangyi Zhang",
            "Fei Wang",
            "Fei Zhao",
            "George De",
            "Ath",
            "Goutam Bhat",
            "Guang-Gui Chen",
            "Guangting Wang",
            "Guoxuan Li",
            "Hakan \u00c7evikalp",
            "Hao Du",
            "Haojie",
            "Zhao",
            "Hasan Saribas",
            "Ho Min Jung",
            "Hongliang Bai",
            "Hongyuan Yu",
            "Houwen Peng",
            "Huchuan",
            "L\u01d4",
            "Hui Li",
            "Jia-Ke Li",
            "Jianhua Li",
            "Jianlong Fu",
            "Jie Chen",
            "Jie Gao",
            "Jie Zhao",
            "Jin Tang",
            "Jing",
            "Jingjing Wu",
            "Jingtuo Liu",
            "Jinqiao Wang",
            "Jinqing Qi",
            "Jinyue Zhang",
            "John Tsotsos",
            "Jong Hyuk Jong Hyuk",
            "Lee",
            "Joost van de Weijer",
            "Josef Kittler",
            "Jun Ha Lee",
            "Junfei Zhuang",
            "Kangkai Zhang",
            "Kangkang",
            "Wang",
            "Kenan Dai",
            "Lei Chen",
            "Lei Liu",
            "Leida Guo",
            "Li Zhang",
            "Liang Wang",
            "Liang Wang",
            "Lichao",
            "Zhang",
            "Lijun Wang",
            "Lijun Zhou",
            "Linyu Zheng",
            "Litu Rout",
            "Luc Van Gool",
            "Luca Bertinetto",
            "Martin",
            "Danelljan",
            "Matteo Dunnhofer",
            "Meng Ni",
            "Min Young Kim",
            "Ming Tang",
            "Ming-Hsuan Yang",
            "Naveen",
            "Paluru",
            "Niki Martinel",
            "Pengfei Xu",
            "Pengfei Zhang",
            "Pengkun Zheng",
            "Pengyu Zhang",
            "S. PhilipH.",
            "Torr",
            "Qi Zhang Qiang Wang",
            "Qing Guo",
            "Radu Timofte",
            "Rama Krishna Sai Subrahmanyam Gorthi",
            "Richard",
            "Everson",
            "Ruize Han",
            "Ruohan Zhang",
            "Shan You",
            "Shao-Chuan Zhao",
            "Shengwei Zhao",
            "Shihu",
            "Shikun Li",
            "Shiming Ge",
            "Shuai Bai",
            "Shuosen Guan",
            "Tengfei Xing",
            "Tianyang Xu",
            "Tianyu",
            "Yang",
            "Ting Zhang",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Wei Feng",
            "Wei Hu",
            "Weizhao Wang",
            "Wenjie Tang",
            "Wenjun",
            "Zeng",
            "Wenyu Liu",
            "Xi Chen",
            "Xi Qiu",
            "Xiang Bai",
            "Xiaojun Wu",
            "Xiaoyun Yang",
            "Xier",
            "Xin Li",
            "Xingyuan Sun",
            "Xingyu Chen",
            "Xinmei Tian",
            "Xuwen Tang",
            "Xuefeng Zhu",
            "Yan-ping Huang",
            "Yanan",
            "Yanchao Lian",
            "Yang Gu",
            "Yang Ming Liu",
            "Yanjie Chen",
            "Yi Zhang",
            "Yinda Xu",
            "Yingming",
            "Yingping Li",
            "Yu Zhou",
            "Yuan Dong",
            "Yufei Xu",
            "Yunhua Zhang",
            "Yunkun Li",
            "Zeyu Zhao",
            "Luo",
            "Zhaoliang Zhang",
            "Zhenhua Feng",
            "Zhenyu He",
            "Zhichao Song",
            "Zhihao Chen",
            "Zhipeng",
            "Zhirong Wu",
            "Zhiwei Xiong",
            "Zhongjian Huang",
            "Zhu Teng",
            "Zihan Ni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "6179ac06f1a8fd1ac6b693b02824948dff438d54",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "23f8927f996d56f3b5076d8993a70bcfc70182a1",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "320d05db95ab42ade69294abe46cd1aca6aca602"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2017-Challenge-Kristan-Leonardis/350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "ID": "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "Title": "The Visual Object Tracking VOT2017 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \"real-time\" experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the\u2026\u00a0",
        "Publication Year": "1 October 2017",
        "Citation Count": "429",
        "Reference Count": "132",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andrej Muhic",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea Vedaldi",
            "Antoine Manzanera",
            "Antoine Tran",
            "Aydin Alatan",
            "Bogdan Cosmin Mocanu",
            "Boyu Chen",
            "Chang Huang",
            "Changsheng Xu",
            "Chong Sun",
            "Dalong Du",
            "Dafan Zhang",
            "Dawei Du",
            "Deepak Mishra",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Francesco Battistone",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Goutam Bhat",
            "Guan Huang",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Hongliang Zhang",
            "Houqiang Li",
            "Huchuan Lu",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jaeil Cho",
            "Jae-Y. Lee",
            "Jana Noskova",
            "Jianke Zhu",
            "Jin Gao",
            "Jingyu Liu",
            "Ji-Wan Kim",
            "Jo{\\~a}o F. Henriques",
            "Jos{\\&#x27;e} Mar{\\&#x27;i}a Mart{\\&#x27;i}nez Sanchez",
            "Junfei Zhuang",
            "Junliang Xing",
            "Junyu Gao",
            "Kai Chen",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Kris Kitani",
            "Lei Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh Poostchi",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Ming-Hsuan Yang",
            "Nianhao Xie",
            "Ning Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "Pallavi M. Venugopal",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Qifeng Yu",
            "Qingming Huang",
            "Rafael Martin Nieto",
            "R. Bowden",
            "Risheng Liu",
            "Ruxandra Tapu",
            "Simon Hadfield",
            "Siwei Lyu",
            "Stuart Golodetz",
            "Sunglok Choi",
            "Tianzhu Zhang",
            "Titus B. Zaharia",
            "Vincenzo Santopietro",
            "Wei Zou",
            "Weiming Hu",
            "Wenbing Tao",
            "Wenbo Li",
            "Wen-gang Zhou",
            "Xianguo Yu",
            "Xiao Bian",
            "Yang Li",
            "Yifan Xing",
            "Yingruo Fan",
            "Zhengyu Zhu",
            "Zhipeng Zhang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2016-Challenge-Kristan-Leonardis/966aad492f75b17f698e981e008b73b51816c6aa",
        "ID": "966aad492f75b17f698e981e008b73b51816c6aa",
        "Title": "The Visual Object Tracking VOT2016 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a\u2026\u00a0",
        "Publication Year": "8 October 2016",
        "Citation Count": "705",
        "Reference Count": "112",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Gustavo Javier Fernandez",
            "Abhinav Kumar Gupta",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Andrea Vedaldi",
            "Andreas Robinson",
            "Andy Jinhua Ma",
            "Anton Yuriiovych Varfolomieiev",
            "A. Aydin Alatan",
            "Aykut Erdem",
            "Bernard Ghanem",
            "Bin Liu",
            "Bohyung Han",
            "Brais Mart{\\&#x27;i}nez",
            "Chang-Ming Chang",
            "Changsheng Xu",
            "Chong Sun",
            "Daijin Kim",
            "Dapeng Chen",
            "Dawei Du",
            "Deepak Mishra",
            "D. Y. Yeung",
            "Erhan Gundogdu",
            "Erkut Erdem",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Fei Zhao",
            "Filiz Bunyak",
            "Francesco Battistone",
            "Gao Zhu",
            "Giorgio Roffo",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Henry Medeiros",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst Possegger",
            "Huchuan Lu",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Hyung Jin Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Y. Lee",
            "Jianke Zhu",
            "Jiayi Feng",
            "Jin Gao",
            "Jin Young Choi",
            "Jingjing Xiao",
            "Ji-Wan Kim",
            "Jiyeoup Jeong",
            "Jo{\\~a}o F. Henriques",
            "Jochen Lang",
            "Jongwon Choi",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Junliang Xing",
            "Junyu Gao",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Krystian Mikolajczyk",
            "Lei Qin",
            "Lijun Wang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Madan Kumar Rapuru",
            "Mahdieh Poostchi",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel F. Valstar",
            "Ming Tang",
            "Mooyeol Baek",
            "Muhammad Haris Khan",
            "Naiyan Wang",
            "Nana Fan",
            "Noor M. Al-Shakarji",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Osman Akin",
            "Payman Moallem",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Pong Chi Yuen",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan Pelapur",
            "Richard Bowden",
            "Robert Lagani{\\`e}re",
            "R. Stolkin",
            "Ryan Walsh",
            "Sebastian Bernd Krah",
            "Shengkun Li",
            "Shengping Zhang",
            "Shizeng Yao",
            "Simon Hadfield",
            "Simone Melzi",
            "Siwei Lyu",
            "Siyi Li",
            "Stefan Becker",
            "Stuart Golodetz",
            "Sumithra Kakanuru",
            "Sunglok Choi",
            "Tao Hu",
            "Thomas Mauthner",
            "Tianzhu Zhang",
            "Tony P. Pridmore",
            "Vincenzo Santopietro",
            "Weiming Hu",
            "Wenbo Li",
            "Wolfgang H{\\&quot;u}bner",
            "Xiangyuan Lan",
            "Xiaomeng Wang",
            "Xin Li",
            "Yang Li",
            "Y. Demiris",
            "Yifan Wang",
            "Yuankai Qi",
            "Zejian Yuan",
            "Zexiong Cai",
            "Zhan Xu",
            "Zhenyu He",
            "Zhizhen Chi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d",
            "6b175816b1f81127f5e2a2fe998df99d62290a1c",
            "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5",
            "16be98fa5924131816bc991a2c7ed91b8c69eaaa"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2015-Challenge-Kristan-Matas/15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
        "ID": "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
        "Title": "The Visual Object Tracking VOT2015 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 pre-decessor are: (i) a new VOT2015 dataset twice\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "357",
        "Reference Count": "84",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Luka Cehovin",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Georg Nebehay",
            "Roman P. Pflugfelder",
            "Abhinav Kumar Gupta",
            "Adel Bibi",
            "Alan",
            "Luke{\\vz}i{\\vc}",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Amir Saffari",
            "Alfredo Petrosino",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Anton",
            "Varfolomieiev",
            "Atilla Baskurt",
            "Baojun Zhao",
            "Bernard Ghanem",
            "Brais Mart{\\&#x27;i}nez",
            "ByeongJu",
            "Lee",
            "Bohyung Han",
            "Chaohui Wang",
            "Christophe Garcia",
            "Chunyuan Zhang",
            "Cordelia",
            "Schmid",
            "Dacheng Tao",
            "Daijin Kim",
            "Dafei Huang",
            "Danil V. Prokhorov",
            "Dawei Du",
            "Dit-Yan",
            "Yeung",
            "Eraldo Ribeiro",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Filiz Bunyak",
            "Gao Zhu",
            "Guna",
            "Seetharaman",
            "Hilke Kieritz",
            "Hing Tuen Yau",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst Possegger",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Ivan Bogun",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Yeong Lee",
            "Jianke Zhu",
            "Jianping Shi",
            "Jiatong Li",
            "J E Jia",
            "Jiayi Feng",
            "Jin Gao",
            "Jin",
            "Youngjoon Choi",
            "Ji-Wan Kim",
            "Jochen von Lang",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Jongwon Choi",
            "Junliang Xing",
            "Kai",
            "Xue",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Alahari Karteek",
            "Ke Gao",
            "Kimin Yun",
            "Kin",
            "Hong Wen Benedict Wong",
            "Lei Luo",
            "Liang Ma",
            "Lipeng Ke",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh",
            "Pootschi",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Mei Wen",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel F. Valstar",
            "Mingxi Tang",
            "Mr Chang",
            "Muhammad Haris Khan",
            "Nana Fan",
            "Naiyan",
            "Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan",
            "Pelapur",
            "R. Bowden",
            "Robert Lagani{\\`e}re",
            "Salma Moujtahid",
            "Sam Hare",
            "Simon Hadfield",
            "Siwei Lyu",
            "Siyi Li",
            "Song Zhu",
            "Stefan Becker",
            "Stefan Duffner",
            "Stephen L. Hicks",
            "Stuart Golodetz",
            "Sun Young Choi",
            "Tianfu Wu",
            "Thomas Mauthner",
            "Tony P. Pridmore",
            "Weiming",
            "Hu",
            "Wolfgang H{\\&quot;u}bner",
            "Xiaomeng Wang",
            "Xin Li",
            "Xinchu Shi",
            "Xuehua Zhao",
            "Xue Mei",
            "Yao",
            "Shizeng",
            "Yang Hua",
            "Yang Li",
            "Yangchun Lu",
            "Yuezun Li",
            "Zhaoyun Chen",
            "Zehua Huang",
            "Zhe",
            "Chen",
            "Zhe Zhang",
            "Zhenyu He",
            "Zhibin Hong"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "7b75da6f5edac80575d9dcf63db164ce24933907"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2013-Challenge-Kristan-Matas/4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "ID": "4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "Title": "The Visual Object Tracking VOT2013 Challenge Results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) workshop was organized in\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "333",
        "Reference Count": "137",
        "Authors": [
            "Matej Kristan",
            "Juan E. Sala Matas",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Luka Cehovin",
            "Georg Nebehay",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustavo Javier Fernandez",
            "Alan Luke{\\vz}i{\\vc}",
            "Aleksandar Dimitriev",
            "Alfredo Petrosino",
            "Amir Saffari",
            "Bo Li",
            "Bohyung Han",
            "Cherkeng Heng",
            "Christophe Garcia",
            "Dominik Pangersic",
            "Gustav H{\\&quot;a}ger",
            "Fahad Shahbaz Khan",
            "Franc Oven",
            "Horst Possegger",
            "Horst Bischof",
            "Hyeonseob Nam",
            "Jianke Zhu",
            "Jijia Li",
            "Jin Young Choi",
            "Jinwoo Choi",
            "Jo{\\~a}o F. Henriques",
            "Joost van de Weijer",
            "Jorge Batista",
            "Karel Lebeda",
            "Kristoffer {\\&quot;O}fj{\\&quot;a}ll",
            "Kwang Moo Yi",
            "Lei Qin",
            "Longyin Wen",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Michael Felsberg",
            "Ming-Ming Cheng",
            "Philip H. S. Torr",
            "Qingming Huang",
            "R. Bowden",
            "Sam Hare",
            "Samantha YueYing Lim",
            "Seunghoon Hong",
            "Shengcai Liao",
            "Simon Hadfield",
            "S. Li",
            "Stefan Duffner",
            "Stuart Golodetz",
            "Thomas Mauthner",
            "Vibhav Vineet",
            "Weiyao Lin",
            "Yang Li",
            "Yuankai Qi",
            "Zhen Lei",
            "Zhi Heng Niu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "e3c433ab9608d7329f944552ba1721e277a42d74",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/D3S-%E2%80%93-A-Discriminative-Single-Shot-Segmentation-Luke%C5%BEi%C4%8D-Matas/45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "ID": "45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "Title": "D3S \u2013 A Discriminative Single Shot Segmentation Tracker",
        "Abstract": "Template-based discriminative trackers are currently the dominant tracking paradigm due to their robustness, but are restricted to bounding box tracking and a limited range of transformation models, which reduces their localization accuracy. We propose a discriminative single-shot segmentation tracker - D3S, which narrows the gap between visual object tracking and video object segmentation. A single-shot network applies two target models with complementary geometric properties, one invariant to\u2026\u00a0",
        "Publication Year": "20 November 2019",
        "Citation Count": "138",
        "Reference Count": "53",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "b3249763ac9ecc4df6ef96721c8c7410e0f0468a",
            "8b74008565b575f9ab7a0962ca5f6955d64db045",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "4a70c20ad66e5f3bb12fccd84c63ba619053c811"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/CDTB%3A-A-Color-and-Depth-Visual-Object-Tracking-and-Luke%C5%BEi%C4%8D-Kart/f202feae9ca7b3766e072b6af657beed2236a93c",
        "ID": "f202feae9ca7b3766e072b6af657beed2236a93c",
        "Title": "CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark",
        "Abstract": "We propose a new color-and-depth general visual object tracking benchmark (CDTB). CDTB is recorded by several passive and active RGB-D setups and contains indoor as well as outdoor sequences acquired in direct sunlight. The CDTB dataset is the largest and most diverse dataset in RGB-D tracking, with an order of magnitude larger number of frames than related datasets. The sequences have been carefully recorded to contain significant object pose change, clutter, occlusion, and periods of long\u2026\u00a0",
        "Publication Year": "1 July 2019",
        "Citation Count": "44",
        "Reference Count": "45",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Ugur Kart",
            "Jani K{\\&quot;a}pyl{\\&quot;a}",
            "Ahmed Durmush",
            "J. K{\\&quot;a}m{\\&quot;a}r{\\&quot;a}inen",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "487eb86379e979a72ebfef67db6eb8f048d1d258",
            "3f02406b9b59d6f966c735953930fede1d751d0d",
            "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "3b75cf84255fce6bdc1fe998761a115437c84c77",
            "c06ecdf5b149c322db0381adb6b3fd5ccb31a720",
            "965b01ffc25e643acd16e91dd74ed0d1879f99ec",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Reptile-Meta-Tracking-Jhang-Tsai/0f50914e86b6010586f1772308858de9a418fb9f",
        "ID": "0f50914e86b6010586f1772308858de9a418fb9f",
        "Title": "Reptile Meta-Tracking",
        "Abstract": "Generic object tracking (GOT) is one of the main topics in computer vision for many years. The goal of GOT is to recognize and locate a specific object in the form of bounding box throughout a sequence of images. Moreover, GOT also requires algorithms to locate objects down to instances level. These requirements produce some unique challenges especially for deep learning based GOT algorithms that may easily become over-fitting if given a really small training dataset of the object during the\u2026\u00a0",
        "Publication Year": "1 September 2019",
        "Citation Count": "One",
        "Reference Count": "16",
        "Authors": [
            "Shang-Jhih Jhang",
            "Chi-Yi Tsai"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "50c60583dc0ef09484358deab329f82ee22c2b66",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0",
            "2ce63d77eecc35faef85a3b752a314c93a077ac9",
            "c46b08850b9c458704a3ca69172e6a0d40a6cb7f",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "a87cc499cf101b3697cacc65094b4b6590e0d061",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Performance-Evaluation-Methodology-for-Long-Term-Luke%C5%BEi%C4%8D-Zajc/23f8927f996d56f3b5076d8993a70bcfc70182a1",
        "ID": "23f8927f996d56f3b5076d8993a70bcfc70182a1",
        "Title": "Performance Evaluation Methodology for Long-Term Visual Object Tracking",
        "Abstract": "A long-term visual object tracking performance evaluation methodology and a benchmark are proposed. Performance measures are designed by following a long-term tracking definition to maximize the analysis probing strength. The new measures outperform existing ones in interpretation potential and in better distinguishing between different tracking behaviors. We show that these measures generalize the short-term performance measures, thus linking the two tracking problems. Furthermore, the new\u2026\u00a0",
        "Publication Year": "19 June 2019",
        "Citation Count": "6",
        "Reference Count": "45",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Now-you-see-me%3A-evaluating-performance-in-long-term-Luke%C5%BEi%C4%8D-Zajc/3275944117b43cc44beebe7c82bffc13ec8cb0fa",
        "ID": "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
        "Title": "Now you see me: evaluating performance in long-term visual tracking",
        "Abstract": "We propose a new long-term tracking performance evaluation methodology and present a new challenging dataset of carefully selected sequences with many target disappearances. We perform an extensive evaluation of six long-term and nine short-term state-of-the-art trackers, using new performance measures, suitable for evaluating long-term tracking - tracking precision, recall and F-score. The evaluation shows that a good model update strategy and the capability of image-wide re-detection are\u2026\u00a0",
        "Publication Year": "19 April 2018",
        "Citation Count": "54",
        "Reference Count": "34",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "d3d36c3caa255053877a7e3250d47d906eec81d2",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "681ee0059ed573265847785d110237861458304e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Visual-Object-Tracking-Benchmark-Moudgil-Gandhi/19d6b9725a59f4b624205829d5f03ac893ca1367",
        "ID": "19d6b9725a59f4b624205829d5f03ac893ca1367",
        "Title": "Long-Term Visual Object Tracking Benchmark",
        "Abstract": "We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term\u2026\u00a0",
        "Publication Year": "4 December 2017",
        "Citation Count": "74",
        "Reference Count": "47",
        "Authors": [
            "A. Moudgil",
            "Vineet Gandhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Sixth-Visual-Object-Tracking-VOT2018-Challenge-Kristan-Leonardis/219e9a4527110baf1feb3df20db12064eeafdfb7",
        "ID": "219e9a4527110baf1feb3df20db12064eeafdfb7",
        "Title": "The Sixth Visual Object Tracking VOT2018 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2018 is the sixth annual tracker benchmarking activity organized by the VOT initiative. Results of over eighty trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis and a \u201creal-time\u201d experiment simulating a situation where a tracker processes images as if provided\u2026\u00a0",
        "Publication Year": "8 September 2018",
        "Citation Count": "588",
        "Reference Count": "100",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Goutam Bhat",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "{\\&#x27;A}lvaro Iglesias-Arias",
            "Aydin Alatan",
            "Abel Gonzalez-Garcia",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea Vedaldi",
            "Andrej Muhic",
            "Anfeng He",
            "Arnold W. M. Smeulders",
            "Asanka G. Perera",
            "Bo Li",
            "Boyu Chen",
            "Changick Kim",
            "Changsheng Xu",
            "Changzhen Xiong",
            "Cheng Tian",
            "Chong Luo",
            "Chong Sun",
            "Cong Hao",
            "Daijin Kim",
            "Deepak Mishra",
            "Deming Chen",
            "Dong Wang",
            "Dongyoon Wee",
            "Efstratios Gavves",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Fan Yang",
            "Fei Zhao",
            "Feng Li",
            "Francesco Battistone",
            "George De Ath",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Haibin Ling",
            "Hamed Kiani Galoogahi",
            "Hankyeol Lee",
            "Haojie Li",
            "Haojie Zhao",
            "Heng Fan",
            "Honggang Zhang",
            "Horst Possegger",
            "Houqiang Li",
            "Huchuan Lu",
            "Hui Zhi",
            "Huiyun Li",
            "Hyemin Lee",
            "Hyung Jin Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jaime Spencer Martin",
            "Javaan Singh Chahl",
            "Jin Young Choi",
            "Jing Li",
            "Jinqiao Wang",
            "Jinqing Qi",
            "Jinyoung Sung",
            "Joakim Johnander",
            "Jo{\\~a}o F. Henriques",
            "Jongwon Choi",
            "Joost van de Weijer",
            "Jorge Rodr{\\&#x27;i}guez Herranz",
            "Jos{\\&#x27;e} Mar{\\&#x27;i}a Mart{\\&#x27;i}nez Sanchez",
            "Josef Kittler",
            "Junfei Zhuang",
            "Junyu Gao",
            "Klemen Grm",
            "Lichao Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Litu Rout",
            "Liu Si",
            "Luca Bertinetto",
            "Lutao Chu",
            "Manqiang Che",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Ming-Hsuan Yang",
            "Mohamed H. Abdelpakey",
            "Mohamed S. Shehata",
            "Myung Gu Kang",
            "Namhoon Lee",
            "Ning Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "Pablo Vicente-Mo{\\~n}ivar",
            "Pedro Senna",
            "Peixia Li",
            "Philip H. S. Torr",
            "Priya Mariam Raju",
            "Ruihe Qian",
            "Qiang Wang",
            "Qin Zhou",
            "Qing Guo",
            "Rafael Martin Nieto",
            "Rama Krishna Sai Subrahmanyam Gorthi",
            "Ran Tao",
            "R. Bowden",
            "Richard M. Everson",
            "Runling Wang",
            "Sangdoo Yun",
            "Seokeon Choi",
            "Sergio Vivas",
            "Shuai Bai",
            "Shuangping Huang",
            "Sihang Wu",
            "Simon Hadfield",
            "Siwen Wang",
            "Stuart Golodetz",
            "Ming Tang",
            "Tianyang Xu",
            "Tianzhu Zhang",
            "Tobias Fischer",
            "Vincenzo Santopietro",
            "Vitomir {\\vS}truc",
            "Wei Wang",
            "Wangmeng Zuo",
            "Wei Feng",
            "Wei Wu",
            "Wei Zou",
            "Weiming Hu",
            "Wen-gang Zhou",
            "Wen Jun Zeng",
            "Xiaofan Zhang",
            "Xiaohe Wu",
            "Xiaojun Wu",
            "Xinmei Tian",
            "Yan Li",
            "Yan Lu",
            "Yee Wei Law",
            "Yi Wu",
            "Y. Demiris",
            "Yicai Yang",
            "Yifan Jiao",
            "Yuhong Li",
            "Yunhua Zhang",
            "Yuxuan Sun",
            "Zheng Zhang",
            "Zhengyu Zhu",
            "Zhenhua Feng",
            "Zhihui Wang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-term-Tracking-in-the-Wild%3A-A-Benchmark-Valmadre-Bertinetto/ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
        "ID": "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
        "Title": "Long-term Tracking in the Wild: A Benchmark",
        "Abstract": "We introduce the OxUvA dataset and benchmark for evaluating single-object tracking algorithms. Benchmarks have enabled great strides in the field of object tracking by defining standardized evaluations on large sets of diverse videos. However, these works have focused exclusively on sequences that are just tens of seconds in length and in which the target is always visible. Consequently, most researchers have designed methods tailored to this \u201cshort-term\u201d scenario, which is poorly\u2026\u00a0",
        "Publication Year": "26 March 2018",
        "Citation Count": "144",
        "Reference Count": "35",
        "Authors": [
            "Jack Valmadre",
            "Luca Bertinetto",
            "Jo{\\~a}o F. Henriques",
            "Ran Tao",
            "Andrea Vedaldi",
            "Arnold W. M. Smeulders",
            "Philip H. S. Torr",
            "Efstratios Gavves"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "d3d36c3caa255053877a7e3250d47d906eec81d2",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Seventh-Visual-Object-Tracking-VOT2019-Results-Kristan-Matas/786577081e00d69eeac8e9612eaf2dad59765e73",
        "ID": "786577081e00d69eeac8e9612eaf2dad59765e73",
        "Title": "The Seventh Visual Object Tracking VOT2019 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed\u2026\u00a0",
        "Publication Year": "1 October 2019",
        "Citation Count": "323",
        "Reference Count": "111",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Joni-Kristian",
            "K{\\&quot;a}m{\\&quot;a}r{\\&quot;a}inen",
            "Luka Cehovin Zajc",
            "Ondrej Drbohlav",
            "Alan Luke{\\vz}i{\\vc}",
            "Amanda Berg",
            "Abdelrahman",
            "Eldesokey",
            "Jani K{\\&quot;a}pyl{\\&quot;a}",
            "Gustavo Javier Fernandez",
            "Abel Gonzalez-Garcia",
            "Alireza",
            "Memarmoghadam",
            "Andong Lu",
            "Anfeng He",
            "Anton Yuriiovych Varfolomieiev",
            "Antoni B. Chan",
            "Ardhendu Shekhar",
            "Tripathi",
            "Arnold W. M. Smeulders",
            "Bala Suraj Pedasingu",
            "Bao Xin Chen",
            "Baopeng Zhang",
            "Baoyuan Wu",
            "Bi",
            "Li",
            "Bin He",
            "Bin Yan",
            "Bing Bai",
            "Bing Li",
            "Bo Li",
            "Byeong Hak Kim",
            "Chao Ma",
            "Chen Fang",
            "Chen",
            "Qian",
            "Cheng Chen",
            "Chenglong Li",
            "Chengquan Zhang",
            "Chi-Yi Tsai",
            "Chong Luo",
            "Christian",
            "Micheloni",
            "Chunhui Zhang",
            "Dacheng Tao",
            "Deepak Gupta",
            "Dejia Song",
            "Dong Wang",
            "Efstratios",
            "Gavves",
            "Eunu Yi",
            "Fahad Shahbaz Khan",
            "Fangyi Zhang",
            "Fei Wang",
            "Fei Zhao",
            "George De",
            "Ath",
            "Goutam Bhat",
            "Guang-Gui Chen",
            "Guangting Wang",
            "Guoxuan Li",
            "Hakan \u00c7evikalp",
            "Hao Du",
            "Haojie",
            "Zhao",
            "Hasan Saribas",
            "Ho Min Jung",
            "Hongliang Bai",
            "Hongyuan Yu",
            "Houwen Peng",
            "Huchuan",
            "L\u01d4",
            "Hui Li",
            "Jia-Ke Li",
            "Jianhua Li",
            "Jianlong Fu",
            "Jie Chen",
            "Jie Gao",
            "Jie Zhao",
            "Jin Tang",
            "Jing",
            "Jingjing Wu",
            "Jingtuo Liu",
            "Jinqiao Wang",
            "Jinqing Qi",
            "Jinyue Zhang",
            "John Tsotsos",
            "Jong Hyuk Jong Hyuk",
            "Lee",
            "Joost van de Weijer",
            "Josef Kittler",
            "Jun Ha Lee",
            "Junfei Zhuang",
            "Kangkai Zhang",
            "Kangkang",
            "Wang",
            "Kenan Dai",
            "Lei Chen",
            "Lei Liu",
            "Leida Guo",
            "Li Zhang",
            "Liang Wang",
            "Liang Wang",
            "Lichao",
            "Zhang",
            "Lijun Wang",
            "Lijun Zhou",
            "Linyu Zheng",
            "Litu Rout",
            "Luc Van Gool",
            "Luca Bertinetto",
            "Martin",
            "Danelljan",
            "Matteo Dunnhofer",
            "Meng Ni",
            "Min Young Kim",
            "Ming Tang",
            "Ming-Hsuan Yang",
            "Naveen",
            "Paluru",
            "Niki Martinel",
            "Pengfei Xu",
            "Pengfei Zhang",
            "Pengkun Zheng",
            "Pengyu Zhang",
            "S. PhilipH.",
            "Torr",
            "Qi Zhang Qiang Wang",
            "Qing Guo",
            "Radu Timofte",
            "Rama Krishna Sai Subrahmanyam Gorthi",
            "Richard",
            "Everson",
            "Ruize Han",
            "Ruohan Zhang",
            "Shan You",
            "Shao-Chuan Zhao",
            "Shengwei Zhao",
            "Shihu",
            "Shikun Li",
            "Shiming Ge",
            "Shuai Bai",
            "Shuosen Guan",
            "Tengfei Xing",
            "Tianyang Xu",
            "Tianyu",
            "Yang",
            "Ting Zhang",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Wei Feng",
            "Wei Hu",
            "Weizhao Wang",
            "Wenjie Tang",
            "Wenjun",
            "Zeng",
            "Wenyu Liu",
            "Xi Chen",
            "Xi Qiu",
            "Xiang Bai",
            "Xiaojun Wu",
            "Xiaoyun Yang",
            "Xier",
            "Xin Li",
            "Xingyuan Sun",
            "Xingyu Chen",
            "Xinmei Tian",
            "Xuwen Tang",
            "Xuefeng Zhu",
            "Yan-ping Huang",
            "Yanan",
            "Yanchao Lian",
            "Yang Gu",
            "Yang Ming Liu",
            "Yanjie Chen",
            "Yi Zhang",
            "Yinda Xu",
            "Yingming",
            "Yingping Li",
            "Yu Zhou",
            "Yuan Dong",
            "Yufei Xu",
            "Yunhua Zhang",
            "Yunkun Li",
            "Zeyu Zhao",
            "Luo",
            "Zhaoliang Zhang",
            "Zhenhua Feng",
            "Zhenyu He",
            "Zhichao Song",
            "Zhihao Chen",
            "Zhipeng",
            "Zhirong Wu",
            "Zhiwei Xiong",
            "Zhongjian Huang",
            "Zhu Teng",
            "Zihan Ni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "6179ac06f1a8fd1ac6b693b02824948dff438d54",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "23f8927f996d56f3b5076d8993a70bcfc70182a1",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "320d05db95ab42ade69294abe46cd1aca6aca602"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Exploring-3-R%E2%80%99s-of-Long-term-Tracking%3A-Recovery-and-Karthik-Moudgil/913cebc279c363fb9476496f096519e27212b3d5",
        "ID": "913cebc279c363fb9476496f096519e27212b3d5",
        "Title": "Exploring 3 R\u2019s of Long-term Tracking: Re-detection, Recovery and Reliability",
        "Abstract": "Recent works have proposed several long term tracking benchmarks and highlight the importance of moving towards long-duration tracking to bridge the gap with application requirements. The current evaluation methodologies, however, do not focus on several aspects that are crucial in a long term perspective like Re-detection, Recovery, and Reliability. In this paper, we propose novel evaluation strategies for a more in-depth analysis of trackers from a long-term perspective. More specifically, (a\u2026\u00a0",
        "Publication Year": "27 October 2019",
        "Citation Count": "4",
        "Reference Count": "41",
        "Authors": [
            "Shyamgopal Karthik",
            "A. Moudgil",
            "Vineet Gandhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "0eb1b75b98d4f4f69a5fb7669ad86d85cdd76848",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "6f7b23893368bd3660086c502f540256c0372ee2",
            "900ab48d25b44c076e31224b7befa503d9550c53"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Long-Term-Tracking-With-Dai-Zhang/adacccd99a42c3145ec6392a1a6b08878376e38b",
        "ID": "adacccd99a42c3145ec6392a1a6b08878376e38b",
        "Title": "High-Performance Long-Term Tracking With Meta-Updater",
        "Abstract": "Long-term visual tracking has drawn increasing attention because it is much closer to practical applications than short-term tracking. Most top-ranked long-term trackers adopt the offline-trained Siamese architectures, thus,they cannot benefit from great progress of short-term trackers with online update. However, it is quite risky to straightforwardly introduce online-update-based trackers to solve the long-term problem, due to long-term uncertain and noisy observations. In this work, we\u2026\u00a0",
        "Publication Year": "1 April 2020",
        "Citation Count": "118",
        "Reference Count": "55",
        "Authors": [
            "Kenan Dai",
            "Yunhua Zhang",
            "Dong Wang",
            "Jianhua Li",
            "Huchuan Lu",
            "Xiaoyun Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "50c60583dc0ef09484358deab329f82ee22c2b66",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "383e67e0de2fdac787976543ba38bada48d046fc",
            "834baad9db5a1de1bfe993ff4a55a8a957eb9e0a",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Visual-Object-Tracking-Benchmark-Moudgil-Gandhi/19d6b9725a59f4b624205829d5f03ac893ca1367",
        "ID": "19d6b9725a59f4b624205829d5f03ac893ca1367",
        "Title": "Long-Term Visual Object Tracking Benchmark",
        "Abstract": "We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term\u2026\u00a0",
        "Publication Year": "4 December 2017",
        "Citation Count": "74",
        "Reference Count": "47",
        "Authors": [
            "A. Moudgil",
            "Vineet Gandhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Visual-Tracking-with-Siamese-Li-Yan/320d05db95ab42ade69294abe46cd1aca6aca602",
        "ID": "320d05db95ab42ade69294abe46cd1aca6aca602",
        "Title": "High Performance Visual Tracking with Siamese Region Proposal Network",
        "Abstract": "Visual object tracking has been a fundamental topic in recent years and many deep learning based trackers have achieved state-of-the-art performance on multiple benchmarks. However, most of these trackers can hardly get top performance with real-time speed. In this paper, we propose the Siamese region proposal network (Siamese-RPN) which is end-to-end trained off-line with large-scale image pairs. Specifically, it consists of Siamese subnetwork for feature extraction and region proposal\u2026\u00a0",
        "Publication Year": "1 June 2018",
        "Citation Count": "1,566",
        "Reference Count": "41",
        "Authors": [
            "Bo Li",
            "Junjie Yan",
            "Wei Wu",
            "Zheng Zhu",
            "Xiaolin Hu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "1131c53b9baaa740a4deef4c1282821b23d18687",
            "7ccbb845829234548bfa9b24c61297b4f0cd678e",
            "5404718135548b01516a668e0c022c5cb22b422e",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "dda27eb7ddc4510f94cac0e5134b5d56aa77b075",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Robust-Long-Term-Object-Tracking-via-Improved-Model-Choi-Lee/f1c9f81ce054619f30b5c27fd97579f7216d7048",
        "ID": "f1c9f81ce054619f30b5c27fd97579f7216d7048",
        "Title": "Robust Long-Term Object Tracking via Improved Discriminative Model Prediction",
        "Abstract": "We propose an improved discriminative model prediction method for robust long-term tracking based on a pre-trained short-term tracker. The baseline pre-trained short-term tracker is SuperDiMP which combines the bounding-box regressor of PrDiMP with the standard DiMP classifier. Our tracker RLT-DiMP improves SuperDiMP in the following three aspects: (1) Uncertainty reduction using random erasing: To make our model robust, we exploit an agreement from multiple images after erasing random small\u2026\u00a0",
        "Publication Year": "11 August 2020",
        "Citation Count": "8",
        "Reference Count": "35",
        "Authors": [
            "Seokeon Choi",
            "Junhyun Lee",
            "Yunsung Lee",
            "Alexander Hauptmann"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "834baad9db5a1de1bfe993ff4a55a8a957eb9e0a",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "069ccdbab6ea6ca2d9c3b75c76360ca1e4e9a5e9",
            "6b6d31b022b7984a25fa9ee7fef64086ce7c464d",
            "bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/D3S-%E2%80%93-A-Discriminative-Single-Shot-Segmentation-Luke%C5%BEi%C4%8D-Matas/45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "ID": "45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "Title": "D3S \u2013 A Discriminative Single Shot Segmentation Tracker",
        "Abstract": "Template-based discriminative trackers are currently the dominant tracking paradigm due to their robustness, but are restricted to bounding box tracking and a limited range of transformation models, which reduces their localization accuracy. We propose a discriminative single-shot segmentation tracker - D3S, which narrows the gap between visual object tracking and video object segmentation. A single-shot network applies two target models with complementary geometric properties, one invariant to\u2026\u00a0",
        "Publication Year": "20 November 2019",
        "Citation Count": "138",
        "Reference Count": "53",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "b3249763ac9ecc4df6ef96721c8c7410e0f0468a",
            "8b74008565b575f9ab7a0962ca5f6955d64db045",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "4a70c20ad66e5f3bb12fccd84c63ba619053c811"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/%E2%80%98Skimming-Perusal%E2%80%99-Tracking%3A-A-Framework-for-and-Yan-Zhao/09b734072ad4f610478847c9cdc59a4a0c309b37",
        "ID": "09b734072ad4f610478847c9cdc59a4a0c309b37",
        "Title": "\u2018Skimming-Perusal\u2019 Tracking: A Framework for Real-Time and Robust Long-Term Tracking",
        "Abstract": "Compared with traditional short-term tracking, long-term tracking poses more challenges and is much closer to realistic applications. However, few works have been done and their performance have also been limited. In this work, we present a novel robust and real-time long-term tracking framework based on the proposed skimming and perusal modules. The perusal module consists of an effective bounding box regressor to generate a series of candidate proposals and a robust target verifier to infer\u2026\u00a0",
        "Publication Year": "4 September 2019",
        "Citation Count": "118",
        "Reference Count": "43",
        "Authors": [
            "B. Yan",
            "Haojie Zhao",
            "Dong Wang",
            "Huchuan Lu",
            "Xiaoyun Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "e73590fdfd6dab391111bb734053ae24207e2c71",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/GlobalTrack%3A-A-Simple-and-Strong-Baseline-for-Huang-Zhao/5664e24cacf3f6374c26b5597765099ee9537413",
        "ID": "5664e24cacf3f6374c26b5597765099ee9537413",
        "Title": "GlobalTrack: A Simple and Strong Baseline for Long-term Tracking",
        "Abstract": "A key capability of a long-term tracker is to search for targets in very large areas (typically the entire image) to handle possible target absences or tracking failures. However, currently there is a lack of such a strong baseline for global instance search. In this work, we aim to bridge this gap. Specifically, we propose GlobalTrack, a pure global instance search based tracker that makes no assumption on the temporal consistency of the target's positions and scales. GlobalTrack is developed\u2026\u00a0",
        "Publication Year": "18 December 2019",
        "Citation Count": "125",
        "Reference Count": "35",
        "Authors": [
            "Lianghua Huang",
            "Xin Zhao",
            "Kaiqi Huang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "900ab48d25b44c076e31224b7befa503d9550c53",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "ae066f27f2edc1c51847ce4cb21b6e1a3db44fa2",
            "4b1965a54a064ac9145b1ce404fe33f0120c8ae3"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Contour-Aware-Long-Term-Tracking-With-Reliable-Tang-Ling/f6186788541d332af19a96183787e01ef9080fb0",
        "ID": "f6186788541d332af19a96183787e01ef9080fb0",
        "Title": "Contour-Aware Long-Term Tracking With Reliable Re-Detection",
        "Abstract": "Recently discriminative correlation filter (DCF) based methods have gained much popularity for their excellent performance and high efficiency. However, most of them perform poorly in long-term tracking as they are not equipped with an effective mechanism to evaluate the quality of tracking results and correct tracking errors. To resolve such issue, this paper proposes a long-term tracking method, which consists of two components, including tracking-by-detection and re-detection. The tracking\u2026\u00a0",
        "Publication Year": "1 December 2020",
        "Citation Count": "6",
        "Reference Count": "60",
        "Authors": [
            "Feng Tang",
            "Qiang Ling"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "46fc2e550dd695eaa899a07a01e306a48b73b656",
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "d806cde30daef5ca1255c6a36c34c2931fd63604",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "d220d7accf5efa65d9b06dc19dce4203642ad238",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "b16a583ee173f222c690242aaff7925838893fe8",
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "ece7625a346edbc5f6fab541c0c246ec06939121"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/RGBD-Object-Tracking%3A-An-In-depth-Review-Yang-Li/dc9a66e0f329de8054f4ab845331fb7183987418",
        "ID": "dc9a66e0f329de8054f4ab845331fb7183987418",
        "Title": "RGBD Object Tracking: An In-depth Review",
        "Abstract": "\u2014RGBD object tracking is gaining momentum in computer vision research thanks to the development of depth sensors. Although numerous RGBD trackers have been pro- posed with promising performance, an in-depth review for comprehensive understanding of this area is lacking. In this paper, we \ufb01rstly review RGBD object trackers from different perspectives, including RGBD fusion, depth usage, and tracking framework. Then, we summarize the existing datasets and the evaluation metrics. We benchmark a\u2026\u00a0",
        "Publication Year": "26 March 2022",
        "Citation Count": "2",
        "Reference Count": "75",
        "Authors": [
            "Jinyu Yang",
            "Zhe Li",
            "Song Yan",
            "Feng Zheng",
            "Alevs Leonardis",
            "Joni-Kristian Kamarainen",
            "Ling Shao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "625aec94369715717158843c3ee288869cbe098f",
            "f33b4ba5efdef921383bde48ed1ed4edff86edb9",
            "487eb86379e979a72ebfef67db6eb8f048d1d258",
            "d884af3933148cef3b50fd38c810f5a7763d0fc9",
            "6290d7a7e353fbfe77e21e4d1086143f5e66312b",
            "f202feae9ca7b3766e072b6af657beed2236a93c",
            "c06ecdf5b149c322db0381adb6b3fd5ccb31a720",
            "7681f4c80774c6661980c5a76ffab357cca5f5cf",
            "3f02406b9b59d6f966c735953930fede1d751d0d",
            "761a9b5d8750eb63a9717650c4aaca53ce36a364"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visible-Thermal-UAV-Tracking%3A-A-Large-Scale-and-New-Zhang-Zhao/e80a02ee86f78ed5e0adfcb7f78a13c28cbedf31",
        "ID": "e80a02ee86f78ed5e0adfcb7f78a13c28cbedf31",
        "Title": "Visible-Thermal UAV Tracking: A Large-Scale Benchmark and New Baseline",
        "Abstract": "With the popularity of multi-modal sensors, visible-thermal (RGB-T) object tracking is to achieve robust performance and wider application scenarios with the guidance of objects' temperature information. However, the lack of paired training samples is the main bottleneck for unlocking the power of RGB-T tracking. Since it is laborious to collect high-quality RGB-T sequences, recent benchmarks only provide test sequences. In this paper, we construct a large-scale benchmark with high diversity\u2026\u00a0",
        "Publication Year": "8 April 2022",
        "Citation Count": "11",
        "Reference Count": "59",
        "Authors": [
            "Pengyu Zhang",
            "Jie Zhao",
            "D. Wang",
            "Huchuan Lu",
            "Xiang Ruan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "1975bee228ac228df235d20777e32331bb21566d",
            "d884af3933148cef3b50fd38c810f5a7763d0fc9",
            "27850781e39df9f750e05409b8072261124068e8",
            "3367dfef9062681c0631b91b4c8b25f5f87d1187",
            "6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "3e4384fa3b599d833bc3e9e2a7815df3236f45b5",
            "e0e50ae9508690ae3a2faf434173f2b382c93320",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "7772b2b1715a3c7d2b726136207776fdff7797ad"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/MFGNet%3A-Dynamic-Modality-Aware-Filter-Generation-Wang-Shu/35d238b9a170d7456422f32796ff41cc26f72a57",
        "ID": "35d238b9a170d7456422f32796ff41cc26f72a57",
        "Title": "MFGNet: Dynamic Modality-Aware Filter Generation for RGB-T Tracking",
        "Abstract": "Many RGB-T trackers attempt to attain robust feature representation by utilizing an adaptive weighting scheme (or attention mechanism). Different from these works, we propose a new dynamic modality-aware filter generation module (named MFGNet) to boost the message communication between visible and thermal data by adaptively adjusting the convolutional kernels for various input images in practical tracking. Given the image pairs as input, we first encode their features with the backbone network\u2026\u00a0",
        "Publication Year": "22 July 2021",
        "Citation Count": "8",
        "Reference Count": "99",
        "Authors": [
            "Xiao Wang",
            "Xiu Shu",
            "Shiliang Zhang",
            "Bo Jiang",
            "Yaowei Wang",
            "Yonghong Tian",
            "Feng Wu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "7e06006deb6d0a4b79f319713b7acacc2b7ca3a1",
            "11841185405c5d17e92110e5067b24e410d5c8de",
            "f9d1d33ced795a95a1d23df62c49c93eab46f6de",
            "fc1f0056de711b997d3e942660800e576c08892c",
            "20e503cefe30a8ac9f996f6eebbfa5df3d87112a",
            "4a8ad8a812022fb716bd4a5fd02f4919fb697c45",
            "bc40c09be4d74a0665f507447982d226fcd8f18d",
            "7772b2b1715a3c7d2b726136207776fdff7797ad",
            "e0e50ae9508690ae3a2faf434173f2b382c93320",
            "50003685fe0d72bd77eb675029da922f55b423bc"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Unsupervised-Cross-Modal-Distillation-for-Thermal-Sun-Zhang/841bd808a62a9d7da7b5075a8da0266297502785",
        "ID": "841bd808a62a9d7da7b5075a8da0266297502785",
        "Title": "Unsupervised Cross-Modal Distillation for Thermal Infrared Tracking",
        "Abstract": "The target representation learned by convolutional neural networks plays an important role in Thermal Infrared (TIR) tracking. Currently, most of the top-performing TIR trackers are still employing representations learned by the model trained on the RGB data. However, this representation does not take into account the information in the TIR modality itself, limiting the performance of TIR tracking. To solve this problem, we propose to distill representations of the TIR modality from the RGB\u2026\u00a0",
        "Publication Year": "31 July 2021",
        "Citation Count": "4",
        "Reference Count": "63",
        "Authors": [
            "Jingxian Sun",
            "Lichao Zhang",
            "Yufei Zha",
            "Abel Gonzalez-Garcia",
            "Peng Zhang",
            "Wei Huang",
            "Yanning Zhang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "abfb590702cbe0bcb14b896278faa1a254c79726",
            "ab48606313cb46884a2ab6fd22ea96a6ebb88108",
            "494bd3c8a04b7cc77c92fe0a1a00bd5380a1a088",
            "7a402bf164c0e961bde8c9d0358a64a1ede2810f",
            "3ad57901042546e8b9f21c3c4fb78a984a8a0a25",
            "4c954e814ad6e8624fed1e8b2747a631307813f8",
            "0b8708a9d4a3a72e20386d6647afd9ef57711614",
            "281388c93fcdd7eaf6cb98015b28da09ee2cc071",
            "5a3ada2d268f1b955fa4e3706d53474ded4b6c20",
            "503bafe063e410050c174fcc741e39b3b1e0eb22"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/CDTB%3A-A-Color-and-Depth-Visual-Object-Tracking-and-Luke%C5%BEi%C4%8D-Kart/f202feae9ca7b3766e072b6af657beed2236a93c",
        "ID": "f202feae9ca7b3766e072b6af657beed2236a93c",
        "Title": "CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark",
        "Abstract": "We propose a new color-and-depth general visual object tracking benchmark (CDTB). CDTB is recorded by several passive and active RGB-D setups and contains indoor as well as outdoor sequences acquired in direct sunlight. The CDTB dataset is the largest and most diverse dataset in RGB-D tracking, with an order of magnitude larger number of frames than related datasets. The sequences have been carefully recorded to contain significant object pose change, clutter, occlusion, and periods of long\u2026\u00a0",
        "Publication Year": "1 July 2019",
        "Citation Count": "44",
        "Reference Count": "45",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Ugur Kart",
            "Jani K{\\&quot;a}pyl{\\&quot;a}",
            "Ahmed Durmush",
            "J. K{\\&quot;a}m{\\&quot;a}r{\\&quot;a}inen",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "487eb86379e979a72ebfef67db6eb8f048d1d258",
            "3f02406b9b59d6f966c735953930fede1d751d0d",
            "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "3b75cf84255fce6bdc1fe998761a115437c84c77",
            "c06ecdf5b149c322db0381adb6b3fd5ccb31a720",
            "965b01ffc25e643acd16e91dd74ed0d1879f99ec",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Learning-Multi-Domain-Convolutional-Network-for-Zhang-Zhang/d8d847b085e9af12eeafc0af8df95ff2a1a98fb5",
        "ID": "d8d847b085e9af12eeafc0af8df95ff2a1a98fb5",
        "Title": "Learning Multi-Domain Convolutional Network for RGB-T Visual Tracking",
        "Abstract": "Object tracking is one of the challenging problems in the field of computer vision. Affected by the unstructured environments, for example, the occlusion, noise, and light, These factors can affect the appearance of the specific object and result in failures when tracking specific objects. To address this issue, we propose a novel visual tracking method based on multimodal convolutional network learning. Our framework adopts a parallel structure, which consists of two shallow convolutional\u2026\u00a0",
        "Publication Year": "1 October 2018",
        "Citation Count": "15",
        "Reference Count": "35",
        "Authors": [
            "Xingming Zhang",
            "Xuehan Zhang",
            "Xuedan Du",
            "Xiangming Zhou",
            "Jun Yin"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "b2180fc4f5cb46b5b5394487842399c501381d67",
            "2ce63d77eecc35faef85a3b752a314c93a077ac9",
            "2f4df08d9072fc2ac181b7fced6a245315ce05c8",
            "eb42cf88027de515750f230b23b1a057dc782108",
            "14d9be7962a4ec5a6e55755f4c7588ea00793652",
            "8d8bb90afaa7c97552bb2401cac9ff95588a87f4",
            "a87cc499cf101b3697cacc65094b4b6590e0d061",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "2822a883d149956934a20614d6934c6ddaac6857"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Learning-Target-Oriented-Dual-Attention-for-Robust-Yang-Zhu/bc40c09be4d74a0665f507447982d226fcd8f18d",
        "ID": "bc40c09be4d74a0665f507447982d226fcd8f18d",
        "Title": "Learning Target-Oriented Dual Attention for Robust RGB-T Tracking",
        "Abstract": "RGB-Thermal object tracking attempts to locate target object using complementary visual and thermal infrared data. Existing RGB-T trackers fuse different modalities by robust feature representation learning or adaptive modal weighting. However, how to integrate dual attention mechanism for visual tracking is still a subject that has not been studied yet. In this paper, we propose two visual attention mechanisms for robust RGB-T object tracking. Specifically, the local attention is implemented\u2026\u00a0",
        "Publication Year": "12 August 2019",
        "Citation Count": "25",
        "Reference Count": "24",
        "Authors": [
            "Rui Yang",
            "Yabin Zhu",
            "Xiao Wang",
            "Chenglong Li",
            "Jin Tang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "1975bee228ac228df235d20777e32331bb21566d",
            "794ed0316647a7fb1d334b7dafc38b7a2b2a5b76",
            "de30071c5d4355fbbaefbfcc6eb74f5998e34bff",
            "fc1f0056de711b997d3e942660800e576c08892c",
            "5c220558907b035bcbf61e3dab89c9128afae7f9",
            "50003685fe0d72bd77eb675029da922f55b423bc",
            "6683442ae358ae4261fdcde0164f83dd1ccd621b",
            "a5667be96826482af4af74e1d575901a3314a2eb",
            "487eb86379e979a72ebfef67db6eb8f048d1d258",
            "8d8bb90afaa7c97552bb2401cac9ff95588a87f4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Tracking-Revisited-Using-RGBD-Camera%3A-Unified-and-Song-Xiao/487eb86379e979a72ebfef67db6eb8f048d1d258",
        "ID": "487eb86379e979a72ebfef67db6eb8f048d1d258",
        "Title": "Tracking Revisited Using RGBD Camera: Unified Benchmark and Baselines",
        "Abstract": "Despite significant progress, tracking is still considered to be a very challenging task. Recently, the increasing popularity of depth sensors has made it possible to obtain reliable depth easily. This may be a game changer for tracking, since depth can be used to prevent model drift and handle occlusion. We also observe that current tracking algorithms are mostly evaluated on a very small number of videos collected and annotated by different groups. The lack of a reasonable size and\u2026\u00a0",
        "Publication Year": "1 December 2013",
        "Citation Count": "264",
        "Reference Count": "36",
        "Authors": [
            "Shuran Song",
            "Jianxiong Xiao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "0816cbac9ea8f4425d9b57fd46174cb35cd5d7cc",
            "723e52c0d0140df7a6e264f1042af89ce9277e6e",
            "9d57723b4908397654fb1846d37db403d8b2b56a",
            "804836b8ad86ef8042e3dcbd45442a52f031ee03",
            "99e25e7abdc1c0b11019733494301bf217d97d1b",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "79953b33404e563086ac063fbf53f9c926f9c0e1",
            "29e1e20323f7cb6c15c6acf5cc6573a2f84e6478",
            "d3ef059816bcf2d2b519ac36935c61a5a5e81e9b",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Jointly-Modeling-Motion-and-Appearance-Cues-for-Zhang-Zhao/d49ba5146ab759be3b257228d7095649b3d48b57",
        "ID": "d49ba5146ab759be3b257228d7095649b3d48b57",
        "Title": "Jointly Modeling Motion and Appearance Cues for Robust RGB-T Tracking",
        "Abstract": "In this study, we propose a novel RGB-T tracking framework by jointly modeling both appearance and motion cues. First, to obtain a robust appearance model, we develop a novel late fusion method to infer the fusion weight maps of both RGB and thermal (T) modalities. The fusion weights are determined by using offline-trained global and local multimodal fusion networks, and then adopted to linearly combine the response maps of RGB and T modalities. Second, when the appearance cue is unreliable, we\u2026\u00a0",
        "Publication Year": "4 July 2020",
        "Citation Count": "45",
        "Reference Count": "69",
        "Authors": [
            "Pengyu Zhang",
            "Jie Zhao",
            "Chunjuan Bo",
            "Dong Wang",
            "Huchuan Lu",
            "Xiaoyun Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "bc40c09be4d74a0665f507447982d226fcd8f18d",
            "4a8ad8a812022fb716bd4a5fd02f4919fb697c45",
            "7772b2b1715a3c7d2b726136207776fdff7797ad",
            "1975bee228ac228df235d20777e32331bb21566d",
            "1017df062cb974a167cfe546a93b57b51e514115",
            "e9fe1e0055665af44eed394fb8e665a0fb7a1d34",
            "7396eff220b9e7fce8af2bd7c0ca70e38b774240",
            "e0e50ae9508690ae3a2faf434173f2b382c93320",
            "fc1f0056de711b997d3e942660800e576c08892c",
            "7e06006deb6d0a4b79f319713b7acacc2b7ca3a1"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Multiple-human-tracking-in-RGB-depth-data%3A-a-survey-Camplani-Paiement/3fbf32a428db505e0bb45177016e8851d9b31e97",
        "ID": "3fbf32a428db505e0bb45177016e8851d9b31e97",
        "Title": "Multiple human tracking in RGB-depth data: a survey",
        "Abstract": "Multiple human tracking (MHT) is a fundamental task in many computer vision applications. Appearance-based approaches, primarily formulated on RGB data, are constrained and affected by problems arising from occlusions and/or illumination variations. In recent years, the arrival of cheap RGB-depth devices has led to many new approaches to MHT, and many of these integrate colour and depth cues to improve each and every stage of the process. In this survey, the authors present the common\u2026\u00a0",
        "Publication Year": "1 June 2017",
        "Citation Count": "40",
        "Reference Count": "102",
        "Authors": [
            "Massimo Camplani",
            "Adeline Paiement",
            "Majid Mirmehdi",
            "Dima Damen",
            "Sion L. Hannuna",
            "Tilo Burghardt",
            "Lili Tao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "92e5e98dffedffabac052c790e1d5715fa9755be",
            "487eb86379e979a72ebfef67db6eb8f048d1d258",
            "9d4519a1fd223b6ab511246afbd032d6dfbc0e56",
            "0816cbac9ea8f4425d9b57fd46174cb35cd5d7cc",
            "6a52a2d27a0d6f7f5508941998344df692216f4d",
            "99e25e7abdc1c0b11019733494301bf217d97d1b",
            "d1930c544cab14d399d25466c997b6765d6506c5",
            "2dcad5cb82da2edeb26d30c109a0d904f4c1ecb9",
            "cbae3eaf926aede9bec7ce2e28c35c1c50b1b43f",
            "35063f48447558bb573642eda0c46ae27332e275"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Long-Term-Tracking-With-Dai-Zhang/adacccd99a42c3145ec6392a1a6b08878376e38b",
        "ID": "adacccd99a42c3145ec6392a1a6b08878376e38b",
        "Title": "High-Performance Long-Term Tracking With Meta-Updater",
        "Abstract": "Long-term visual tracking has drawn increasing attention because it is much closer to practical applications than short-term tracking. Most top-ranked long-term trackers adopt the offline-trained Siamese architectures, thus,they cannot benefit from great progress of short-term trackers with online update. However, it is quite risky to straightforwardly introduce online-update-based trackers to solve the long-term problem, due to long-term uncertain and noisy observations. In this work, we\u2026\u00a0",
        "Publication Year": "1 April 2020",
        "Citation Count": "118",
        "Reference Count": "55",
        "Authors": [
            "Kenan Dai",
            "Yunhua Zhang",
            "Dong Wang",
            "Jianhua Li",
            "Huchuan Lu",
            "Xiaoyun Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "50c60583dc0ef09484358deab329f82ee22c2b66",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "383e67e0de2fdac787976543ba38bada48d046fc",
            "834baad9db5a1de1bfe993ff4a55a8a957eb9e0a",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Tracking-by-Trackers-with-a-Distilled-and-Model-Dunnhofer-Martinel/bd4f219ce6bc5c22f9da71959d5192cf0b0141fe",
        "ID": "bd4f219ce6bc5c22f9da71959d5192cf0b0141fe",
        "Title": "Tracking-by-Trackers with a Distilled and Reinforced Model",
        "Abstract": "Visual object tracking was generally tackled by reasoning independently on fast processing algorithms, accurate online adaptation methods, and fusion of trackers. In this paper, we unify such goals by proposing a novel tracking methodology that takes advantage of other visual trackers, offline and online. A compact student model is trained via the marriage of knowledge distillation and reinforcement learning. The first allows to transfer and compress tracking knowledge of other trackers. The\u2026\u00a0",
        "Publication Year": "8 July 2020",
        "Citation Count": "16",
        "Reference Count": "86",
        "Authors": [
            "Matteo Dunnhofer",
            "Niki Martinel",
            "Christian Micheloni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "eb00b8453b23d4f6f142378e2fb0f0a9e6f9c5e2",
            "1c604a8c6466d40911dc36d2522c315d6bab0f68",
            "4cbe61862bb95fc99293c24d6e02afcb50a05461",
            "f342285b29a207f6918f49b12fd49aa7d9eb0d38",
            "96dc41d3b004fd4c7f96b71b4e174beb3088b2bb",
            "d50cc385d093d84343b8eec4a01612561fa5ee09",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "a73bc57fb0aa429ba5f7f12b6d02e2c6274cabdd",
            "f2aa4dc725821980f39e27dfc23d5a0fbd4be6cf",
            "2ce63d77eecc35faef85a3b752a314c93a077ac9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Is-First-Person-Vision-Challenging-for-Object-Dunnhofer-Furnari/ca97f741f331b5b43d0577a46c05984f0785a8fa",
        "ID": "ca97f741f331b5b43d0577a46c05984f0785a8fa",
        "Title": "Is First Person Vision Challenging for Object Tracking?",
        "Abstract": "Understanding human-object interactions is fundamental in First Person Vision (FPV). Tracking algorithms which follow the objects manipulated by the camera wearer can provide useful cues to effectively model such interactions. Visual tracking solutions available in the computer vision literature have significantly improved their performance in the last years for a large variety of target objects and tracking scenarios. However, despite a few previous attempts to exploit trackers in FPV\u2026\u00a0",
        "Publication Year": "24 November 2020",
        "Citation Count": "12",
        "Reference Count": "106",
        "Authors": [
            "Matteo Dunnhofer",
            "Antonino Furnari",
            "Giovanni Maria Farinella",
            "Christian Micheloni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "50c60583dc0ef09484358deab329f82ee22c2b66",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "44990f618f46f02da321b1043a64e72d5f7c0486",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "d1e61fa7824709cae37fb59483dd0772e3101c08",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "9559f0b77932a3c5f17aeb8564b400430d173ec7"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Method-of-Stable-Long-Term-Single-Object-Tracking-Yi-Tong/c734274f43575bc5f4bcf8719f0be55a5e89be5e",
        "ID": "c734274f43575bc5f4bcf8719f0be55a5e89be5e",
        "Title": "A Method of Stable Long-Term Single Object Tracking",
        "Abstract": "We propose a stable long-term tracking method to deal with visual tracking in multiple complex scenarios to solve the problem of frequent disappearance and reappearance of targets in long-term tracking. In our method, we do not blindly start the global tracker once the target disappears, but use it only when necessary and in reasonable scope with the assistance of localization module. In addition, we designed an FP-verifier based on feature pools to reevaluate the candidate bounding boxes given\u2026\u00a0",
        "Publication Year": "5 July 2021",
        "Citation Count": "2",
        "Reference Count": "18",
        "Authors": [
            "Zitong Yi",
            "Zhihang Tong",
            "Yanyun Zhao",
            "Zhicheng Zhao",
            "Fei Su"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "6f7b23893368bd3660086c502f540256c0372ee2",
            "900ab48d25b44c076e31224b7befa503d9550c53"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/%E2%80%98Skimming-Perusal%E2%80%99-Tracking%3A-A-Framework-for-and-Yan-Zhao/09b734072ad4f610478847c9cdc59a4a0c309b37",
        "ID": "09b734072ad4f610478847c9cdc59a4a0c309b37",
        "Title": "\u2018Skimming-Perusal\u2019 Tracking: A Framework for Real-Time and Robust Long-Term Tracking",
        "Abstract": "Compared with traditional short-term tracking, long-term tracking poses more challenges and is much closer to realistic applications. However, few works have been done and their performance have also been limited. In this work, we present a novel robust and real-time long-term tracking framework based on the proposed skimming and perusal modules. The perusal module consists of an effective bounding box regressor to generate a series of candidate proposals and a robust target verifier to infer\u2026\u00a0",
        "Publication Year": "4 September 2019",
        "Citation Count": "118",
        "Reference Count": "43",
        "Authors": [
            "B. Yan",
            "Haojie Zhao",
            "Dong Wang",
            "Huchuan Lu",
            "Xiaoyun Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "e73590fdfd6dab391111bb734053ae24207e2c71",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Online-Decision-Based-Visual-Tracking-via-Learning-Song-Zhang/5b73cd259a3fa72f95e8bac9e520250b950acf3a",
        "ID": "5b73cd259a3fa72f95e8bac9e520250b950acf3a",
        "Title": "Online Decision Based Visual Tracking via Reinforcement Learning",
        "Abstract": "A deep visual tracker is typically based on either object detection or template matching while each of them is only suitable for a particular group of scenes. It is straightforward to consider fusing them together to pursue more reliable tracking. However, this is not wise as they follow different tracking principles. Unlike previous fusion-based methods, we propose a novel ensemble framework, named DTNet, with an online decision mechanism for visual tracking based on hierarchical reinforcement\u2026\u00a0",
        "Publication Year": "2020",
        "Citation Count": "12",
        "Reference Count": "41",
        "Authors": [
            "Ke Song",
            "Wei Zhang",
            "Ran Song",
            "Yibin Li"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "96dc41d3b004fd4c7f96b71b4e174beb3088b2bb",
            "a5278fc76eff08668bc1957b01b22eb627fa2c36",
            "3715dcd55475e1039b4ec98d38a3324de58a36c3",
            "6683442ae358ae4261fdcde0164f83dd1ccd621b",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "fdb98f5a7015de0956ef8d4e468257dc3079b5e5",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "bc4cfc075e406f9f5c621fe27a3e0002eec4a8b3",
            "c46b08850b9c458704a3ca69172e6a0d40a6cb7f",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/GlobalTrack%3A-A-Simple-and-Strong-Baseline-for-Huang-Zhao/5664e24cacf3f6374c26b5597765099ee9537413",
        "ID": "5664e24cacf3f6374c26b5597765099ee9537413",
        "Title": "GlobalTrack: A Simple and Strong Baseline for Long-term Tracking",
        "Abstract": "A key capability of a long-term tracker is to search for targets in very large areas (typically the entire image) to handle possible target absences or tracking failures. However, currently there is a lack of such a strong baseline for global instance search. In this work, we aim to bridge this gap. Specifically, we propose GlobalTrack, a pure global instance search based tracker that makes no assumption on the temporal consistency of the target's positions and scales. GlobalTrack is developed\u2026\u00a0",
        "Publication Year": "18 December 2019",
        "Citation Count": "125",
        "Reference Count": "35",
        "Authors": [
            "Lianghua Huang",
            "Xin Zhao",
            "Kaiqi Huang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "900ab48d25b44c076e31224b7befa503d9550c53",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "ae066f27f2edc1c51847ce4cb21b6e1a3db44fa2",
            "4b1965a54a064ac9145b1ce404fe33f0120c8ae3"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Tracking-by-Means-of-Deep-Reinforcement-and-Dunnhofer-Martinel/eb00b8453b23d4f6f142378e2fb0f0a9e6f9c5e2",
        "ID": "eb00b8453b23d4f6f142378e2fb0f0a9e6f9c5e2",
        "Title": "Visual Tracking by Means of Deep Reinforcement Learning and an Expert Demonstrator",
        "Abstract": "In the last decade many different algorithms have been proposed to track a generic object in videos. Their execution on recent large-scale video datasets can produce a great amount of various tracking behaviours. New trends in Reinforcement Learning showed that demonstrations of an expert agent can be efficiently used to speed-up the process of policy learning. Taking inspiration from such works and from the recent applications of Reinforcement Learning to visual tracking, we propose two novel\u2026\u00a0",
        "Publication Year": "18 September 2019",
        "Citation Count": "27",
        "Reference Count": "53",
        "Authors": [
            "Matteo Dunnhofer",
            "Niki Martinel",
            "Gian Luca Foresti",
            "Christian Micheloni"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "96dc41d3b004fd4c7f96b71b4e174beb3088b2bb",
            "6b0422cb93bb3426ab480ffe2009ab16f5ee22ca",
            "001d36f857ae634b98e8c629853df324c21f323f",
            "3281c2fa244834400c970f33a20aa1fb0ca2f53d",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "a9607714002b5debc0cf7b96a3def0cc6a005198",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "e3b0ea7209731c47b582215c6c67f9c691ad9863"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Visual-Object-Tracking-Benchmark-Moudgil-Gandhi/19d6b9725a59f4b624205829d5f03ac893ca1367",
        "ID": "19d6b9725a59f4b624205829d5f03ac893ca1367",
        "Title": "Long-Term Visual Object Tracking Benchmark",
        "Abstract": "We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term\u2026\u00a0",
        "Publication Year": "4 December 2017",
        "Citation Count": "74",
        "Reference Count": "47",
        "Authors": [
            "A. Moudgil",
            "Vineet Gandhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Predictive-Visual-Tracking%3A-A-New-Benchmark-and-Li-Li/19fe26d0cfe16471f4d2a05053c9f51cf14f0fa8",
        "ID": "19fe26d0cfe16471f4d2a05053c9f51cf14f0fa8",
        "Title": "Predictive Visual Tracking: A New Benchmark and Baseline Approach",
        "Abstract": "\u2014As a crucial robotic perception capability, visual tracking has been intensively studied recently. In the real-world scenarios, the onboard processing time of the image streams inevitably leads to a discrepancy between the tracking results and the real-world states. However, existing visual tracking benchmarks commonly run the trackers of\ufb02ine and ignore such latency in the evaluation. In this work, we aim to deal with a more realistic problem of latency-aware tracking. The state-of-the-art\u2026\u00a0",
        "Publication Year": "8 March 2021",
        "Citation Count": "4",
        "Reference Count": "38",
        "Authors": [
            "Bowen Li",
            "Yiming Li",
            "Junjie Ye",
            "Changhong Fu",
            "Hang Zhao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "27850781e39df9f750e05409b8072261124068e8",
            "f3d7eb617179db9f9621fa2c978dfb9f2c39341f",
            "ca97f741f331b5b43d0577a46c05984f0785a8fa",
            "86aac093dcef187bdfb296888ba2a62bccb15c81",
            "c29199b0cd3c9b60288a0b726939fa829d6c2a34",
            "2c62be4b55661e8037117d697a2c0b296453ed11"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/EgoTracks%3A-A-Long-term-Egocentric-Visual-Object-Tang-Liang/5fea6a7854c6debb8010ae217f0c83370bbca784",
        "ID": "5fea6a7854c6debb8010ae217f0c83370bbca784",
        "Title": "EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset",
        "Abstract": "Visual object tracking is a key component to many egocentric vision problems. However, the full spectrum of challenges of egocentric tracking faced by an embodied AI is underrepresented in many existing datasets; these tend to focus on relatively short, third-person videos. Egocentric video has several distinguishing characteristics from those commonly found in past datasets: frequent large camera motions and hand interactions with objects commonly lead to occlusions or objects exiting the\u2026\u00a0",
        "Publication Year": "9 January 2023",
        "Citation Count": "One",
        "Reference Count": "80",
        "Authors": [
            "Hao Tang",
            "Kevin J Liang",
            "Kristen Grauman",
            "Matt Feiszli",
            "Weiyao Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "dc47b17250b639d3a89a716c7216ef69b33f9e33",
            "72af9b2e03d3668e09edd0ec413b0b20cbce8f9c",
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "d1e61fa7824709cae37fb59483dd0772e3101c08",
            "8c0469d102e02e942a74fd319f0ac20fa9702111",
            "162dba3ef611480e959ada4ec54b0714f5564808",
            "847a153286d7f6f496f1ff61089831c267d68e30",
            "71b7178df5d2b112d07e45038cb5637208659ff7",
            "cc4e3700906008d47a73ae46a22b69d665157793",
            "c89da5aa9697ab9d5366353ec29b3e9c1b610469"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/PVT%2B%2B%3A-A-Simple-End-to-End-Latency-Aware-Visual-Li-Huang/8fa3221af7f6d3008e00cc0c459ecbde6f1014da",
        "ID": "8fa3221af7f6d3008e00cc0c459ecbde6f1014da",
        "Title": "PVT++: A Simple End-to-End Latency-Aware Visual Tracking Framework",
        "Abstract": "Visual object tracking is essential to intelligent robots. Most existing approaches have ignored the online latency that can cause severe performance degradation during real-world processing. Especially for unmanned aerial vehicles (UAVs), where robust tracking is more challenging and onboard computation is limited, the latency issue can be fatal. In this work, we present a simple framework for end-to-end latency-aware tracking, i.e., end-to-end predictive visual tracking (PVT++). Unlike\u2026\u00a0",
        "Publication Year": "21 November 2022",
        "Citation Count": "One",
        "Reference Count": "64",
        "Authors": [
            "Bowen Li",
            "Ziyuan Huang",
            "Junjie Ye",
            "Yiming Li",
            "Sebastian A. Scherer",
            "Hang Zhao",
            "Changhong Fu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "19fe26d0cfe16471f4d2a05053c9f51cf14f0fa8",
            "4ef52feb1997b1a71f1ca4d49f72a5ce4d43a8b0",
            "894e4376750b83b63649cc518b121f345ca0df83",
            "689b230b228c7ff5e2bb5d500c5349f54bcc6d3c",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "0619650ae0f698bcc38244a6858cc270df9dfaad",
            "be412c7c7128cf91455233b652d6c94a6001a7c8",
            "921901edc30c30554dc78cab724d06ea9097389f",
            "9269b52994d8af23dc17dfbc225cd25c0902686c",
            "320d05db95ab42ade69294abe46cd1aca6aca602"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/MECCANO%3A-A-Multimodal-Egocentric-Dataset-for-Humans-Ragusa-Furnari/0fd84fa8f5a24fa55c1e1fe35bf81e2126b23225",
        "ID": "0fd84fa8f5a24fa55c1e1fe35bf81e2126b23225",
        "Title": "MECCANO: A Multimodal Egocentric Dataset for Humans Behavior Understanding in the Industrial-like Domain",
        "Abstract": "Wearable cameras allow to acquire images and videos from the user\u2019s perspective. These data can be processed to understand humans behavior. Despite human behavior analysis has been thoroughly investigated in third person vision, it is still understudied in egocentric settings and in particular in industrial scenarios. To encourage research in this \ufb01eld, we present MECCANO, a multimodal dataset of egocentric videos to study humans behavior understanding in industrial-like settings. The\u2026\u00a0",
        "Publication Year": "19 September 2022",
        "Citation Count": "3",
        "Reference Count": "101",
        "Authors": [
            "Francesco Ragusa",
            "Antonino Furnari",
            "Giovanni Maria Farinella"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "a58a0732664b97b471b795df5812f98f24840490",
            "b67282a73c79438095799de916bf44ae55f1d310",
            "355f769cc896ff3ea302423587c9a1b7c2301c4e",
            "fc50c9392fd23b6c88915177c6ae904a498aacea",
            "00a6ee03c2a8d22644513f1e983d5159197b201a",
            "24c726119e21dc87d1e34bb3bb3f180e5dca66b6",
            "f2053238548ceb5d2a18353415943497985068de",
            "07cf6c4c1714a0cd88e5c1566aac9df40e111db7",
            "994481d46df92709b61614f5e756e40df4117622",
            "7ef40f47e6f20c87391dd77b6e8c081709e1b8bd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Egocentric-Prediction-of-Action-Target-in-3D-Li-Cao/ae0d3f3f13f10d72ba151405b751b273ed3e82d5",
        "ID": "ae0d3f3f13f10d72ba151405b751b273ed3e82d5",
        "Title": "Egocentric Prediction of Action Target in 3D",
        "Abstract": "We are interested in anticipating as early as possible the target location of a person's object manipulation action in a 3D workspace from egocentric vision. It is important in fields like human-robot collaboration, but has not yet received enough attention from vision and learning communities. To stimulate more research on this challenging egocentric vision task, we propose a large multimodality dataset of more than 1 million frames of RGB-D and IMU streams, and provide evaluation metrics\u2026\u00a0",
        "Publication Year": "24 March 2022",
        "Citation Count": "2",
        "Reference Count": "60",
        "Authors": [
            "Yiming Li",
            "Ziang Cao",
            "Andrew Liang",
            "Benjamin Liang",
            "Luoyao Chen",
            "Hang Zhao",
            "Chen Feng"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "73bc8e056d4318b41bb76bf270442f52e8080f82",
            "792829f263a523eedf1a8748ec23d25cf664c2b4",
            "07cf6c4c1714a0cd88e5c1566aac9df40e111db7",
            "ed78a2671ef61c031759c01434678c282f23faec",
            "994481d46df92709b61614f5e756e40df4117622",
            "a58a0732664b97b471b795df5812f98f24840490",
            "8bfa0c14c2ae48c1ee6b145008137e4d69688416",
            "6021af236342c11c44f681d2aa21b0b46756236a",
            "7ef40f47e6f20c87391dd77b6e8c081709e1b8bd",
            "98656db7128d5349822c7a59e705baf618ae2a2d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Ego4D%3A-Around-the-World-in-3%2C000-Hours-of-Video-Grauman-Westbury/847a153286d7f6f496f1ff61089831c267d68e30",
        "ID": "847a153286d7f6f496f1ff61089831c267d68e30",
        "Title": "Ego4D: Around the World in 3,000 Hours of Egocentric Video",
        "Abstract": "We introduce Ego4D, a massive-scale egocentric video dataset and benchmark suite. It offers 3,670 hours of dailylife activity video spanning hundreds of scenarios (household, outdoor, workplace, leisure, etc.) captured by 931 unique camera wearers from 74 worldwide locations and 9 different countries. The approach to collection is designed to uphold rigorous privacy and ethics standards, with consenting participants and robust de-identification procedures where relevant. Ego4D dramatically\u2026\u00a0",
        "Publication Year": "13 October 2021",
        "Citation Count": "245",
        "Reference Count": "221",
        "Authors": [
            "Kristen Grauman",
            "Andrew Westbury",
            "Eugene Byrne",
            "Zachary Q. Chavis",
            "Antonino Furnari",
            "Rohit Girdhar",
            "Jackson Hamburger",
            "Hao Jiang",
            "Miao Liu",
            "Xingyu Liu",
            "Miguel Martin",
            "Tushar Nagarajan",
            "Ilija Radosavovic",
            "Santhosh K. Ramakrishnan",
            "Fiona Ryan",
            "Jayant Sharma",
            "Michael Wray",
            "Mengmeng Xu",
            "Eric Z. Xu",
            "Chen Zhao",
            "Siddhant Bansal",
            "Dhruv Batra",
            "Vincent Cartillier",
            "Sean Crane",
            "Tien Do",
            "Morrie Doulaty",
            "Akshay Erapalli",
            "Christoph Feichtenhofer",
            "Adriano Fragomeni",
            "Qichen Fu",
            "Christian Fuegen",
            "Abrham Gebreselasie",
            "Cristina Gonz{\\&#x27;a}lez",
            "James M. Hillis",
            "Xuhua Huang",
            "Yifei Huang",
            "Wenqi Jia",
            "Weslie Khoo",
            "J{\\&#x27;a}chym Kol{\\&#x27;a}r",
            "Satwik Kottur",
            "Anurag Kumar",
            "Federico Landini",
            "Chao Li",
            "Yanghao Li",
            "Zhenqiang Li",
            "Karttikeya Mangalam",
            "Raghava Modhugu",
            "Jonathan Munro",
            "Tullie Murrell",
            "Takumi Nishiyasu",
            "Will Price",
            "Paola Ruiz Puentes",
            "Merey Ramazanova",
            "Leda Sari",
            "Kiran K. Somasundaram",
            "Audrey Southerland",
            "Yusuke Sugano",
            "Ruijie Tao",
            "Minh Vo",
            "Yuchen Wang",
            "Xindi Wu",
            "Takuma Yagi",
            "Yunyi Zhu",
            "Pablo Arbel{\\&#x27;a}ez",
            "David J. Crandall",
            "Dima Damen",
            "Giovanni Maria Farinella",
            "Bernard Ghanem",
            "Vamsi Krishna Ithapu",
            "C. V. Jawahar",
            "Hanbyul Joo",
            "Kris Kitani",
            "Haizhou Li",
            "Richard A. Newcombe",
            "Aude Oliva",
            "Hyun Soo Park",
            "James M. Rehg",
            "Yoichi Sato",
            "Jianbo Shi",
            "Mike Zheng Shou",
            "Antonio Torralba",
            "Lorenzo Torresani",
            "Mingfei Yan",
            "Jitendra Malik"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "9311779489e597315488749ee6c386bfa3f3512e",
            "54423c91d0db22193439f21d424302eab2d83b24",
            "7c9de67cc76aeecddcd07e8898acea3ef4eba738",
            "fe87da6f364417d87ecaf525e563851718ffdb07",
            "fa1723b216b1f41b085b62b450b7b0bd9f2fd281",
            "554626c58303f9fc6fc0c64595b1ab041147371f",
            "fc50c9392fd23b6c88915177c6ae904a498aacea",
            "54c7c3909c7e1e827befdbe8d2595a3b196ba1b8",
            "86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6",
            "616a23ebf79e35033c84797993943013c5dde5a0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Meta-Tracker%3A-Fast-and-Robust-Online-Adaptation-for-Park-Berg/50c60583dc0ef09484358deab329f82ee22c2b66",
        "ID": "50c60583dc0ef09484358deab329f82ee22c2b66",
        "Title": "Meta-Tracker: Fast and Robust Online Adaptation for Visual Object Trackers",
        "Abstract": "This paper improves state-of-the-art visual object trackers that use online adaptation. Our core contribution is an offline meta-learning-based method to adjust the initial deep networks used in online adaptation-based tracking. The meta learning is driven by the goal of deep networks that can quickly be adapted to robustly model a particular target in future frames. Ideally the resulting models focus on features that are useful for future frames, and avoid overfitting to background clutter\u2026\u00a0",
        "Publication Year": "9 January 2018",
        "Citation Count": "152",
        "Reference Count": "58",
        "Authors": [
            "Eunbyung Park",
            "Alexander C. Berg"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "dda27eb7ddc4510f94cac0e5134b5d56aa77b075",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "db39754bde43c5555d7086261d1a6fd55af7de06",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "1b3a107739e7f7e05c50999a3d79b8225746f662"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/D3S-%E2%80%93-A-Discriminative-Single-Shot-Segmentation-Luke%C5%BEi%C4%8D-Matas/45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "ID": "45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "Title": "D3S \u2013 A Discriminative Single Shot Segmentation Tracker",
        "Abstract": "Template-based discriminative trackers are currently the dominant tracking paradigm due to their robustness, but are restricted to bounding box tracking and a limited range of transformation models, which reduces their localization accuracy. We propose a discriminative single-shot segmentation tracker - D3S, which narrows the gap between visual object tracking and video object segmentation. A single-shot network applies two target models with complementary geometric properties, one invariant to\u2026\u00a0",
        "Publication Year": "20 November 2019",
        "Citation Count": "138",
        "Reference Count": "53",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "b3249763ac9ecc4df6ef96721c8c7410e0f0468a",
            "8b74008565b575f9ab7a0962ca5f6955d64db045",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "4a70c20ad66e5f3bb12fccd84c63ba619053c811"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/MOTChallenge%3A-A-Benchmark-for-Single-Camera-Target-Dendorfer-Osep/44990f618f46f02da321b1043a64e72d5f7c0486",
        "ID": "44990f618f46f02da321b1043a64e72d5f7c0486",
        "Title": "MOTChallenge: A Benchmark for Single-Camera Multiple Target Tracking",
        "Abstract": "Standardized benchmarks have been crucial in pushing the performance of computer vision algorithms, especially since the advent of deep learning. Although leaderboards should not be over-claimed, they often provide the most objective measure of performance and are therefore important guides for research. We present MOTChallenge, a benchmark for single-camera Multiple Object Tracking (MOT) launched in late 2014, to collect existing and new data and create a framework for the standardized\u2026\u00a0",
        "Publication Year": "15 October 2020",
        "Citation Count": "111",
        "Reference Count": "163",
        "Authors": [
            "Patrick Dendorfer",
            "Aljosa Osep",
            "Anton Milan",
            "Konrad Schindler",
            "Daniel Cremers",
            "Ian D. Reid",
            "Stefan Roth",
            "Laura Leal-Taix{\\&#x27;e}"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d11c50e49998e2156da7c179a3caea86e9601abd",
            "3fc761752fa3c3b46965d0b983f7a41758f87b86",
            "982cb4421cedce057ae2fc864efac8e43d9c0a5a",
            "ddb80e2c3e1c2ba012ff33bafaef86f02b7275b0",
            "de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42",
            "21b2e8702df2c2e3bd7ce760709bc221ea2cd52f",
            "462e13f050e89fe10180d843838b9a679ee08739",
            "0cf0ad8235929417d904acd1c672713ca4fdb105",
            "ae01c1540f7a37a95116217c60a4fbc3e3415c25",
            "c8de9f5482d9ee9c8f5422872d02723df39aad66"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Know-Your-Surroundings%3A-Exploiting-Scene-for-Object-Bhat-Danelljan/d1e61fa7824709cae37fb59483dd0772e3101c08",
        "ID": "d1e61fa7824709cae37fb59483dd0772e3101c08",
        "Title": "Know Your Surroundings: Exploiting Scene Information for Object Tracking",
        "Abstract": "Current state-of-the-art trackers only rely on a target appearance model in order to localize the object in each frame. Such approaches are however prone to fail in case of e.g. fast appearance changes or presence of distractor objects, where a target appearance model alone is insufficient for robust tracking. Having the knowledge about the presence and locations of other objects in the surrounding scene can be highly beneficial in such cases. This scene information can be propagated through\u2026\u00a0",
        "Publication Year": "24 March 2020",
        "Citation Count": "160",
        "Reference Count": "57",
        "Authors": [
            "Goutam Bhat",
            "Martin Danelljan",
            "Luc Van Gool",
            "Radu Timofte"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ba9975c8cc84a0d27ecaf23de81c76d37d50420a",
            "4b1965a54a064ac9145b1ce404fe33f0120c8ae3",
            "5c8a6874011640981e4103d120957802fa28f004",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "26c50d272883fc8f72656526f915bb283f772b27",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "503bafe063e410050c174fcc741e39b3b1e0eb22",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Online-Object-Tracking%3A-A-Benchmark-Wu-Lim/bfba194dfd9c7c27683082aa8331adc4c5963a0d",
        "ID": "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
        "Title": "Online Object Tracking: A Benchmark",
        "Abstract": "Object tracking is one of the most important components in numerous applications of computer vision. While much progress has been made in recent years with efforts on sharing code and datasets, it is of great importance to develop a library and benchmark to gauge the state of the art. After briefly reviewing recent advances of online object tracking, we carry out large scale experiments with various evaluation criteria to understand how these algorithms perform. The test image sequences are\u2026\u00a0",
        "Publication Year": "23 June 2013",
        "Citation Count": "3,598",
        "Reference Count": "66",
        "Authors": [
            "Yi Wu",
            "Jongwoo Lim",
            "Ming-Hsuan Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2822a883d149956934a20614d6934c6ddaac6857",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "237c54150e151e2c9cbfe427219a2ab5864505c6",
            "2d705458ebae2cb368a6417fe879b2400bf457c9",
            "a65c76169bdb8479353806556f61bf94fdec7e10",
            "d908f10ca52c19cd98edeef4323fb5619cfcdf9a",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "e13fc55a4dfbf933665e4555dafba558a17f9fa7",
            "257cfe2995243b2a5f91a7a423bf2853e1c05420",
            "421bf4eeba623f722bf98340d71e3d229881e92d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Struck%3A-Structured-Output-Tracking-with-Kernels-Hare-Golodetz/61394599ed0aabe04b724c7ca3a778825c7e776f",
        "ID": "61394599ed0aabe04b724c7ca3a778825c7e776f",
        "Title": "Struck: Structured Output Tracking with Kernels",
        "Abstract": "Adaptive tracking-by-detection methods are widely used in computer vision for tracking arbitrary objects. Current approaches treat the tracking problem as a classification task and use online learning techniques to update the object model. However, for these updates to happen one needs to convert the estimated object position into a set of labelled training examples, and it is not clear how best to perform this intermediate step. Furthermore, the objective for the classifier (label prediction\u2026\u00a0",
        "Publication Year": "1 October 2016",
        "Citation Count": "1,604",
        "Reference Count": "60",
        "Authors": [
            "Sam Hare",
            "Stuart Golodetz",
            "Amir Saffari",
            "Vibhav Vineet",
            "Ming-Ming Cheng",
            "Stephen L. Hicks",
            "Philip H. S. Torr"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "5b9ace65f7368f6dc6907c8f6f7c3b0c248d9bc4",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "421bf4eeba623f722bf98340d71e3d229881e92d",
            "006f283a50d325840433f4cf6d15876d475bba77",
            "16e36a4b59e214786737aa4ebc3ba86075b61e49",
            "b762ecb0624005831f2f3d8eb626d53e8eca4b6c",
            "e98cc247b597f6fdba9710fbed719c919f8bf45e",
            "c559e4099a6351837753b0a413f9bafed90f5dcd",
            "27d69a2d96600efb66fd907d8287ca3b6e734c59",
            "236d4de0b1c73217238f370e7d30243c7ee9707a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Egocentric-Object-Tracking%3A-An-Odometry-Based-Alletto-Serra/9559f0b77932a3c5f17aeb8564b400430d173ec7",
        "ID": "9559f0b77932a3c5f17aeb8564b400430d173ec7",
        "Title": "Egocentric Object Tracking: An Odometry-Based Solution",
        "Abstract": "Tracking objects moving around a person is one of the key steps in human visual augmentation: we could estimate their locations when they are out of our field of view, know their position, distance or velocity just to name a few possibilities. This is no easy task: in this paper, we show how current state-of-the-art visual tracking algorithms fail if challenged with a first-person sequence recorded from a wearable camera attached to a moving user. We propose an evaluation that highlights these\u2026\u00a0",
        "Publication Year": "7 September 2015",
        "Citation Count": "6",
        "Reference Count": "12",
        "Authors": [
            "Stefano Alletto",
            "Giuseppe Serra",
            "Rita Cucchiara"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "035c0a712e7d153cc138efea14f85e3bb98e11c7",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "089ad5baacbac0aad7076a675bec1d07ffc11307",
            "5b9ace65f7368f6dc6907c8f6f7c3b0c248d9bc4",
            "15cd7d675e499d6e53014916d7cf4a1714341f6a",
            "c6f89de36a8114787dd163f6a4d75e443ff77b74",
            "7262fd451a9da82b87b4ed03d40dd259f4ee52d6",
            "a6bcafe421ea576c360db0f3746f64a172f3c220",
            "014e1186209e4f942f3b5ba29b6b039c8e99ad88"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Towards-Sequence-Level-Training-for-Visual-Tracking-Kim-Lee/a7acd088493d06c117b839e7a62eec2de3fd8f9b",
        "ID": "a7acd088493d06c117b839e7a62eec2de3fd8f9b",
        "Title": "Towards Sequence-Level Training for Visual Tracking",
        "Abstract": ". Despite the extensive adoption of machine learning on the task of visual object tracking, recent learning-based approaches have largely overlooked the fact that visual tracking is a sequence-level task in its nature; they rely heavily on frame-level training, which inevitably induces inconsistency between training and testing in terms of both data distributions and task objectives. This work introduces a sequence-level training strategy for visual tracking based on reinforcement learning and\u2026\u00a0",
        "Publication Year": "11 August 2022",
        "Citation Count": "One",
        "Reference Count": "50",
        "Authors": [
            "Minji Kim",
            "Seungkwang Lee",
            "Jungseul Ok",
            "Bohyung Han",
            "Minsu Cho"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "81d8eb42b13b921ea9fd714c25734c9dc2fe93e2",
            "6b0422cb93bb3426ab480ffe2009ab16f5ee22ca",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "1fbb4201af091aef55360f113ba35814063923e4",
            "96dc41d3b004fd4c7f96b71b4e174beb3088b2bb",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "5b73cd259a3fa72f95e8bac9e520250b950acf3a",
            "3281c2fa244834400c970f33a20aa1fb0ca2f53d",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "be412c7c7128cf91455233b652d6c94a6001a7c8"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Accelerated-Video-Annotation-driven-by-Deep-and-Price-Ahmad/992c156a95d301634df8b1f4de9c3b6194fcf4d6",
        "ID": "992c156a95d301634df8b1f4de9c3b6194fcf4d6",
        "Title": "Accelerated Video Annotation driven by Deep Detector and Tracker",
        "Abstract": "Annotating object ground truth in videos is vital for several downstream tasks in robot perception and machine learning, such as for evaluating the performance of an object tracker or training an image-based object detector. The accuracy of the annotated instances of the moving objects on every image frame in a video is crucially important. Achieving that through manual annotations is not only very time consuming and labor intensive, but is also prone to high error rate. State-of-the-art\u2026\u00a0",
        "Publication Year": "19 February 2023",
        "Citation Count": "One",
        "Reference Count": "14",
        "Authors": [
            "Eric Price",
            "Aamir Ahmad"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "eca36815ab2a82a74d5e6284869fa638f374da0b",
            "4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0",
            "0530cbeb847f5e5002d1183c482759dff5f8c439",
            "19476caeb9305540faf84adba9a0bb12bd2c29a8",
            "b75acee3311d9f8505835c97597a16de2aeb1972",
            "bd040c9f76d3b0b77e2065089b8d344c9b5d83d6",
            "1bbedeec388ca94ae7d6131c42ad816bbbc58f92",
            "4a34bfbe37e1f0cc44b5952ac964eb6810f46737",
            "9aaa3f78117089968003c5b37cf7715ee5931392",
            "af7f1d4b57f88061a75de1d02a685842ef6f1687"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/SiamOA%3A-siamese-offset-aware-object-tracking-Zhang-Xie/53201f6a34e5bedd793f0132e3b4c59a098c2274",
        "ID": "53201f6a34e5bedd793f0132e3b4c59a098c2274",
        "Title": "SiamOA: siamese offset-aware object tracking",
        "Abstract": "Object tracking task can be divided into two subtasks: classification and regression. Some state-of-the-art methods utilize classification score and quality estimation score to select proposal box. However, their classification branches and quality estimation branches are inconsistent in the training stage and the inference stage. Besides, the existing anchor-based regression relies on a lot of prior knowledge, which aggravates the burden of trackers. To alleviate these problems, we propose a\u2026\u00a0",
        "Publication Year": "16 August 2022",
        "Citation Count": "4",
        "Reference Count": "58",
        "Authors": [
            "Jianming Zhang",
            "Xianding Xie",
            "Zhuofan Zheng",
            "Li-Dan Kuang",
            "Yudong Zhang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "738165f33c50b059e87b14d8b4a129230e14eacd",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "cce1fecc800d2782da638f3060d5b2e887739f74",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "be412c7c7128cf91455233b652d6c94a6001a7c8",
            "0530cbeb847f5e5002d1183c482759dff5f8c439",
            "cad39e1bd27156d07c384eff97517c1896496bcf",
            "da60e046aac895b5775ed34bde45beb86aad0fe8",
            "72c43972036b430ca5caafd9e674ee22f589e9c4",
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Transformers-in-Single-Object-Tracking%3A-An-Survey-Thangavel-Kokul/fc2c4aaea508973c26fe05edcb3202005e04494a",
        "ID": "fc2c4aaea508973c26fe05edcb3202005e04494a",
        "Title": "Transformers in Single Object Tracking: An Experimental Survey",
        "Abstract": "Single-object tracking is a well-known and challenging research topic in computer vision. Over the last two decades, numerous researchers have proposed various algorithms to solve this problem and achieved promising results. Recently, Transformer-based tracking approaches have ushered in a new era in single-object tracking by introducing new perspectives and achieving superior tracking robustness. In this paper, we conduct an in-depth literature analysis of Transformer tracking approaches by\u2026\u00a0",
        "Publication Year": "23 February 2023",
        "Citation Count": "One",
        "Reference Count": "101",
        "Authors": [
            "Janani Thangavel",
            "Thanikasalam Kokul",
            "Amirthalingam Ramanan",
            "Subha Fernando"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "24de23963bec39fe0e39612e2cacb76c83d66f93",
            "1af342faa6a90612651788917e4bbbd3f06f8410",
            "b6eaec7917439d79ce840fa97bc371552e9b6685",
            "9916ed982600be133ed2d185b70fe721809a3096",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "522c2da0e51f6d3d50493e7a9a2dfedb7f72e649",
            "39b27ee48caa5bb68a8c50ef5f02121729847334",
            "c1329f91cfa11011712227c8765fbbe38b9f2b7e",
            "dc47b17250b639d3a89a716c7216ef69b33f9e33"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Novel-Algorithm-Based-on-a-Common-Subspace-Fusion-Javed-Mahmood/6ad7652a8891b7b54b3ef1edeeee0e114f7da85c",
        "ID": "6ad7652a8891b7b54b3ef1edeeee0e114f7da85c",
        "Title": "A Novel Algorithm Based on a Common Subspace Fusion for Visual Object Tracking",
        "Abstract": "Recent methods for visual tracking exploit a multitude of information obtained from combinations of handcrafted and/or deep features. However, the response maps derived from these feature combinations are often fused using simple strategies such as winner-takes-all or weighted sum approaches. Although some efficient fusion methods have also been proposed, these methods still do not leverage the individual strengths of the different features being fused. In the current work, we propose a novel\u2026\u00a0",
        "Publication Year": "2022",
        "Citation Count": "3",
        "Reference Count": "78",
        "Authors": [
            "Sajid Javed",
            "A. Mahmood",
            "Ihsan Ullah",
            "Thierry Bouwmans",
            "Majid Khonji",
            "J. Dias",
            "Naoufel Werghi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "9f55546c875853100bd3921c1e3a118f9afd131c",
            "a5278fc76eff08668bc1957b01b22eb627fa2c36",
            "3aaf88163e9e502daf5be57917470c30c63da6a6",
            "7a96b5e56cd1a3964f22d0cb3a82eeddf331a5a5",
            "10a9e890e24a1196995376a0416fff0a3248787e",
            "c17b85fc95591573bc356650522d303f8d76aeb9",
            "3df8fce8e843776e39d45fb7e739a1251b565a67",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c",
            "5c8a6874011640981e4103d120957802fa28f004"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Siamese-Box-Adaptive-Network-for-Visual-Tracking-Chen-Zhong/cce1fecc800d2782da638f3060d5b2e887739f74",
        "ID": "cce1fecc800d2782da638f3060d5b2e887739f74",
        "Title": "Siamese Box Adaptive Network for Visual Tracking",
        "Abstract": "Most of the existing trackers usually rely on either a multi-scale searching scheme or pre-defined anchor boxes to accurately estimate the scale and aspect ratio of a target. Unfortunately, they typically call for tedious and heuristic configurations. To address this issue, we propose a simple yet effective visual tracking framework (named Siamese Box Adaptive Network, SiamBAN) by exploiting the expressive power of the fully convolutional network (FCN). SiamBAN views the visual tracking problem\u2026\u00a0",
        "Publication Year": "15 March 2020",
        "Citation Count": "360",
        "Reference Count": "52",
        "Authors": [
            "Zedu Chen",
            "Bineng Zhong",
            "Guorong Li",
            "Shengping Zhang",
            "Rongrong Ji"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "47a58f8bec1d34004a7d7cf837e27a26de64f0f7",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "f98be9a91dbf00b52a494720bd36be9c73a1210e",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "4b1965a54a064ac9145b1ce404fe33f0120c8ae3",
            "2e713509e96daf06e65e10bdc438d00a827c914c",
            "6683442ae358ae4261fdcde0164f83dd1ccd621b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Handcrafted-and-Deep-Trackers%3A-Recent-Visual-Object-Fiaz-Mahmood/19476caeb9305540faf84adba9a0bb12bd2c29a8",
        "ID": "19476caeb9305540faf84adba9a0bb12bd2c29a8",
        "Title": "Handcrafted and Deep Trackers: Recent Visual Object Tracking Approaches and Trends",
        "Abstract": "In recent years visual object tracking has become a very active research area. An increasing number of tracking algorithms are being proposed each year. It is because tracking has wide applications in various real world problems such as human-computer interaction, autonomous vehicles, robotics, surveillance and security just to name a few. In the current study, we review latest trends and advances in the tracking area and evaluate the robustness of different trackers based on the feature\u2026\u00a0",
        "Publication Year": "6 December 2018",
        "Citation Count": "51",
        "Reference Count": "153",
        "Authors": [
            "Mustansar Fiaz",
            "Arif Mahmood",
            "Sajid Javed",
            "Soon Ki Jung"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "6410c97ae03d356e14544c8e95f5367fb7ebb6e6",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "739d084e486702dbdad01d668f77b431228bae9d",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "f48d00ff375327c8743ade0fccf60db845f4a826",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "3812d8864b87b3c715fb59b501eaee0539be269e",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "2bcf2bd59219d89f335cbc8d1dd4f431076b4c4c"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Learning-Dynamic-Siamese-Network-for-Visual-Object-Guo-Feng/7574b7e5a75fdd338c27af5aeb77ab79460c4437",
        "ID": "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
        "Title": "Learning Dynamic Siamese Network for Visual Object Tracking",
        "Abstract": "How to effectively learn temporal variation of target appearance, to exclude the interference of cluttered background, while maintaining real-time response, is an essential problem of visual object tracking. Recently, Siamese networks have shown great potentials of matching based trackers in achieving balanced accuracy and beyond realtime speed. However, they still have a big gap to classification & updating based trackers in tolerating the temporal changes of objects and imaging conditions. In\u2026\u00a0",
        "Publication Year": "1 October 2017",
        "Citation Count": "610",
        "Reference Count": "36",
        "Authors": [
            "Qing Guo",
            "Wei Feng",
            "Ce Zhou",
            "Rui Huang",
            "Liang Wan",
            "Song Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "5c8a6874011640981e4103d120957802fa28f004",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "0f12a3aaf3851078d93a9bba4e3ebece6d4bcfe5",
            "3dc60732c1c08165c9d4e7b334ce66e511474bb2",
            "3d5fe9ef560c08f0c56249360247c7d4b40ce023",
            "c46b08850b9c458704a3ca69172e6a0d40a6cb7f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/SiamCAR%3A-Siamese-Fully-Convolutional-Classification-Guo-Wang/738165f33c50b059e87b14d8b4a129230e14eacd",
        "ID": "738165f33c50b059e87b14d8b4a129230e14eacd",
        "Title": "SiamCAR: Siamese Fully Convolutional Classification and Regression for Visual Tracking",
        "Abstract": "By decomposing the visual tracking task into two subproblems as classification for pixel category and regression for object bounding box at this pixel, we propose a novel fully convolutional Siamese network to solve visual tracking end-to-end in a per-pixel manner. The proposed framework SiamCAR consists of two simple subnetworks: one Siamese subnetwork for feature extraction and one classification-regression subnetwork for bounding box prediction. Different from state-of-the-art trackers like\u2026\u00a0",
        "Publication Year": "17 November 2019",
        "Citation Count": "295",
        "Reference Count": "42",
        "Authors": [
            "Dongyan Guo",
            "Jun Wang",
            "Ying Cui",
            "Zhenhua Wang",
            "Shengyong Chen"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "fdb98f5a7015de0956ef8d4e468257dc3079b5e5",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "f98be9a91dbf00b52a494720bd36be9c73a1210e",
            "a3a4471e82260f573d240cc34aeff431cf236571",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "53970ae69a73f547a56661fd25f6711746d277fb",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Visual-Tracking-with-Siamese-Li-Yan/320d05db95ab42ade69294abe46cd1aca6aca602",
        "ID": "320d05db95ab42ade69294abe46cd1aca6aca602",
        "Title": "High Performance Visual Tracking with Siamese Region Proposal Network",
        "Abstract": "Visual object tracking has been a fundamental topic in recent years and many deep learning based trackers have achieved state-of-the-art performance on multiple benchmarks. However, most of these trackers can hardly get top performance with real-time speed. In this paper, we propose the Siamese region proposal network (Siamese-RPN) which is end-to-end trained off-line with large-scale image pairs. Specifically, it consists of Siamese subnetwork for feature extraction and region proposal\u2026\u00a0",
        "Publication Year": "1 June 2018",
        "Citation Count": "1,566",
        "Reference Count": "41",
        "Authors": [
            "Bo Li",
            "Junjie Yan",
            "Wei Wu",
            "Zheng Zhu",
            "Xiaolin Hu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "1131c53b9baaa740a4deef4c1282821b23d18687",
            "7ccbb845829234548bfa9b24c61297b4f0cd678e",
            "5404718135548b01516a668e0c022c5cb22b422e",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "dda27eb7ddc4510f94cac0e5134b5d56aa77b075",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/SiamFC%2B%2B%3A-Towards-Robust-and-Accurate-Visual-with-Xu-Wang/be412c7c7128cf91455233b652d6c94a6001a7c8",
        "ID": "be412c7c7128cf91455233b652d6c94a6001a7c8",
        "Title": "SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines",
        "Abstract": "Visual tracking problem demands to efficiently perform robust classification and accurate target state estimation over a given target at the same time. Former methods have proposed various ways of target state estimation, yet few of them took the particularity of the visual tracking problem itself into consideration. Based on a careful analysis, we propose a set of practical guidelines of target state estimation for high-performance generic object tracker design. Following these guidelines, we\u2026\u00a0",
        "Publication Year": "14 November 2019",
        "Citation Count": "391",
        "Reference Count": "38",
        "Authors": [
            "Yinda Xu",
            "Zeyu Wang",
            "Zuoxin Li",
            "Yuan Ye",
            "Gang Yu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "900ab48d25b44c076e31224b7befa503d9550c53",
            "a87cc499cf101b3697cacc65094b4b6590e0d061",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/D3S-%E2%80%93-A-Discriminative-Single-Shot-Segmentation-Luke%C5%BEi%C4%8D-Matas/45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "ID": "45512d44f1205bc92775f2e880858b3f23c9f5fd",
        "Title": "D3S \u2013 A Discriminative Single Shot Segmentation Tracker",
        "Abstract": "Template-based discriminative trackers are currently the dominant tracking paradigm due to their robustness, but are restricted to bounding box tracking and a limited range of transformation models, which reduces their localization accuracy. We propose a discriminative single-shot segmentation tracker - D3S, which narrows the gap between visual object tracking and video object segmentation. A single-shot network applies two target models with complementary geometric properties, one invariant to\u2026\u00a0",
        "Publication Year": "20 November 2019",
        "Citation Count": "138",
        "Reference Count": "53",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "b3249763ac9ecc4df6ef96721c8c7410e0f0468a",
            "8b74008565b575f9ab7a0962ca5f6955d64db045",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "4a70c20ad66e5f3bb12fccd84c63ba619053c811"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Deep-Tracking-and-Segmentation-Approach-for-Peng-Song/b33bcf197d1ec7c432a5eda4ed07f17898fb5f4b",
        "ID": "b33bcf197d1ec7c432a5eda4ed07f17898fb5f4b",
        "Title": "A Deep Tracking and Segmentation Approach for Soccer Videos Visual Effects",
        "Abstract": "The applications of deep learning algorithm in sports contain enormous potential. Specifically, in soccer, tracking algorithm could record the tracks of players, which could play as an assistant to assess team performance and evaluate strategies. Moreover, through segmentation model, we could extract semantic attributes of players. This auxiliary information may contribute to the special visual effects processing in broadcasting or entertainment area. Unlike general tracking tasks, soccer\u2026\u00a0",
        "Publication Year": "16 October 2020",
        "Citation Count": "One",
        "Reference Count": "9",
        "Authors": [
            "Shenhui Peng",
            "Li Song",
            "Jun Ling",
            "Rong Xie",
            "Song Xu",
            "Lin Li"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "4960ab1cef23e5ccd60173725ea280f462164a0e",
            "a2fcb9088e6dca3ea850de871c08b6fa084a190e",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "cab372bc3824780cce20d9dd1c22d4df39ed081a",
            "65c9b4b1d49f46b3f8f64a5f617acfc14f85d031",
            "71b7178df5d2b112d07e45038cb5637208659ff7"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2017-Challenge-Kristan-Leonardis/350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "ID": "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "Title": "The Visual Object Tracking VOT2017 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \"real-time\" experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the\u2026\u00a0",
        "Publication Year": "1 October 2017",
        "Citation Count": "429",
        "Reference Count": "132",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andrej Muhic",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea Vedaldi",
            "Antoine Manzanera",
            "Antoine Tran",
            "Aydin Alatan",
            "Bogdan Cosmin Mocanu",
            "Boyu Chen",
            "Chang Huang",
            "Changsheng Xu",
            "Chong Sun",
            "Dalong Du",
            "Dafan Zhang",
            "Dawei Du",
            "Deepak Mishra",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Francesco Battistone",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Goutam Bhat",
            "Guan Huang",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Hongliang Zhang",
            "Houqiang Li",
            "Huchuan Lu",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jaeil Cho",
            "Jae-Y. Lee",
            "Jana Noskova",
            "Jianke Zhu",
            "Jin Gao",
            "Jingyu Liu",
            "Ji-Wan Kim",
            "Jo{\\~a}o F. Henriques",
            "Jos{\\&#x27;e} Mar{\\&#x27;i}a Mart{\\&#x27;i}nez Sanchez",
            "Junfei Zhuang",
            "Junliang Xing",
            "Junyu Gao",
            "Kai Chen",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Kris Kitani",
            "Lei Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh Poostchi",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Ming-Hsuan Yang",
            "Nianhao Xie",
            "Ning Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "Pallavi M. Venugopal",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Qifeng Yu",
            "Qingming Huang",
            "Rafael Martin Nieto",
            "R. Bowden",
            "Risheng Liu",
            "Ruxandra Tapu",
            "Simon Hadfield",
            "Siwei Lyu",
            "Stuart Golodetz",
            "Sunglok Choi",
            "Tianzhu Zhang",
            "Titus B. Zaharia",
            "Vincenzo Santopietro",
            "Wei Zou",
            "Weiming Hu",
            "Wenbing Tao",
            "Wenbo Li",
            "Wen-gang Zhou",
            "Xianguo Yu",
            "Xiao Bian",
            "Yang Li",
            "Yifan Xing",
            "Yingruo Fan",
            "Zhengyu Zhu",
            "Zhipeng Zhang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/MOT20%3A-A-benchmark-for-multi-object-tracking-in-Dendorfer-Rezatofighi/d11c50e49998e2156da7c179a3caea86e9601abd",
        "ID": "d11c50e49998e2156da7c179a3caea86e9601abd",
        "Title": "MOT20: A benchmark for multi object tracking in crowded scenes",
        "Abstract": "Standardized benchmarks are crucial for the majority of computer vision applications. Although leaderboards and ranking tables should not be over-claimed, benchmarks often provide the most objective measure of performance and are therefore important guides for research. The benchmark for Multiple Object Tracking, MOTChallenge, was launched with the goal to establish a standardized evaluation of multiple object tracking methods. The challenge focuses on multiple people tracking, since\u2026\u00a0",
        "Publication Year": "19 March 2020",
        "Citation Count": "311",
        "Reference Count": "17",
        "Authors": [
            "Patrick Dendorfer",
            "Hamid Rezatofighi",
            "Anton Milan",
            "Javen Qinfeng Shi",
            "Daniel Cremers",
            "Ian D. Reid",
            "Stefan Roth",
            "Konrad Schindler",
            "Laura Leal-Taix&#x27;e"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ac0d88ca5f75a4a80da90365c28fa26f1a26d4c4",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d",
            "2258e01865367018ed6f4262c880df85b94959f8",
            "616fda61990097f0401b33dbf01541bd83a939a0",
            "aa574e55ea3401ec9bc500eed990e4f402730d26",
            "1e417f05a5d4f3642237d2231122c7b09c2e348a",
            "616b246e332573af1f4859aa91440280774c183a",
            "9b49f70bcaf6e473930681b9a0562f130ae01533",
            "a06d56ba4daafbfa0cf02d1640b840504b2cb089",
            "a56bace35df401cc77d854327800f977fa279eb3"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/MOTChallenge-2015%3A-Towards-a-Benchmark-for-Tracking-Leal-Taix%C3%A9-Milan/5bae9822d703c585a61575dced83fa2f4dea1c6d",
        "ID": "5bae9822d703c585a61575dced83fa2f4dea1c6d",
        "Title": "MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking",
        "Abstract": "In the recent past, the computer vision community has developed centralized benchmarks for the performance evaluation of a variety of tasks, including generic object and pedestrian detection, 3D reconstruction, optical flow, single-object short-term tracking, and stereo estimation. Despite potential pitfalls of such benchmarks, they have proved to be extremely helpful to advance the state of the art in the respective area. Interestingly, there has been rather limited work on the standardization\u2026\u00a0",
        "Publication Year": "8 April 2015",
        "Citation Count": "614",
        "Reference Count": "57",
        "Authors": [
            "Laura Leal-Taix{\\&#x27;e}",
            "Anton Milan",
            "Ian D. Reid",
            "Stefan Roth",
            "Konrad Schindler"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3e083dc8aeb7983a5cdff146985363d38caf0886",
            "2258e01865367018ed6f4262c880df85b94959f8",
            "de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42",
            "aa574e55ea3401ec9bc500eed990e4f402730d26",
            "616fda61990097f0401b33dbf01541bd83a939a0",
            "0302bb2d5476540cfb21467473f5eca843caf90b",
            "5b1e33f60514a307054de5642a13051c1e1438b6",
            "9b49f70bcaf6e473930681b9a0562f130ae01533",
            "b238f3f2a487271973c573634611229c432cf467",
            "f042e85c26cd3638fcdc6599aa546d85045a7c5d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Know-Your-Surroundings%3A-Exploiting-Scene-for-Object-Bhat-Danelljan/d1e61fa7824709cae37fb59483dd0772e3101c08",
        "ID": "d1e61fa7824709cae37fb59483dd0772e3101c08",
        "Title": "Know Your Surroundings: Exploiting Scene Information for Object Tracking",
        "Abstract": "Current state-of-the-art trackers only rely on a target appearance model in order to localize the object in each frame. Such approaches are however prone to fail in case of e.g. fast appearance changes or presence of distractor objects, where a target appearance model alone is insufficient for robust tracking. Having the knowledge about the presence and locations of other objects in the surrounding scene can be highly beneficial in such cases. This scene information can be propagated through\u2026\u00a0",
        "Publication Year": "24 March 2020",
        "Citation Count": "160",
        "Reference Count": "57",
        "Authors": [
            "Goutam Bhat",
            "Martin Danelljan",
            "Luc Van Gool",
            "Radu Timofte"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ba9975c8cc84a0d27ecaf23de81c76d37d50420a",
            "4b1965a54a064ac9145b1ce404fe33f0120c8ae3",
            "5c8a6874011640981e4103d120957802fa28f004",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "26c50d272883fc8f72656526f915bb283f772b27",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "503bafe063e410050c174fcc741e39b3b1e0eb22",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Detecting-Events-and-Key-Actors-in-Multi-person-Ramanathan-Huang/195df1106f4d7aff0e9cb609358abbf80f54a716",
        "ID": "195df1106f4d7aff0e9cb609358abbf80f54a716",
        "Title": "Detecting Events and Key Actors in Multi-person Videos",
        "Abstract": "Multi-person event recognition is a challenging task, often with many people active in the scene but only a small subset contributing to an actual event. In this paper, we propose a model which learns to detect events in such videos while automatically \"attending\" to the people responsible for the event. Our model does not use explicit annotations regarding who or where those people are during training and testing. In particular, we track people in videos and use a recurrent neural network (RNN\u2026\u00a0",
        "Publication Year": "9 November 2015",
        "Citation Count": "186",
        "Reference Count": "75",
        "Authors": [
            "Vignesh Ramanathan",
            "Jonathan Huang",
            "Sami Abu-El-Haija",
            "Alexander N. Gorban",
            "Kevin P. Murphy",
            "Li Fei-Fei"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2c305fa65fed336e6be1d15a6567075c6ea6e51b",
            "906e03d61d6a87b09cf7920d882f09fcedc8223d",
            "10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f",
            "08e61adbfa2178e3fa895a7f85a84597c183aede",
            "0f86767732f76f478d5845f2e59f99ba106e9265",
            "0f930a56632a7e436a2b3d39f3383f0adcc54306",
            "bd243d77076b3b8fe046bd3dc6e8a02aa9b38d62",
            "d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68",
            "38ee79ef860def18e026e0e72188cd93e14b640d",
            "a39e6968580762ac5ae3cd064e86e1849f3efb7f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Graph-Attention-Tracking-Guo-Shao/37929e9283d214a1688bd6fa9759cd6e89b2312d",
        "ID": "37929e9283d214a1688bd6fa9759cd6e89b2312d",
        "Title": "Graph Attention Tracking",
        "Abstract": "Siamese network based trackers formulate the visual tracking task as a similarity matching problem. Almost all popular Siamese trackers realize the similarity learning via convolutional feature cross-correlation between a target branch and a search branch. However, since the size of target feature region needs to be pre-fixed, these cross-correlation base methods suffer from either reserving much adverse background information or missing a great deal of foreground information. Moreover, the\u2026\u00a0",
        "Publication Year": "23 November 2020",
        "Citation Count": "131",
        "Reference Count": "36",
        "Authors": [
            "Dongyan Guo",
            "Yan Shao",
            "Ying Cui",
            "Zhenhua Wang",
            "Liyan Zhang",
            "Chunhua Shen"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "53970ae69a73f547a56661fd25f6711746d277fb",
            "a3a4471e82260f573d240cc34aeff431cf236571",
            "8dbb2a1939a60f56d0508f597d99c3dc2c27aa61",
            "cce1fecc800d2782da638f3060d5b2e887739f74",
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "738165f33c50b059e87b14d8b4a129230e14eacd",
            "6683442ae358ae4261fdcde0164f83dd1ccd621b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/EgoTracks%3A-A-Long-term-Egocentric-Visual-Object-Tang-Liang/5fea6a7854c6debb8010ae217f0c83370bbca784",
        "ID": "5fea6a7854c6debb8010ae217f0c83370bbca784",
        "Title": "EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset",
        "Abstract": "Visual object tracking is a key component to many egocentric vision problems. However, the full spectrum of challenges of egocentric tracking faced by an embodied AI is underrepresented in many existing datasets; these tend to focus on relatively short, third-person videos. Egocentric video has several distinguishing characteristics from those commonly found in past datasets: frequent large camera motions and hand interactions with objects commonly lead to occlusions or objects exiting the\u2026\u00a0",
        "Publication Year": "9 January 2023",
        "Citation Count": "One",
        "Reference Count": "80",
        "Authors": [
            "Hao Tang",
            "Kevin J Liang",
            "Kristen Grauman",
            "Matt Feiszli",
            "Weiyao Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "dc47b17250b639d3a89a716c7216ef69b33f9e33",
            "72af9b2e03d3668e09edd0ec413b0b20cbce8f9c",
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "d1e61fa7824709cae37fb59483dd0772e3101c08",
            "8c0469d102e02e942a74fd319f0ac20fa9702111",
            "162dba3ef611480e959ada4ec54b0714f5564808",
            "847a153286d7f6f496f1ff61089831c267d68e30",
            "71b7178df5d2b112d07e45038cb5637208659ff7",
            "cc4e3700906008d47a73ae46a22b69d665157793",
            "c89da5aa9697ab9d5366353ec29b3e9c1b610469"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Transparent-Object-Tracking-Benchmark-Fan-Miththanthaya/ce1da08be62183845cac70b7236ee9de5f2dde43",
        "ID": "ce1da08be62183845cac70b7236ee9de5f2dde43",
        "Title": "Transparent Object Tracking Benchmark",
        "Abstract": "Visual tracking has achieved considerable progress in recent years. However, current research in the field mainly focuses on tracking of opaque objects, while little attention is paid to transparent object tracking. In this paper, we make the first attempt in exploring this problem by proposing a Transparent Object Tracking Benchmark (TOTB). Specifically, TOTB consists of 225 videos (86K frames) from 15 diverse transparent object categories. Each sequence is manually labeled with axis-aligned\u2026\u00a0",
        "Publication Year": "21 November 2020",
        "Citation Count": "10",
        "Reference Count": "63",
        "Authors": [
            "Heng Fan",
            "Halady Akhilesha Miththanthaya",
            "Harshit",
            "Siranjiv Ramana Rajan",
            "Xiaoqiong Liu",
            "Zhilin Zou",
            "Yuewei Lin",
            "Haibin Ling"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "f46318bf67ab6b30284f125ac8bb6f9a7503595e",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "e284bc13c2b76d0d0c7ad61d976f8a9d3eef8461",
            "900ab48d25b44c076e31224b7befa503d9550c53",
            "487eb86379e979a72ebfef67db6eb8f048d1d258"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Tracking%3A-An-Experimental-Survey-Smeulders-Chu/eda3368a5198ca55768b07b6f5667aea28baf2cd",
        "ID": "eda3368a5198ca55768b07b6f5667aea28baf2cd",
        "Title": "Visual Tracking: An Experimental Survey",
        "Abstract": "There is a large variety of trackers, which have been proposed in the literature during the last two decades with some mixed success. Object tracking in realistic scenarios is a difficult problem, therefore, it remains a most active area of research in computer vision. A good tracker should perform well in a large number of videos involving illumination changes, occlusion, clutter, camera motion, low contrast, specularities, and at least six more aspects. However, the performance of proposed\u2026\u00a0",
        "Publication Year": "1 July 2014",
        "Citation Count": "1,443",
        "Reference Count": "120",
        "Authors": [
            "Arnold W. M. Smeulders",
            "Dung Manh Chu",
            "Rita Cucchiara",
            "Simone Calderara",
            "Afshin Dehghan",
            "Mubarak Shah"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2258e01865367018ed6f4262c880df85b94959f8",
            "b762ecb0624005831f2f3d8eb626d53e8eca4b6c",
            "a52a6cf39054e6f406f67b57cc895e9df1163fc8",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "45e098084c676eee87a71806b7eb7ec03f0410c9",
            "68cc57640bfd04f697048534f82d16bf10a002ec",
            "8f1a4c9be59b43175c86954829690084ac1e8a1a",
            "da199480427da6b4c3800b11a91ef7f9bbbc90ee",
            "21d467174bdcf882eefcae2f10c23a1af5b3e73d",
            "070375a20acf9252f903164586c75110472cd84f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Egocentric-Object-Tracking%3A-An-Odometry-Based-Alletto-Serra/9559f0b77932a3c5f17aeb8564b400430d173ec7",
        "ID": "9559f0b77932a3c5f17aeb8564b400430d173ec7",
        "Title": "Egocentric Object Tracking: An Odometry-Based Solution",
        "Abstract": "Tracking objects moving around a person is one of the key steps in human visual augmentation: we could estimate their locations when they are out of our field of view, know their position, distance or velocity just to name a few possibilities. This is no easy task: in this paper, we show how current state-of-the-art visual tracking algorithms fail if challenged with a first-person sequence recorded from a wearable camera attached to a moving user. We propose an evaluation that highlights these\u2026\u00a0",
        "Publication Year": "7 September 2015",
        "Citation Count": "6",
        "Reference Count": "12",
        "Authors": [
            "Stefano Alletto",
            "Giuseppe Serra",
            "Rita Cucchiara"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "035c0a712e7d153cc138efea14f85e3bb98e11c7",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "089ad5baacbac0aad7076a675bec1d07ffc11307",
            "5b9ace65f7368f6dc6907c8f6f7c3b0c248d9bc4",
            "15cd7d675e499d6e53014916d7cf4a1714341f6a",
            "c6f89de36a8114787dd163f6a4d75e443ff77b74",
            "7262fd451a9da82b87b4ed03d40dd259f4ee52d6",
            "a6bcafe421ea576c360db0f3746f64a172f3c220",
            "014e1186209e4f942f3b5ba29b6b039c8e99ad88"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Online-Object-Tracking%3A-A-Benchmark-Wu-Lim/bfba194dfd9c7c27683082aa8331adc4c5963a0d",
        "ID": "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
        "Title": "Online Object Tracking: A Benchmark",
        "Abstract": "Object tracking is one of the most important components in numerous applications of computer vision. While much progress has been made in recent years with efforts on sharing code and datasets, it is of great importance to develop a library and benchmark to gauge the state of the art. After briefly reviewing recent advances of online object tracking, we carry out large scale experiments with various evaluation criteria to understand how these algorithms perform. The test image sequences are\u2026\u00a0",
        "Publication Year": "23 June 2013",
        "Citation Count": "3,598",
        "Reference Count": "66",
        "Authors": [
            "Yi Wu",
            "Jongwoo Lim",
            "Ming-Hsuan Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2822a883d149956934a20614d6934c6ddaac6857",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "237c54150e151e2c9cbfe427219a2ab5864505c6",
            "2d705458ebae2cb368a6417fe879b2400bf457c9",
            "a65c76169bdb8479353806556f61bf94fdec7e10",
            "d908f10ca52c19cd98edeef4323fb5619cfcdf9a",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "e13fc55a4dfbf933665e4555dafba558a17f9fa7",
            "257cfe2995243b2a5f91a7a423bf2853e1c05420",
            "421bf4eeba623f722bf98340d71e3d229881e92d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/EYEWATCHME%E2%80%943D-Hand-and-object-tracking-for-inside-Sun-Klank/b90010d61509bcacff64003b7e31e817487ea018",
        "ID": "b90010d61509bcacff64003b7e31e817487ea018",
        "Title": "EYEWATCHME\u20143D Hand and object tracking for inside out activity analysis",
        "Abstract": "This paper investigates the \u201cinside-out\u201d recognition of everyday manipulation tasks using a gaze-directed camera, which is a camera that actively directs at the visual attention focus of the person wearing the camera. We present EYEWATCHME, an integrated vision and state estimation system that at the same time tracks the positions and the poses of the acting hands, the pose that the manipulated object, and the pose of the observing camera. Taken together, EYEWATCHME provides comprehensive data\u2026\u00a0",
        "Publication Year": "20 June 2009",
        "Citation Count": "51",
        "Reference Count": "16",
        "Authors": [
            "Li Sun",
            "Ulrich Klank",
            "Michael Beetz"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "1af1ada3d7232a1bb9b8bdc7e29fb5842dacf033",
            "fa7c6369ed7c781b3353111ce5a2cd28eca80e12",
            "df748027eebf7b7d4545f7b6f878f5abe7c0f4b4",
            "c9ae535089e641f8059b293216c74326765b4dc7",
            "febec389afdbcfd27f74d14e0ff245fba8ea785d",
            "36c22fa5789a85cf79c07f550801b3f0ccc9c9fc",
            "0132e68e6adf3d087d45f3b1c4803d4140c55e0a",
            "d455da91b83f1852d340dfd64a31fd61a82c380a",
            "583dbd03a342c522ee8cd43d3f532b666afdb140",
            "facd94b9358a0519f0db0ef9da43ea813a5daebf"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Meta-Tracker%3A-Fast-and-Robust-Online-Adaptation-for-Park-Berg/50c60583dc0ef09484358deab329f82ee22c2b66",
        "ID": "50c60583dc0ef09484358deab329f82ee22c2b66",
        "Title": "Meta-Tracker: Fast and Robust Online Adaptation for Visual Object Trackers",
        "Abstract": "This paper improves state-of-the-art visual object trackers that use online adaptation. Our core contribution is an offline meta-learning-based method to adjust the initial deep networks used in online adaptation-based tracking. The meta learning is driven by the goal of deep networks that can quickly be adapted to robustly model a particular target in future frames. Ideally the resulting models focus on features that are useful for future frames, and avoid overfitting to background clutter\u2026\u00a0",
        "Publication Year": "9 January 2018",
        "Citation Count": "152",
        "Reference Count": "58",
        "Authors": [
            "Eunbyung Park",
            "Alexander C. Berg"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "dda27eb7ddc4510f94cac0e5134b5d56aa77b075",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "db39754bde43c5555d7086261d1a6fd55af7de06",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "1b3a107739e7f7e05c50999a3d79b8225746f662"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Tracking-Learning-Detection-Kalal/c63a34ac6a4e049118070e707ca7679fbb132d33",
        "ID": "c63a34ac6a4e049118070e707ca7679fbb132d33",
        "Title": "Tracking-Learning-Detection",
        "Abstract": "This paper investigates long-term tracking of unknown objects in a video stream. The object is defined by its location and extent in a single frame. In every frame that follows, the task is to determine the object's location and extent or indicate that the object is not present. We propose a novel tracking framework (TLD) that explicitly decomposes the long-term tracking task into tracking, learning, and detection. The tracker follows the object from frame to frame. The detector localizes all\u2026\u00a0",
        "Publication Year": "1 July 2012",
        "Citation Count": "3,039",
        "Reference Count": "148",
        "Authors": [
            "Zdenek Kalal"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "03f9c789ae36196e3e6669c49370b8d48fcf26a2",
            "421bf4eeba623f722bf98340d71e3d229881e92d",
            "17d65b2f276bc3b92f4a92567becc4fe41ffcb69",
            "eaf10795a2a34ba6638fd79815d4b81e20eb5955",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "6d0db7dc45147d5d5680a0918fc1a1e23b0124d2",
            "59d710f21659460f6c368d2d50bcf47ea8b45690",
            "5029362f4e0966d21a2ebf788bfadb5ae55697aa",
            "d908f10ca52c19cd98edeef4323fb5619cfcdf9a",
            "719b816653c43cd0b0298d1092bb1479a1049fdb"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-robust-spatial-temporal-correlation-filter-for-Chen-Liu/1e318864509718478dbf363fee229594a7fda5d3",
        "ID": "1e318864509718478dbf363fee229594a7fda5d3",
        "Title": "A robust spatial-temporal correlation filter tracker for efficient UAV visual tracking",
        "Abstract": "Correlation filters (CFs) have exhibited remarkable performance in visual target tracking, especially in aerial tracking of unmanned aerial vehicles (UAVs). Most existing CF-based trackers focus on how to effectively settle the unwanted boundary effect problem, while ignoring the different contributions of the discriminative features, which would lead to suboptimal performance in tracking. In this work, a robust spatial-temporal correlation filter, i.e., the temporal regularized background\u2026\u00a0",
        "Publication Year": "10 June 2022",
        "Citation Count": "2",
        "Reference Count": "52",
        "Authors": [
            "Lin Chen",
            "Yung-Wha Liu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "0619650ae0f698bcc38244a6858cc270df9dfaad",
            "0b6b9484a909943908f002dd152d2bcdf501ff96",
            "bbc97484fe622da1e07cf5816ecd8e6b32235d78",
            "9f45b55af027503fab557f55f70e81e43c6c1db7",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "9af31cba16dc857d96c28c5161c4e73af848a8aa",
            "3b4b9d403be348d87d21cf69a8a789f118131e29",
            "43eb56d0dfdb1d5c78a0d2acb43b436f2d5c4ecf",
            "0cae491292feccbc9ad1d864cf8b7144923ce6de",
            "6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Adversarial-Blur-Deblur-Network-for-Robust-UAV-Zuo-Fu/f06a22165f0bcc92eac865e3eeddec3c7e2cf44c",
        "ID": "f06a22165f0bcc92eac865e3eeddec3c7e2cf44c",
        "Title": "Adversarial Blur-Deblur Network for Robust UAV Tracking",
        "Abstract": "Unmanned aerial vehicle (UAV) tracking has been widely applied in real-world applications such as surveillance and monitoring. However, the inherent high maneuverability and agility of UAV often lead to motion blur, which can impair the visual appearance of the target object and easily degrade the existing trackers. To overcome this challenge, this work proposes a tracking-oriented adversarial blur-deblur network (ABDNet), composed of a novel deblurrer to recover the visual appearance of the\u2026\u00a0",
        "Publication Year": "1 February 2023",
        "Citation Count": "2",
        "Reference Count": "38",
        "Authors": [
            "Haobo Zuo",
            "Changhong Fu",
            "Sihang Li",
            "Kunhan Lu",
            "Yiming Li",
            "Chen Feng"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "235a720e00c1d770afcc199b7badbc994d22b505",
            "0f142d13437d01e11ccfb2ec735f37da5ffb298b",
            "14d3b8af761ee4a7b780ad1f4a059c89a17db296",
            "827ee2cdc56ea65ef644bd8ca085f4274b106f03",
            "1171234cb2f3e1589592e3d04eb10c132fc6a5c8",
            "1b3a7e6ebd89a1fb03c992110952d7bddae3345a",
            "0619650ae0f698bcc38244a6858cc270df9dfaad",
            "4d57a810cd768b5ad4de6d1e21673f3d3b89f00d",
            "cce1fecc800d2782da638f3060d5b2e887739f74",
            "6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Mutual-Information-Learned-Classifiers%3A-an-of-Deep-Yi-Zhang/1b412b76087530a1969517da271393519f30fad1",
        "ID": "1b412b76087530a1969517da271393519f30fad1",
        "Title": "Mutual Information Learned Classifiers: an Information-theoretic Viewpoint of Training Deep Learning Classification Systems",
        "Abstract": "Deep learning systems have been reported to achieve state-of- the-art performances in many applications, and a key is the existence of well trained classi\ufb01ers on benchmark datasets. As a main-stream loss function, the cross entropy can easily lead us to \ufb01nd models which demonstrate severe over\ufb01tting behavior. In this paper, we show that the existing cross entropy loss minimization problem essentially learns the label conditional entropy (CE) of the underlying data distribution of the dataset\u2026\u00a0",
        "Publication Year": "21 September 2022",
        "Citation Count": "One",
        "Reference Count": "61",
        "Authors": [
            "Jirong Yi",
            "Qiaosheng Eric Zhang",
            "Zhenji Chen",
            "Qiaoan Liu",
            "Weizhuo Shao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "39000df05781f49365cb1b223d228dd9b859efc4",
            "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "611d94856a234eed829db59ce5aaa9ce48969b47",
            "f6e0856b4a9199fa968ac00da612a9407b5cb85c",
            "372bf2716c53e353be6c3f027493f1a40edb6640",
            "c1cbdf90813c8da1f46019748b1316986d83da0a",
            "a4cec122a08216fe8a3bc19b22e78fbaea096256",
            "ee7e6452b24f781d4b6671b90f27f60aed7b1ef8",
            "b582edb16f5425642767cb6c26839111f867f4dc",
            "8bddd0afd064e2d45ab6cf9510f2631f7438c17b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/GlobalTrack%3A-A-Simple-and-Strong-Baseline-for-Huang-Zhao/5664e24cacf3f6374c26b5597765099ee9537413",
        "ID": "5664e24cacf3f6374c26b5597765099ee9537413",
        "Title": "GlobalTrack: A Simple and Strong Baseline for Long-term Tracking",
        "Abstract": "A key capability of a long-term tracker is to search for targets in very large areas (typically the entire image) to handle possible target absences or tracking failures. However, currently there is a lack of such a strong baseline for global instance search. In this work, we aim to bridge this gap. Specifically, we propose GlobalTrack, a pure global instance search based tracker that makes no assumption on the temporal consistency of the target's positions and scales. GlobalTrack is developed\u2026\u00a0",
        "Publication Year": "18 December 2019",
        "Citation Count": "125",
        "Reference Count": "35",
        "Authors": [
            "Lianghua Huang",
            "Xin Zhao",
            "Kaiqi Huang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "900ab48d25b44c076e31224b7befa503d9550c53",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "ae066f27f2edc1c51847ce4cb21b6e1a3db44fa2",
            "4b1965a54a064ac9145b1ce404fe33f0120c8ae3"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Tracking-Learning-Detection-Kalal/c63a34ac6a4e049118070e707ca7679fbb132d33",
        "ID": "c63a34ac6a4e049118070e707ca7679fbb132d33",
        "Title": "Tracking-Learning-Detection",
        "Abstract": "This paper investigates long-term tracking of unknown objects in a video stream. The object is defined by its location and extent in a single frame. In every frame that follows, the task is to determine the object's location and extent or indicate that the object is not present. We propose a novel tracking framework (TLD) that explicitly decomposes the long-term tracking task into tracking, learning, and detection. The tracker follows the object from frame to frame. The detector localizes all\u2026\u00a0",
        "Publication Year": "1 July 2012",
        "Citation Count": "3,039",
        "Reference Count": "148",
        "Authors": [
            "Zdenek Kalal"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "03f9c789ae36196e3e6669c49370b8d48fcf26a2",
            "421bf4eeba623f722bf98340d71e3d229881e92d",
            "17d65b2f276bc3b92f4a92567becc4fe41ffcb69",
            "eaf10795a2a34ba6638fd79815d4b81e20eb5955",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "6d0db7dc45147d5d5680a0918fc1a1e23b0124d2",
            "59d710f21659460f6c368d2d50bcf47ea8b45690",
            "5029362f4e0966d21a2ebf788bfadb5ae55697aa",
            "d908f10ca52c19cd98edeef4323fb5619cfcdf9a",
            "719b816653c43cd0b0298d1092bb1479a1049fdb"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/%E2%80%98Skimming-Perusal%E2%80%99-Tracking%3A-A-Framework-for-and-Yan-Zhao/09b734072ad4f610478847c9cdc59a4a0c309b37",
        "ID": "09b734072ad4f610478847c9cdc59a4a0c309b37",
        "Title": "\u2018Skimming-Perusal\u2019 Tracking: A Framework for Real-Time and Robust Long-Term Tracking",
        "Abstract": "Compared with traditional short-term tracking, long-term tracking poses more challenges and is much closer to realistic applications. However, few works have been done and their performance have also been limited. In this work, we present a novel robust and real-time long-term tracking framework based on the proposed skimming and perusal modules. The perusal module consists of an effective bounding box regressor to generate a series of candidate proposals and a robust target verifier to infer\u2026\u00a0",
        "Publication Year": "4 September 2019",
        "Citation Count": "118",
        "Reference Count": "43",
        "Authors": [
            "B. Yan",
            "Haojie Zhao",
            "Dong Wang",
            "Huchuan Lu",
            "Xiaoyun Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "e73590fdfd6dab391111bb734053ae24207e2c71",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Saliency-Associated-Object-Tracking-Zhou-Pei/48c6ca17f17038ff9933dca86a23f8516168a3ea",
        "ID": "48c6ca17f17038ff9933dca86a23f8516168a3ea",
        "Title": "Saliency-Associated Object Tracking",
        "Abstract": "Most existing trackers based on deep learning perform tracking in a holistic strategy, which aims to learn deep representations of the whole target for localizing the target. It is arduous for such methods to track targets with various appearance variations. To address this limitation, another type of methods adopts a part-based tracking strategy which divides the target into equal patches and tracks all these patches in parallel. The target state is inferred by summarizing the tracking results\u2026\u00a0",
        "Publication Year": "8 August 2021",
        "Citation Count": "24",
        "Reference Count": "51",
        "Authors": [
            "Zikun Zhou",
            "Wenjie Pei",
            "Xin Li",
            "Hongpeng Wang",
            "Feng Zheng",
            "Zhenyu He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "503bafe063e410050c174fcc741e39b3b1e0eb22",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "d1e61fa7824709cae37fb59483dd0772e3101c08",
            "a9448de3265ed9ecdc11c79273aee92daa31f79a",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "c17b85fc95591573bc356650522d303f8d76aeb9",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Bridging-the-Gap-Between-Detection-and-Tracking%3A-A-Huang-Zhao/ae066f27f2edc1c51847ce4cb21b6e1a3db44fa2",
        "ID": "ae066f27f2edc1c51847ce4cb21b6e1a3db44fa2",
        "Title": "Bridging the Gap Between Detection and Tracking: A Unified Approach",
        "Abstract": "Object detection models have been a source of inspiration for many tracking-by-detection algorithms over the past decade. Recent deep trackers borrow designs or modules from the latest object detection methods, such as bounding box regression, RPN and ROI pooling, and can deliver impressive performance. In this paper, instead of redesigning a new tracking-by-detection algorithm, we aim to explore a general framework for building trackers directly upon almost any advanced object detector. To\u2026\u00a0",
        "Publication Year": "1 October 2019",
        "Citation Count": "32",
        "Reference Count": "59",
        "Authors": [
            "Lianghua Huang",
            "Xin Zhao",
            "Kaiqi Huang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "f8e79ac0ea341056ef20f2616628b3e964764cfd",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "26c50d272883fc8f72656526f915bb283f772b27",
            "7536bce1007a765fd097a7cc8ea62208a8c89b85",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-term-Tracking-in-the-Wild%3A-A-Benchmark-Valmadre-Bertinetto/ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
        "ID": "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
        "Title": "Long-term Tracking in the Wild: A Benchmark",
        "Abstract": "We introduce the OxUvA dataset and benchmark for evaluating single-object tracking algorithms. Benchmarks have enabled great strides in the field of object tracking by defining standardized evaluations on large sets of diverse videos. However, these works have focused exclusively on sequences that are just tens of seconds in length and in which the target is always visible. Consequently, most researchers have designed methods tailored to this \u201cshort-term\u201d scenario, which is poorly\u2026\u00a0",
        "Publication Year": "26 March 2018",
        "Citation Count": "144",
        "Reference Count": "35",
        "Authors": [
            "Jack Valmadre",
            "Luca Bertinetto",
            "Jo{\\~a}o F. Henriques",
            "Ran Tao",
            "Andrea Vedaldi",
            "Arnold W. M. Smeulders",
            "Philip H. S. Torr",
            "Efstratios Gavves"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "d3d36c3caa255053877a7e3250d47d906eec81d2",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Long-Term-Tracking-With-Dai-Zhang/adacccd99a42c3145ec6392a1a6b08878376e38b",
        "ID": "adacccd99a42c3145ec6392a1a6b08878376e38b",
        "Title": "High-Performance Long-Term Tracking With Meta-Updater",
        "Abstract": "Long-term visual tracking has drawn increasing attention because it is much closer to practical applications than short-term tracking. Most top-ranked long-term trackers adopt the offline-trained Siamese architectures, thus,they cannot benefit from great progress of short-term trackers with online update. However, it is quite risky to straightforwardly introduce online-update-based trackers to solve the long-term problem, due to long-term uncertain and noisy observations. In this work, we\u2026\u00a0",
        "Publication Year": "1 April 2020",
        "Citation Count": "118",
        "Reference Count": "55",
        "Authors": [
            "Kenan Dai",
            "Yunhua Zhang",
            "Dong Wang",
            "Jianhua Li",
            "Huchuan Lu",
            "Xiaoyun Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "50c60583dc0ef09484358deab329f82ee22c2b66",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "383e67e0de2fdac787976543ba38bada48d046fc",
            "834baad9db5a1de1bfe993ff4a55a8a957eb9e0a",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/STMTrack%3A-Template-free-Visual-Tracking-with-Memory-Fu-Liu/811ffb185bc90ac5d02d6dbfbcdb6173756b52ef",
        "ID": "811ffb185bc90ac5d02d6dbfbcdb6173756b52ef",
        "Title": "STMTrack: Template-free Visual Tracking with Space-time Memory Networks",
        "Abstract": "Boosting performance of the offline trained siamese trackers is getting harder nowadays since the fixed information of the template cropped from the first frame has been almost thoroughly mined, but they are poorly capable of resisting target appearance changes. Existing trackers with template updating mechanisms rely on time-consuming numerical optimization and complex hand-designed strategies to achieve competitive performance, hindering them from real-time tracking and practical applications\u2026\u00a0",
        "Publication Year": "1 April 2021",
        "Citation Count": "76",
        "Reference Count": "70",
        "Authors": [
            "Z. Fu",
            "Qingjie Liu",
            "Zehua Fu",
            "Yunhong Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "26c50d272883fc8f72656526f915bb283f772b27",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "47a58f8bec1d34004a7d7cf837e27a26de64f0f7",
            "6cbc9a49e920231887604e3c3a018a9f2fdbd5e0",
            "8dbb2a1939a60f56d0508f597d99c3dc2c27aa61",
            "cce1fecc800d2782da638f3060d5b2e887739f74",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "5eca15a355b2a9a1e80879e850afe49d3c398c53",
            "365d7308a10da357009621d22b1548ab464277c3"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Distractor-Aware-Fast-Tracking-via-Dynamic-and-MOT-Zhang-Zhong/16cf8225d1b86c54a18b917a9475bfbd68b46306",
        "ID": "16cf8225d1b86c54a18b917a9475bfbd68b46306",
        "Title": "Distractor-Aware Fast Tracking via Dynamic Convolutions and MOT Philosophy",
        "Abstract": "A practical long-term tracker typically contains three key properties, i.e. an efficient model design, an effective global re-detection strategy and a robust distractor awareness mechanism. However, most state-of-the-art long-term trackers (e.g., Pseudo and re-detecting based ones) do not take all three key properties into account and therefore may either be time-consuming or drift to distractors. To address the issues, we propose a two-task tracking framework (named DMTrack), which utilizes\u2026\u00a0",
        "Publication Year": "25 April 2021",
        "Citation Count": "14",
        "Reference Count": "47",
        "Authors": [
            "Zikai Zhang",
            "Bineng Zhong",
            "Shengping Zhang",
            "Zhenjun Tang",
            "Xin Liu",
            "Zhaoxiang Zhang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "ae066f27f2edc1c51847ce4cb21b6e1a3db44fa2",
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "a62e40be6c2078ace369ce58801b3d5d1dd1a351",
            "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "069ccdbab6ea6ca2d9c3b75c76360ca1e4e9a5e9",
            "060239a69c0a975aaeb603630b40065acf3f8fde",
            "3d372b63020c4d2c9510624f370b50d9f292bcde"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Predictive-Visual-Tracking%3A-A-New-Benchmark-and-Li-Li/19fe26d0cfe16471f4d2a05053c9f51cf14f0fa8",
        "ID": "19fe26d0cfe16471f4d2a05053c9f51cf14f0fa8",
        "Title": "Predictive Visual Tracking: A New Benchmark and Baseline Approach",
        "Abstract": "\u2014As a crucial robotic perception capability, visual tracking has been intensively studied recently. In the real-world scenarios, the onboard processing time of the image streams inevitably leads to a discrepancy between the tracking results and the real-world states. However, existing visual tracking benchmarks commonly run the trackers of\ufb02ine and ignore such latency in the evaluation. In this work, we aim to deal with a more realistic problem of latency-aware tracking. The state-of-the-art\u2026\u00a0",
        "Publication Year": "8 March 2021",
        "Citation Count": "4",
        "Reference Count": "38",
        "Authors": [
            "Bowen Li",
            "Yiming Li",
            "Junjie Ye",
            "Changhong Fu",
            "Hang Zhao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "27850781e39df9f750e05409b8072261124068e8",
            "f3d7eb617179db9f9621fa2c978dfb9f2c39341f",
            "ca97f741f331b5b43d0577a46c05984f0785a8fa",
            "86aac093dcef187bdfb296888ba2a62bccb15c81",
            "c29199b0cd3c9b60288a0b726939fa829d6c2a34",
            "2c62be4b55661e8037117d697a2c0b296453ed11"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2017-Challenge-Kristan-Leonardis/350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "ID": "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "Title": "The Visual Object Tracking VOT2017 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \"real-time\" experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the\u2026\u00a0",
        "Publication Year": "1 October 2017",
        "Citation Count": "429",
        "Reference Count": "132",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andrej Muhic",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea Vedaldi",
            "Antoine Manzanera",
            "Antoine Tran",
            "Aydin Alatan",
            "Bogdan Cosmin Mocanu",
            "Boyu Chen",
            "Chang Huang",
            "Changsheng Xu",
            "Chong Sun",
            "Dalong Du",
            "Dafan Zhang",
            "Dawei Du",
            "Deepak Mishra",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Francesco Battistone",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Goutam Bhat",
            "Guan Huang",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Hongliang Zhang",
            "Houqiang Li",
            "Huchuan Lu",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jaeil Cho",
            "Jae-Y. Lee",
            "Jana Noskova",
            "Jianke Zhu",
            "Jin Gao",
            "Jingyu Liu",
            "Ji-Wan Kim",
            "Jo{\\~a}o F. Henriques",
            "Jos{\\&#x27;e} Mar{\\&#x27;i}a Mart{\\&#x27;i}nez Sanchez",
            "Junfei Zhuang",
            "Junliang Xing",
            "Junyu Gao",
            "Kai Chen",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Kris Kitani",
            "Lei Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh Poostchi",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Ming-Hsuan Yang",
            "Nianhao Xie",
            "Ning Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "Pallavi M. Venugopal",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Qifeng Yu",
            "Qingming Huang",
            "Rafael Martin Nieto",
            "R. Bowden",
            "Risheng Liu",
            "Ruxandra Tapu",
            "Simon Hadfield",
            "Siwei Lyu",
            "Stuart Golodetz",
            "Sunglok Choi",
            "Tianzhu Zhang",
            "Titus B. Zaharia",
            "Vincenzo Santopietro",
            "Wei Zou",
            "Weiming Hu",
            "Wenbing Tao",
            "Wenbo Li",
            "Wen-gang Zhou",
            "Xianguo Yu",
            "Xiao Bian",
            "Yang Li",
            "Yifan Xing",
            "Yingruo Fan",
            "Zhengyu Zhu",
            "Zhipeng Zhang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2016-Challenge-Kristan-Leonardis/966aad492f75b17f698e981e008b73b51816c6aa",
        "ID": "966aad492f75b17f698e981e008b73b51816c6aa",
        "Title": "The Visual Object Tracking VOT2016 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a\u2026\u00a0",
        "Publication Year": "8 October 2016",
        "Citation Count": "705",
        "Reference Count": "112",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Gustavo Javier Fernandez",
            "Abhinav Kumar Gupta",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Andrea Vedaldi",
            "Andreas Robinson",
            "Andy Jinhua Ma",
            "Anton Yuriiovych Varfolomieiev",
            "A. Aydin Alatan",
            "Aykut Erdem",
            "Bernard Ghanem",
            "Bin Liu",
            "Bohyung Han",
            "Brais Mart{\\&#x27;i}nez",
            "Chang-Ming Chang",
            "Changsheng Xu",
            "Chong Sun",
            "Daijin Kim",
            "Dapeng Chen",
            "Dawei Du",
            "Deepak Mishra",
            "D. Y. Yeung",
            "Erhan Gundogdu",
            "Erkut Erdem",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Fei Zhao",
            "Filiz Bunyak",
            "Francesco Battistone",
            "Gao Zhu",
            "Giorgio Roffo",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Henry Medeiros",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst Possegger",
            "Huchuan Lu",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Hyung Jin Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Y. Lee",
            "Jianke Zhu",
            "Jiayi Feng",
            "Jin Gao",
            "Jin Young Choi",
            "Jingjing Xiao",
            "Ji-Wan Kim",
            "Jiyeoup Jeong",
            "Jo{\\~a}o F. Henriques",
            "Jochen Lang",
            "Jongwon Choi",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Junliang Xing",
            "Junyu Gao",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Krystian Mikolajczyk",
            "Lei Qin",
            "Lijun Wang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Madan Kumar Rapuru",
            "Mahdieh Poostchi",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel F. Valstar",
            "Ming Tang",
            "Mooyeol Baek",
            "Muhammad Haris Khan",
            "Naiyan Wang",
            "Nana Fan",
            "Noor M. Al-Shakarji",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Osman Akin",
            "Payman Moallem",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Pong Chi Yuen",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan Pelapur",
            "Richard Bowden",
            "Robert Lagani{\\`e}re",
            "R. Stolkin",
            "Ryan Walsh",
            "Sebastian Bernd Krah",
            "Shengkun Li",
            "Shengping Zhang",
            "Shizeng Yao",
            "Simon Hadfield",
            "Simone Melzi",
            "Siwei Lyu",
            "Siyi Li",
            "Stefan Becker",
            "Stuart Golodetz",
            "Sumithra Kakanuru",
            "Sunglok Choi",
            "Tao Hu",
            "Thomas Mauthner",
            "Tianzhu Zhang",
            "Tony P. Pridmore",
            "Vincenzo Santopietro",
            "Weiming Hu",
            "Wenbo Li",
            "Wolfgang H{\\&quot;u}bner",
            "Xiangyuan Lan",
            "Xiaomeng Wang",
            "Xin Li",
            "Yang Li",
            "Y. Demiris",
            "Yifan Wang",
            "Yuankai Qi",
            "Zejian Yuan",
            "Zexiong Cai",
            "Zhan Xu",
            "Zhenyu He",
            "Zhizhen Chi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d",
            "6b175816b1f81127f5e2a2fe998df99d62290a1c",
            "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5",
            "16be98fa5924131816bc991a2c7ed91b8c69eaaa"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT-2016-Challenge-Kristan-Leonardis/6179ac06f1a8fd1ac6b693b02824948dff438d54",
        "ID": "6179ac06f1a8fd1ac6b693b02824948dff438d54",
        "Title": "The Visual Object Tracking VOT 2016 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply prelearned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a short\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "74",
        "Reference Count": "109",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman",
            "Pflugfelder",
            "Luka Cehovin",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Gustavo Javier Fernandez",
            "Abhinav Kumar Gupta",
            "Alfredo Petrosino",
            "Alireza",
            "Memarmoghadam",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Andrea",
            "Vedaldi",
            "Andreas Robinson",
            "Andy Jinhua Ma",
            "Anton Yuriiovych Varfolomieiev",
            "Aydin",
            "Alatan",
            "Aykut Erdem",
            "Bernard Ghanem",
            "Bin Liu",
            "Bohyung Han",
            "Brais Mart{\\&#x27;i}nez",
            "Chang-Ming Chang",
            "Changsheng Xu",
            "Chong Sun",
            "Daijin Kim",
            "Dapeng Chen",
            "Dawei Du",
            "Deepak Mishra",
            "Dit-Yan",
            "Yeung",
            "Erhan Gundogdu",
            "Erkut Erdem",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Fei Zhao",
            "Filiz Bunyak",
            "Francesco Battistone",
            "Gao Zhu",
            "Giorgio Roffo",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Henry Medeiros",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst",
            "Possegger",
            "Huchuan Lu",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Hyung Jin",
            "Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jae-Y. Lee",
            "Jianke Zhu",
            "Jiayi Feng",
            "Jin Gao",
            "Jin Young",
            "Choi",
            "Jingjing Xiao",
            "Ji-Wan Kim",
            "Jiyeoup Jeong",
            "Jo{\\~a}o F. Henriques",
            "Jochen Lang",
            "Jongwon Choi",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Junliang Xing",
            "Junyu",
            "Gao",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Krystian",
            "Miko\u0142ajczyk",
            "Lei Qin",
            "Lijun Wang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Madan Kumar Rapuru",
            "Mahdieh Poostchi",
            "Mario Edoardo Maresca",
            "Martin",
            "Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel",
            "Valstar",
            "Mooyeol Baek",
            "M. H. Khan",
            "Naiyan",
            "Wang",
            "Nana Fan",
            "Noor M. Al-Shakarji",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Osman Akin",
            "Payman Moallem",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Pong Chi Yuen",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan Pelapur",
            "Richard",
            "Bowden",
            "Robert Lagani{\\`e}re",
            "R. Stolkin",
            "Ryan Walsh",
            "Brock Sebastian",
            "Krah",
            "Shengkun Li",
            "Shengping Zhang",
            "Shizeng Yao",
            "Simon Hadfield",
            "Simone Melzi",
            "Siwei Lyu",
            "Siyi Li",
            "Stefan Becker",
            "Stuart Golodetz",
            "Sumithra Kakanuru",
            "Sunglok Choi",
            "Tao Hu",
            "Thomas Mauthner",
            "Tianzhu Zhang",
            "Tony P. Pridmore",
            "Vincenzo Santopietro",
            "Weiming Hu",
            "Wolfgang H{\\&quot;u}bner",
            "Xiangyuan Lan",
            "Xiaomeng Wang",
            "Y. Demiris",
            "Yifan Wang",
            "Yuankai Qi",
            "Ze-jian",
            "Yuan",
            "Zexiong Cai",
            "Zhan Xu",
            "Zhenyu He",
            "Zhizhen Chi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "2bcf2bd59219d89f335cbc8d1dd4f431076b4c4c",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2015-Challenge-Kristan-Matas/047ea298464b041a90c4ab4e716356c019d613ab",
        "ID": "047ea298464b041a90c4ab4e716356c019d613ab",
        "Title": "The Visual Object Tracking VOT2015 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 predecessor are: (i) a new VOT2015 dataset twice\u2026\u00a0",
        "Publication Year": "7 December 2015",
        "Citation Count": "398",
        "Reference Count": "84",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Luka Cehovin",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Georg Nebehay",
            "Roman P. Pflugfelder",
            "Zhe Chen"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "17f16b89edaed5d16867287ed8a85e917304b4ba",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "7b75da6f5edac80575d9dcf63db164ce24933907"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Visual-Object-Tracking-Benchmark-Moudgil-Gandhi/19d6b9725a59f4b624205829d5f03ac893ca1367",
        "ID": "19d6b9725a59f4b624205829d5f03ac893ca1367",
        "Title": "Long-Term Visual Object Tracking Benchmark",
        "Abstract": "We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term\u2026\u00a0",
        "Publication Year": "4 December 2017",
        "Citation Count": "74",
        "Reference Count": "47",
        "Authors": [
            "A. Moudgil",
            "Vineet Gandhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Performance-Evaluation-Methodology-for-Long-Term-Luke%C5%BEi%C4%8D-Zajc/23f8927f996d56f3b5076d8993a70bcfc70182a1",
        "ID": "23f8927f996d56f3b5076d8993a70bcfc70182a1",
        "Title": "Performance Evaluation Methodology for Long-Term Visual Object Tracking",
        "Abstract": "A long-term visual object tracking performance evaluation methodology and a benchmark are proposed. Performance measures are designed by following a long-term tracking definition to maximize the analysis probing strength. The new measures outperform existing ones in interpretation potential and in better distinguishing between different tracking behaviors. We show that these measures generalize the short-term performance measures, thus linking the two tracking problems. Furthermore, the new\u2026\u00a0",
        "Publication Year": "19 June 2019",
        "Citation Count": "6",
        "Reference Count": "45",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Tracking-through-Failure-Cases-Lebeda-Hadfield/9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "ID": "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "Title": "Long-Term Tracking through Failure Cases",
        "Abstract": "Long term tracking of an object, given only a single instance in an initial frame, remains an open problem. We propose a visual tracking algorithm, robust to many of the difficulties which often occur in real-world scenes. Correspondences of edge-based features are used, to overcome the reliance on the texture of the tracked object and improve invariance to lighting. Furthermore we address long-term stability, enabling the tracker to recover from drift and to provide redetection following\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "54",
        "Reference Count": "17",
        "Authors": [
            "Karel Lebeda",
            "Simon Hadfield",
            "Jiri Matas",
            "R. Bowden"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "00058304b7c51b9dcf837d4125cab0a4b0588aef",
            "5b9ace65f7368f6dc6907c8f6f7c3b0c248d9bc4",
            "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca",
            "4411f262853bf7f1eb8e2efe03eb0402f5e9ad2c",
            "fcba52c59e8537e48e747207837cefd04786bd3d",
            "948a74b25508ab674be06f6a94ca8bc07a082361",
            "dfa5a0cce66f9e840dd98ac8094434efcc4a9de5",
            "779220bb5190b976e025dc649b2e9a0e4b3597b9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Visual-Tracking-with-Siamese-Li-Yan/320d05db95ab42ade69294abe46cd1aca6aca602",
        "ID": "320d05db95ab42ade69294abe46cd1aca6aca602",
        "Title": "High Performance Visual Tracking with Siamese Region Proposal Network",
        "Abstract": "Visual object tracking has been a fundamental topic in recent years and many deep learning based trackers have achieved state-of-the-art performance on multiple benchmarks. However, most of these trackers can hardly get top performance with real-time speed. In this paper, we propose the Siamese region proposal network (Siamese-RPN) which is end-to-end trained off-line with large-scale image pairs. Specifically, it consists of Siamese subnetwork for feature extraction and region proposal\u2026\u00a0",
        "Publication Year": "1 June 2018",
        "Citation Count": "1,566",
        "Reference Count": "41",
        "Authors": [
            "Bo Li",
            "Junjie Yan",
            "Wei Wu",
            "Zheng Zhu",
            "Xiaolin Hu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "1131c53b9baaa740a4deef4c1282821b23d18687",
            "7ccbb845829234548bfa9b24c61297b4f0cd678e",
            "5404718135548b01516a668e0c022c5cb22b422e",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "dda27eb7ddc4510f94cac0e5134b5d56aa77b075",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Deep-Bidirectional-Correlation-Filters-for-Visual-Javed-Zhang/0f5a25b52bef4f5fb969887224ba84e89c32e47c",
        "ID": "0f5a25b52bef4f5fb969887224ba84e89c32e47c",
        "Title": "Deep Bidirectional Correlation Filters for Visual Object Tracking",
        "Abstract": "Visual Object Tracking (VOT) is an essential task for many computer vision applications. VOT becomes challenging when a target object faces severe occlusion, drastic illumination changes, and scale variation problems. In the literature, Discriminative Correlation Filters (DCFs)-based tracking methods have achieved promising results in terms of accuracy and efficiency in many complex VOT scenarios. A plethora of DCFs trackers have been proposed which exploit information observed in past frames\u2026\u00a0",
        "Publication Year": "1 July 2020",
        "Citation Count": "3",
        "Reference Count": "34",
        "Authors": [
            "Sajid Javed",
            "Xiaoxiong Zhang",
            "Lakmal D. Seneviratne",
            "J. Dias",
            "Naoufel Werghi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "9e6d1625cb8ae06eaa741bd79c2a89cd98ec8f9a",
            "5c8a6874011640981e4103d120957802fa28f004",
            "3eedcf9302f299a1eebbc0f543a366454d6dcefb",
            "01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "9ce6dd3ad74236b09a12062b7e86942cff76034d",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "ce8c76bfedc5d86faabf0d49dc42a4924f75876d",
            "9f45b55af027503fab557f55f70e81e43c6c1db7",
            "f46318bf67ab6b30284f125ac8bb6f9a7503595e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Predictive-Visual-Tracking%3A-A-New-Benchmark-and-Li-Li/19fe26d0cfe16471f4d2a05053c9f51cf14f0fa8",
        "ID": "19fe26d0cfe16471f4d2a05053c9f51cf14f0fa8",
        "Title": "Predictive Visual Tracking: A New Benchmark and Baseline Approach",
        "Abstract": "\u2014As a crucial robotic perception capability, visual tracking has been intensively studied recently. In the real-world scenarios, the onboard processing time of the image streams inevitably leads to a discrepancy between the tracking results and the real-world states. However, existing visual tracking benchmarks commonly run the trackers of\ufb02ine and ignore such latency in the evaluation. In this work, we aim to deal with a more realistic problem of latency-aware tracking. The state-of-the-art\u2026\u00a0",
        "Publication Year": "8 March 2021",
        "Citation Count": "4",
        "Reference Count": "38",
        "Authors": [
            "Bowen Li",
            "Yiming Li",
            "Junjie Ye",
            "Changhong Fu",
            "Hang Zhao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "27850781e39df9f750e05409b8072261124068e8",
            "f3d7eb617179db9f9621fa2c978dfb9f2c39341f",
            "ca97f741f331b5b43d0577a46c05984f0785a8fa",
            "86aac093dcef187bdfb296888ba2a62bccb15c81",
            "c29199b0cd3c9b60288a0b726939fa829d6c2a34",
            "2c62be4b55661e8037117d697a2c0b296453ed11"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Effective-Local-and-Global-Search-for-Fast-Tracking-Zhao-Yan/b47943161a0cefb8963ad0a7830e51c396bff3b1",
        "ID": "b47943161a0cefb8963ad0a7830e51c396bff3b1",
        "Title": "Effective Local and Global Search for Fast Long-Term Tracking",
        "Abstract": "Compared with short-term tracking, long-term tracking remains a challenging task that usually requires the tracking algorithm to track targets within a local region and re-detect targets over the entire image. However, few works have been done and their performances have also been limited. In this paper, we present a novel robust and real-time long-term tracking framework based on the proposed local search module and re-detection module. The local search module consists of an effective bounding\u2026\u00a0",
        "Publication Year": "23 February 2022",
        "Citation Count": "4",
        "Reference Count": "62",
        "Authors": [
            "Haojie Zhao",
            "B. Yan",
            "D. Wang",
            "Xuesheng Qian",
            "Xiaoyun Yang",
            "Huchuan Lu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3d372b63020c4d2c9510624f370b50d9f292bcde",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "d3d36c3caa255053877a7e3250d47d906eec81d2",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "913cebc279c363fb9476496f096519e27212b3d5",
            "219e9a4527110baf1feb3df20db12064eeafdfb7",
            "19d6b9725a59f4b624205829d5f03ac893ca1367"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Single-Object-Tracking-Research%3A-A-Survey-Han-Feng/cf4ade985aa66109909e56c9df93ff0b3ef2ca98",
        "ID": "cf4ade985aa66109909e56c9df93ff0b3ef2ca98",
        "Title": "Single Object Tracking Research: A Survey",
        "Abstract": "Visual object tracking is an important and fundamental task in computer vision, which has many real-world applications, e.g., video surveillance, visual navigation and robotic service. Visual object tracking also has many challenges, such as object loss, object deformation, background clutters, and object fast motion. To solve the above problems and track the target accurately and efficiently, many visual object tracking algorithms have been emerged in recent years. In this paper, we first\u2026\u00a0",
        "Publication Year": "25 April 2022",
        "Citation Count": "2",
        "Reference Count": "119",
        "Authors": [
            "Ruize Han",
            "Wei Feng",
            "Qing Guo",
            "Qinghua Hu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "eb35dff22c4e947dcd753dc38bb8557d8def47cc",
            "2e7e3b4eb8bc0a7f29ca560b1cceb986a1dcd977",
            "388d29f001411ff80650f80cf197afc440d98b51",
            "1098c07a5d80a07c281d3af340ae74b2a6c82317",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "f5dbe4550d24d5374d9e10fce44a35b105c7ee07",
            "60863b09592df8ef41bd616ac9df947eb212246a",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2017-Challenge-Kristan-Leonardis/350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "ID": "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
        "Title": "The Visual Object Tracking VOT2017 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \"real-time\" experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the\u2026\u00a0",
        "Publication Year": "1 October 2017",
        "Citation Count": "429",
        "Reference Count": "132",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andrej Muhic",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea Vedaldi",
            "Antoine Manzanera",
            "Antoine Tran",
            "Aydin Alatan",
            "Bogdan Cosmin Mocanu",
            "Boyu Chen",
            "Chang Huang",
            "Changsheng Xu",
            "Chong Sun",
            "Dalong Du",
            "Dafan Zhang",
            "Dawei Du",
            "Deepak Mishra",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Francesco Battistone",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Goutam Bhat",
            "Guan Huang",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Hongliang Zhang",
            "Houqiang Li",
            "Huchuan Lu",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jaeil Cho",
            "Jae-Y. Lee",
            "Jana Noskova",
            "Jianke Zhu",
            "Jin Gao",
            "Jingyu Liu",
            "Ji-Wan Kim",
            "Jo{\\~a}o F. Henriques",
            "Jos{\\&#x27;e} Mar{\\&#x27;i}a Mart{\\&#x27;i}nez Sanchez",
            "Junfei Zhuang",
            "Junliang Xing",
            "Junyu Gao",
            "Kai Chen",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Kris Kitani",
            "Lei Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh Poostchi",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Ming-Hsuan Yang",
            "Nianhao Xie",
            "Ning Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "Pallavi M. Venugopal",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Qifeng Yu",
            "Qingming Huang",
            "Rafael Martin Nieto",
            "R. Bowden",
            "Risheng Liu",
            "Ruxandra Tapu",
            "Simon Hadfield",
            "Siwei Lyu",
            "Stuart Golodetz",
            "Sunglok Choi",
            "Tianzhu Zhang",
            "Titus B. Zaharia",
            "Vincenzo Santopietro",
            "Wei Zou",
            "Weiming Hu",
            "Wenbing Tao",
            "Wenbo Li",
            "Wen-gang Zhou",
            "Xianguo Yu",
            "Xiao Bian",
            "Yang Li",
            "Yifan Xing",
            "Yingruo Fan",
            "Zhengyu Zhu",
            "Zhipeng Zhang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2016-Challenge-Kristan-Leonardis/966aad492f75b17f698e981e008b73b51816c6aa",
        "ID": "966aad492f75b17f698e981e008b73b51816c6aa",
        "Title": "The Visual Object Tracking VOT2016 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a\u2026\u00a0",
        "Publication Year": "8 October 2016",
        "Citation Count": "705",
        "Reference Count": "112",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Gustavo Javier Fernandez",
            "Abhinav Kumar Gupta",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Andrea Vedaldi",
            "Andreas Robinson",
            "Andy Jinhua Ma",
            "Anton Yuriiovych Varfolomieiev",
            "A. Aydin Alatan",
            "Aykut Erdem",
            "Bernard Ghanem",
            "Bin Liu",
            "Bohyung Han",
            "Brais Mart{\\&#x27;i}nez",
            "Chang-Ming Chang",
            "Changsheng Xu",
            "Chong Sun",
            "Daijin Kim",
            "Dapeng Chen",
            "Dawei Du",
            "Deepak Mishra",
            "D. Y. Yeung",
            "Erhan Gundogdu",
            "Erkut Erdem",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Fei Zhao",
            "Filiz Bunyak",
            "Francesco Battistone",
            "Gao Zhu",
            "Giorgio Roffo",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Henry Medeiros",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst Possegger",
            "Huchuan Lu",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Hyung Jin Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Y. Lee",
            "Jianke Zhu",
            "Jiayi Feng",
            "Jin Gao",
            "Jin Young Choi",
            "Jingjing Xiao",
            "Ji-Wan Kim",
            "Jiyeoup Jeong",
            "Jo{\\~a}o F. Henriques",
            "Jochen Lang",
            "Jongwon Choi",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Junliang Xing",
            "Junyu Gao",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Krystian Mikolajczyk",
            "Lei Qin",
            "Lijun Wang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Madan Kumar Rapuru",
            "Mahdieh Poostchi",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel F. Valstar",
            "Ming Tang",
            "Mooyeol Baek",
            "Muhammad Haris Khan",
            "Naiyan Wang",
            "Nana Fan",
            "Noor M. Al-Shakarji",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Osman Akin",
            "Payman Moallem",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Pong Chi Yuen",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan Pelapur",
            "Richard Bowden",
            "Robert Lagani{\\`e}re",
            "R. Stolkin",
            "Ryan Walsh",
            "Sebastian Bernd Krah",
            "Shengkun Li",
            "Shengping Zhang",
            "Shizeng Yao",
            "Simon Hadfield",
            "Simone Melzi",
            "Siwei Lyu",
            "Siyi Li",
            "Stefan Becker",
            "Stuart Golodetz",
            "Sumithra Kakanuru",
            "Sunglok Choi",
            "Tao Hu",
            "Thomas Mauthner",
            "Tianzhu Zhang",
            "Tony P. Pridmore",
            "Vincenzo Santopietro",
            "Weiming Hu",
            "Wenbo Li",
            "Wolfgang H{\\&quot;u}bner",
            "Xiangyuan Lan",
            "Xiaomeng Wang",
            "Xin Li",
            "Yang Li",
            "Y. Demiris",
            "Yifan Wang",
            "Yuankai Qi",
            "Zejian Yuan",
            "Zexiong Cai",
            "Zhan Xu",
            "Zhenyu He",
            "Zhizhen Chi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d",
            "6b175816b1f81127f5e2a2fe998df99d62290a1c",
            "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5",
            "16be98fa5924131816bc991a2c7ed91b8c69eaaa"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2015-Challenge-Kristan-Matas/047ea298464b041a90c4ab4e716356c019d613ab",
        "ID": "047ea298464b041a90c4ab4e716356c019d613ab",
        "Title": "The Visual Object Tracking VOT2015 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 predecessor are: (i) a new VOT2015 dataset twice\u2026\u00a0",
        "Publication Year": "7 December 2015",
        "Citation Count": "398",
        "Reference Count": "84",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Luka Cehovin",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Georg Nebehay",
            "Roman P. Pflugfelder",
            "Zhe Chen"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "17f16b89edaed5d16867287ed8a85e917304b4ba",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "7b75da6f5edac80575d9dcf63db164ce24933907"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2013-Challenge-Kristan-Matas/4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "ID": "4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "Title": "The Visual Object Tracking VOT2013 Challenge Results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) workshop was organized in\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "333",
        "Reference Count": "137",
        "Authors": [
            "Matej Kristan",
            "Juan E. Sala Matas",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Luka Cehovin",
            "Georg Nebehay",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustavo Javier Fernandez",
            "Alan Luke{\\vz}i{\\vc}",
            "Aleksandar Dimitriev",
            "Alfredo Petrosino",
            "Amir Saffari",
            "Bo Li",
            "Bohyung Han",
            "Cherkeng Heng",
            "Christophe Garcia",
            "Dominik Pangersic",
            "Gustav H{\\&quot;a}ger",
            "Fahad Shahbaz Khan",
            "Franc Oven",
            "Horst Possegger",
            "Horst Bischof",
            "Hyeonseob Nam",
            "Jianke Zhu",
            "Jijia Li",
            "Jin Young Choi",
            "Jinwoo Choi",
            "Jo{\\~a}o F. Henriques",
            "Joost van de Weijer",
            "Jorge Batista",
            "Karel Lebeda",
            "Kristoffer {\\&quot;O}fj{\\&quot;a}ll",
            "Kwang Moo Yi",
            "Lei Qin",
            "Longyin Wen",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Michael Felsberg",
            "Ming-Ming Cheng",
            "Philip H. S. Torr",
            "Qingming Huang",
            "R. Bowden",
            "Sam Hare",
            "Samantha YueYing Lim",
            "Seunghoon Hong",
            "Shengcai Liao",
            "Simon Hadfield",
            "S. Li",
            "Stefan Duffner",
            "Stuart Golodetz",
            "Thomas Mauthner",
            "Vibhav Vineet",
            "Weiyao Lin",
            "Yang Li",
            "Yuankai Qi",
            "Zhen Lei",
            "Zhi Heng Niu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "e3c433ab9608d7329f944552ba1721e277a42d74",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Visual-Object-Tracking-Benchmark-Moudgil-Gandhi/19d6b9725a59f4b624205829d5f03ac893ca1367",
        "ID": "19d6b9725a59f4b624205829d5f03ac893ca1367",
        "Title": "Long-Term Visual Object Tracking Benchmark",
        "Abstract": "We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term\u2026\u00a0",
        "Publication Year": "4 December 2017",
        "Citation Count": "74",
        "Reference Count": "47",
        "Authors": [
            "A. Moudgil",
            "Vineet Gandhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Novel-Performance-Evaluation-Methodology-for-Kristan-Matas/0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
        "ID": "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
        "Title": "A Novel Performance Evaluation Methodology for Single-Target Trackers",
        "Abstract": "This paper addresses the problem of single-target tracker performance evaluation. We consider the performance measures, the dataset and the evaluation system to be the most important components of tracker evaluation and propose requirements for each of them. The requirements are the basis of a new evaluation methodology that aims at a simple and easily interpretable tracker comparison. The ranking-based methodology addresses tracker equivalence in terms of statistical significance and practical\u2026\u00a0",
        "Publication Year": "4 March 2015",
        "Citation Count": "548",
        "Reference Count": "88",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Roman P. Pflugfelder",
            "Gustavo Javier Fernandez",
            "Georg Nebehay",
            "Fatih Murat Porikli",
            "Luka Cehovin"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "edf6607f0c819390a13e60b722cc40f97359c9c4",
            "2258e01865367018ed6f4262c880df85b94959f8",
            "a52a6cf39054e6f406f67b57cc895e9df1163fc8",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "8f1a4c9be59b43175c86954829690084ac1e8a1a",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "681ee0059ed573265847785d110237861458304e",
            "0cae491292feccbc9ad1d864cf8b7144923ce6de",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-term-Tracking-in-the-Wild%3A-A-Benchmark-Valmadre-Bertinetto/ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
        "ID": "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
        "Title": "Long-term Tracking in the Wild: A Benchmark",
        "Abstract": "We introduce the OxUvA dataset and benchmark for evaluating single-object tracking algorithms. Benchmarks have enabled great strides in the field of object tracking by defining standardized evaluations on large sets of diverse videos. However, these works have focused exclusively on sequences that are just tens of seconds in length and in which the target is always visible. Consequently, most researchers have designed methods tailored to this \u201cshort-term\u201d scenario, which is poorly\u2026\u00a0",
        "Publication Year": "26 March 2018",
        "Citation Count": "144",
        "Reference Count": "35",
        "Authors": [
            "Jack Valmadre",
            "Luca Bertinetto",
            "Jo{\\~a}o F. Henriques",
            "Ran Tao",
            "Andrea Vedaldi",
            "Arnold W. M. Smeulders",
            "Philip H. S. Torr",
            "Efstratios Gavves"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "d3d36c3caa255053877a7e3250d47d906eec81d2",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Now-you-see-me%3A-evaluating-performance-in-long-term-Luke%C5%BEi%C4%8D-Zajc/3275944117b43cc44beebe7c82bffc13ec8cb0fa",
        "ID": "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
        "Title": "Now you see me: evaluating performance in long-term visual tracking",
        "Abstract": "We propose a new long-term tracking performance evaluation methodology and present a new challenging dataset of carefully selected sequences with many target disappearances. We perform an extensive evaluation of six long-term and nine short-term state-of-the-art trackers, using new performance measures, suitable for evaluating long-term tracking - tracking precision, recall and F-score. The evaluation shows that a good model update strategy and the capability of image-wide re-detection are\u2026\u00a0",
        "Publication Year": "19 April 2018",
        "Citation Count": "54",
        "Reference Count": "34",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "d3d36c3caa255053877a7e3250d47d906eec81d2",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "681ee0059ed573265847785d110237861458304e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Tracking-through-Failure-Cases-Lebeda-Hadfield/9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "ID": "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "Title": "Long-Term Tracking through Failure Cases",
        "Abstract": "Long term tracking of an object, given only a single instance in an initial frame, remains an open problem. We propose a visual tracking algorithm, robust to many of the difficulties which often occur in real-world scenes. Correspondences of edge-based features are used, to overcome the reliance on the texture of the tracked object and improve invariance to lighting. Furthermore we address long-term stability, enabling the tracker to recover from drift and to provide redetection following\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "54",
        "Reference Count": "17",
        "Authors": [
            "Karel Lebeda",
            "Simon Hadfield",
            "Jiri Matas",
            "R. Bowden"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "00058304b7c51b9dcf837d4125cab0a4b0588aef",
            "5b9ace65f7368f6dc6907c8f6f7c3b0c248d9bc4",
            "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca",
            "4411f262853bf7f1eb8e2efe03eb0402f5e9ad2c",
            "fcba52c59e8537e48e747207837cefd04786bd3d",
            "948a74b25508ab674be06f6a94ca8bc07a082361",
            "dfa5a0cce66f9e840dd98ac8094434efcc4a9de5",
            "779220bb5190b976e025dc649b2e9a0e4b3597b9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-object-tracking-challenges-revisited%3A-VOT-Bei-Zhen/4b90dfbd6983cf9d47d1053efe630c515f9833b5",
        "ID": "4b90dfbd6983cf9d47d1053efe630c515f9833b5",
        "Title": "Visual object tracking challenges revisited: VOT vs. OTB",
        "Abstract": "Numerous benchmark datasets and evaluation toolkits have been designed to facilitate visual object tracking evaluation. However, it is not clear which evaluation protocols are preferred for different tracking objectives. Even worse, different evaluation protocols sometimes yield contradictory conclusions, further hampering reliable evaluation. Therefore, we 1) introduce the new concept of mirror tracking to measure the robustness of a tracker and identify its over-fitting scenarios; 2) measure\u2026\u00a0",
        "Publication Year": "27 September 2018",
        "Citation Count": "5",
        "Reference Count": "31",
        "Authors": [
            "Sun Bei",
            "Zuo Zhen",
            "Luo Wusheng",
            "Du Liebo",
            "Lu Qin"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "bf97833a354d7faa3793599ac5c1ec1eb3eb7e07",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "ce8c76bfedc5d86faabf0d49dc42a4924f75876d",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Predictive-Visual-Tracking%3A-A-New-Benchmark-and-Li-Li/19fe26d0cfe16471f4d2a05053c9f51cf14f0fa8",
        "ID": "19fe26d0cfe16471f4d2a05053c9f51cf14f0fa8",
        "Title": "Predictive Visual Tracking: A New Benchmark and Baseline Approach",
        "Abstract": "\u2014As a crucial robotic perception capability, visual tracking has been intensively studied recently. In the real-world scenarios, the onboard processing time of the image streams inevitably leads to a discrepancy between the tracking results and the real-world states. However, existing visual tracking benchmarks commonly run the trackers of\ufb02ine and ignore such latency in the evaluation. In this work, we aim to deal with a more realistic problem of latency-aware tracking. The state-of-the-art\u2026\u00a0",
        "Publication Year": "8 March 2021",
        "Citation Count": "4",
        "Reference Count": "38",
        "Authors": [
            "Bowen Li",
            "Yiming Li",
            "Junjie Ye",
            "Changhong Fu",
            "Hang Zhao"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8",
            "6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "27850781e39df9f750e05409b8072261124068e8",
            "f3d7eb617179db9f9621fa2c978dfb9f2c39341f",
            "ca97f741f331b5b43d0577a46c05984f0785a8fa",
            "86aac093dcef187bdfb296888ba2a62bccb15c81",
            "c29199b0cd3c9b60288a0b726939fa829d6c2a34",
            "2c62be4b55661e8037117d697a2c0b296453ed11"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/AMTSet%3A-a-benchmark-for-abrupt-motion-tracking-Wang-Wang/2b53d19e926520d542fb053e0a7b20a332e48324",
        "ID": "2b53d19e926520d542fb053e0a7b20a332e48324",
        "Title": "AMTSet: a benchmark for abrupt motion tracking",
        "Abstract": "Since the OTB100 benchmark dataset is released, it has been widely used in a large number of researches on object tracking for performance evaluation. However, the existing datasets are insufficient to evaluate trackers in handling different challenging factors. In this paper, we present the first dataset and benchmark for tracking objects with abrupt motion (AMTSet). The dataset consists of 50 videos of special scenes from our real life, such as camera switching, sudden dynamic change, low\u2026\u00a0",
        "Publication Year": "15 May 2021",
        "Citation Count": "One",
        "Reference Count": "66",
        "Authors": [
            "Fasheng Wang",
            "Chang Wang",
            "Shuangshuang Yin",
            "Jianjun He",
            "Fuming Sun",
            "Junxing Zhang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "900ab48d25b44c076e31224b7befa503d9550c53",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "ce8c76bfedc5d86faabf0d49dc42a4924f75876d",
            "60863b09592df8ef41bd616ac9df947eb212246a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-quantitative-attribute-based-benchmark-for-visual-Kang-Liu/27fb3e2952b50fc27ddb3d7d9dbbd1614df64999",
        "ID": "27fb3e2952b50fc27ddb3d7d9dbbd1614df64999",
        "Title": "A quantitative attribute-based benchmark methodology for single-target visual tracking",
        "Abstract": "In the past several years, various visual object tracking benchmarks have been proposed, and some of them have been used widely in numerous recently proposed trackers. However, most of the discussions focus on the overall performance, and cannot describe the strengths and weaknesses of the trackers in detail. Meanwhile, several benchmark measures that are often used in tests lack convincing interpretation. In this paper, 12 frame-wise visual attributes that reflect different aspects of the\u2026\u00a0",
        "Publication Year": "1 March 2020",
        "Citation Count": "One",
        "Reference Count": "58",
        "Authors": [
            "Wen-jing Kang",
            "Chang Liu",
            "Gong-liang Liu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "681ee0059ed573265847785d110237861458304e",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "388d29f001411ff80650f80cf197afc440d98b51",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2016-Challenge-Kristan-Leonardis/966aad492f75b17f698e981e008b73b51816c6aa",
        "ID": "966aad492f75b17f698e981e008b73b51816c6aa",
        "Title": "The Visual Object Tracking VOT2016 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a\u2026\u00a0",
        "Publication Year": "8 October 2016",
        "Citation Count": "705",
        "Reference Count": "112",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Gustavo Javier Fernandez",
            "Abhinav Kumar Gupta",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Andrea Vedaldi",
            "Andreas Robinson",
            "Andy Jinhua Ma",
            "Anton Yuriiovych Varfolomieiev",
            "A. Aydin Alatan",
            "Aykut Erdem",
            "Bernard Ghanem",
            "Bin Liu",
            "Bohyung Han",
            "Brais Mart{\\&#x27;i}nez",
            "Chang-Ming Chang",
            "Changsheng Xu",
            "Chong Sun",
            "Daijin Kim",
            "Dapeng Chen",
            "Dawei Du",
            "Deepak Mishra",
            "D. Y. Yeung",
            "Erhan Gundogdu",
            "Erkut Erdem",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Fei Zhao",
            "Filiz Bunyak",
            "Francesco Battistone",
            "Gao Zhu",
            "Giorgio Roffo",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Henry Medeiros",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst Possegger",
            "Huchuan Lu",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Hyung Jin Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Y. Lee",
            "Jianke Zhu",
            "Jiayi Feng",
            "Jin Gao",
            "Jin Young Choi",
            "Jingjing Xiao",
            "Ji-Wan Kim",
            "Jiyeoup Jeong",
            "Jo{\\~a}o F. Henriques",
            "Jochen Lang",
            "Jongwon Choi",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Junliang Xing",
            "Junyu Gao",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Krystian Mikolajczyk",
            "Lei Qin",
            "Lijun Wang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Madan Kumar Rapuru",
            "Mahdieh Poostchi",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel F. Valstar",
            "Ming Tang",
            "Mooyeol Baek",
            "Muhammad Haris Khan",
            "Naiyan Wang",
            "Nana Fan",
            "Noor M. Al-Shakarji",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Osman Akin",
            "Payman Moallem",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Pong Chi Yuen",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan Pelapur",
            "Richard Bowden",
            "Robert Lagani{\\`e}re",
            "R. Stolkin",
            "Ryan Walsh",
            "Sebastian Bernd Krah",
            "Shengkun Li",
            "Shengping Zhang",
            "Shizeng Yao",
            "Simon Hadfield",
            "Simone Melzi",
            "Siwei Lyu",
            "Siyi Li",
            "Stefan Becker",
            "Stuart Golodetz",
            "Sumithra Kakanuru",
            "Sunglok Choi",
            "Tao Hu",
            "Thomas Mauthner",
            "Tianzhu Zhang",
            "Tony P. Pridmore",
            "Vincenzo Santopietro",
            "Weiming Hu",
            "Wenbo Li",
            "Wolfgang H{\\&quot;u}bner",
            "Xiangyuan Lan",
            "Xiaomeng Wang",
            "Xin Li",
            "Yang Li",
            "Y. Demiris",
            "Yifan Wang",
            "Yuankai Qi",
            "Zejian Yuan",
            "Zexiong Cai",
            "Zhan Xu",
            "Zhenyu He",
            "Zhizhen Chi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d",
            "6b175816b1f81127f5e2a2fe998df99d62290a1c",
            "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5",
            "16be98fa5924131816bc991a2c7ed91b8c69eaaa"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2015-Challenge-Kristan-Matas/047ea298464b041a90c4ab4e716356c019d613ab",
        "ID": "047ea298464b041a90c4ab4e716356c019d613ab",
        "Title": "The Visual Object Tracking VOT2015 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 predecessor are: (i) a new VOT2015 dataset twice\u2026\u00a0",
        "Publication Year": "7 December 2015",
        "Citation Count": "398",
        "Reference Count": "84",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Luka Cehovin",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Georg Nebehay",
            "Roman P. Pflugfelder",
            "Zhe Chen"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "17f16b89edaed5d16867287ed8a85e917304b4ba",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "7b75da6f5edac80575d9dcf63db164ce24933907"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2013-Challenge-Kristan-Matas/4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "ID": "4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "Title": "The Visual Object Tracking VOT2013 Challenge Results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) workshop was organized in\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "333",
        "Reference Count": "137",
        "Authors": [
            "Matej Kristan",
            "Juan E. Sala Matas",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Luka Cehovin",
            "Georg Nebehay",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustavo Javier Fernandez",
            "Alan Luke{\\vz}i{\\vc}",
            "Aleksandar Dimitriev",
            "Alfredo Petrosino",
            "Amir Saffari",
            "Bo Li",
            "Bohyung Han",
            "Cherkeng Heng",
            "Christophe Garcia",
            "Dominik Pangersic",
            "Gustav H{\\&quot;a}ger",
            "Fahad Shahbaz Khan",
            "Franc Oven",
            "Horst Possegger",
            "Horst Bischof",
            "Hyeonseob Nam",
            "Jianke Zhu",
            "Jijia Li",
            "Jin Young Choi",
            "Jinwoo Choi",
            "Jo{\\~a}o F. Henriques",
            "Joost van de Weijer",
            "Jorge Batista",
            "Karel Lebeda",
            "Kristoffer {\\&quot;O}fj{\\&quot;a}ll",
            "Kwang Moo Yi",
            "Lei Qin",
            "Longyin Wen",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Michael Felsberg",
            "Ming-Ming Cheng",
            "Philip H. S. Torr",
            "Qingming Huang",
            "R. Bowden",
            "Sam Hare",
            "Samantha YueYing Lim",
            "Seunghoon Hong",
            "Shengcai Liao",
            "Simon Hadfield",
            "S. Li",
            "Stefan Duffner",
            "Stuart Golodetz",
            "Thomas Mauthner",
            "Vibhav Vineet",
            "Weiyao Lin",
            "Yang Li",
            "Yuankai Qi",
            "Zhen Lei",
            "Zhi Heng Niu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "e3c433ab9608d7329f944552ba1721e277a42d74",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-VOT2013-challenge%3A-overview-and-additional-Kristan-Pflugfelder/4dff84213493bb177dc6bff266a9893538a1f879",
        "ID": "4dff84213493bb177dc6bff266a9893538a1f879",
        "Title": "The VOT2013 challenge: overview and additional results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) challenge and workshop\u2026\u00a0",
        "Publication Year": "2014",
        "Citation Count": "22",
        "Reference Count": "47",
        "Authors": [
            "Matej Kristan",
            "Roman P. Pflugfelder",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Fatih Murat Porikli",
            "Luka Cehovin",
            "Georg Nebehay",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "6169efdeca33714833b120152ae591b8a5f159fa",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "82635fb63640ae95f90ee9bdc07832eb461ca881",
            "edf6607f0c819390a13e60b722cc40f97359c9c4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Online-Object-Tracking-with-Proposal-Selection-Hua-Karteek/f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
        "ID": "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
        "Title": "Online Object Tracking with Proposal Selection",
        "Abstract": "Tracking-by-detection approaches are some of the most successful object trackers in recent years. Their success is largely determined by the detector model they learn initially and then update over time. However, under challenging conditions where an object can undergo transformations, e.g., severe rotation, these methods are found to be lacking. In this paper, we address this problem by formulating it as a proposal selection task and making two contributions. The first one is introducing novel\u2026\u00a0",
        "Publication Year": "30 September 2015",
        "Citation Count": "104",
        "Reference Count": "52",
        "Authors": [
            "Yang Hua",
            "Alahari Karteek",
            "Cordelia Schmid"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "d806cde30daef5ca1255c6a36c34c2931fd63604",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "b6d31905b671e6d442311c0e275772652df3abb6",
            "fe2aaad872a2cf08c09dd52ca972f323666306db",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "1183db5f409e8498d1a0f542703f908275a6dc34",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "894767a3911ce9295844579380b4a727f7a2a0bf"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Novel-Performance-Evaluation-Methodology-for-Kristan-Matas/0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
        "ID": "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
        "Title": "A Novel Performance Evaluation Methodology for Single-Target Trackers",
        "Abstract": "This paper addresses the problem of single-target tracker performance evaluation. We consider the performance measures, the dataset and the evaluation system to be the most important components of tracker evaluation and propose requirements for each of them. The requirements are the basis of a new evaluation methodology that aims at a simple and easily interpretable tracker comparison. The ranking-based methodology addresses tracker equivalence in terms of statistical significance and practical\u2026\u00a0",
        "Publication Year": "4 March 2015",
        "Citation Count": "548",
        "Reference Count": "88",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Roman P. Pflugfelder",
            "Gustavo Javier Fernandez",
            "Georg Nebehay",
            "Fatih Murat Porikli",
            "Luka Cehovin"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "edf6607f0c819390a13e60b722cc40f97359c9c4",
            "2258e01865367018ed6f4262c880df85b94959f8",
            "a52a6cf39054e6f406f67b57cc895e9df1163fc8",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "8f1a4c9be59b43175c86954829690084ac1e8a1a",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "681ee0059ed573265847785d110237861458304e",
            "0cae491292feccbc9ad1d864cf8b7144923ce6de",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Tracking%3A-An-Experimental-Survey-Smeulders-Chu/eda3368a5198ca55768b07b6f5667aea28baf2cd",
        "ID": "eda3368a5198ca55768b07b6f5667aea28baf2cd",
        "Title": "Visual Tracking: An Experimental Survey",
        "Abstract": "There is a large variety of trackers, which have been proposed in the literature during the last two decades with some mixed success. Object tracking in realistic scenarios is a difficult problem, therefore, it remains a most active area of research in computer vision. A good tracker should perform well in a large number of videos involving illumination changes, occlusion, clutter, camera motion, low contrast, specularities, and at least six more aspects. However, the performance of proposed\u2026\u00a0",
        "Publication Year": "1 July 2014",
        "Citation Count": "1,443",
        "Reference Count": "120",
        "Authors": [
            "Arnold W. M. Smeulders",
            "Dung Manh Chu",
            "Rita Cucchiara",
            "Simone Calderara",
            "Afshin Dehghan",
            "Mubarak Shah"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2258e01865367018ed6f4262c880df85b94959f8",
            "b762ecb0624005831f2f3d8eb626d53e8eca4b6c",
            "a52a6cf39054e6f406f67b57cc895e9df1163fc8",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "45e098084c676eee87a71806b7eb7ec03f0410c9",
            "68cc57640bfd04f697048534f82d16bf10a002ec",
            "8f1a4c9be59b43175c86954829690084ac1e8a1a",
            "da199480427da6b4c3800b11a91ef7f9bbbc90ee",
            "21d467174bdcf882eefcae2f10c23a1af5b3e73d",
            "070375a20acf9252f903164586c75110472cd84f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT-2016-Challenge-Kristan-Leonardis/6179ac06f1a8fd1ac6b693b02824948dff438d54",
        "ID": "6179ac06f1a8fd1ac6b693b02824948dff438d54",
        "Title": "The Visual Object Tracking VOT 2016 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply prelearned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a short\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "74",
        "Reference Count": "109",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman",
            "Pflugfelder",
            "Luka Cehovin",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Gustavo Javier Fernandez",
            "Abhinav Kumar Gupta",
            "Alfredo Petrosino",
            "Alireza",
            "Memarmoghadam",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Andrea",
            "Vedaldi",
            "Andreas Robinson",
            "Andy Jinhua Ma",
            "Anton Yuriiovych Varfolomieiev",
            "Aydin",
            "Alatan",
            "Aykut Erdem",
            "Bernard Ghanem",
            "Bin Liu",
            "Bohyung Han",
            "Brais Mart{\\&#x27;i}nez",
            "Chang-Ming Chang",
            "Changsheng Xu",
            "Chong Sun",
            "Daijin Kim",
            "Dapeng Chen",
            "Dawei Du",
            "Deepak Mishra",
            "Dit-Yan",
            "Yeung",
            "Erhan Gundogdu",
            "Erkut Erdem",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Fei Zhao",
            "Filiz Bunyak",
            "Francesco Battistone",
            "Gao Zhu",
            "Giorgio Roffo",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Henry Medeiros",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst",
            "Possegger",
            "Huchuan Lu",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Hyung Jin",
            "Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jae-Y. Lee",
            "Jianke Zhu",
            "Jiayi Feng",
            "Jin Gao",
            "Jin Young",
            "Choi",
            "Jingjing Xiao",
            "Ji-Wan Kim",
            "Jiyeoup Jeong",
            "Jo{\\~a}o F. Henriques",
            "Jochen Lang",
            "Jongwon Choi",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Junliang Xing",
            "Junyu",
            "Gao",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Krystian",
            "Miko\u0142ajczyk",
            "Lei Qin",
            "Lijun Wang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Madan Kumar Rapuru",
            "Mahdieh Poostchi",
            "Mario Edoardo Maresca",
            "Martin",
            "Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel",
            "Valstar",
            "Mooyeol Baek",
            "M. H. Khan",
            "Naiyan",
            "Wang",
            "Nana Fan",
            "Noor M. Al-Shakarji",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Osman Akin",
            "Payman Moallem",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Pong Chi Yuen",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan Pelapur",
            "Richard",
            "Bowden",
            "Robert Lagani{\\`e}re",
            "R. Stolkin",
            "Ryan Walsh",
            "Brock Sebastian",
            "Krah",
            "Shengkun Li",
            "Shengping Zhang",
            "Shizeng Yao",
            "Simon Hadfield",
            "Simone Melzi",
            "Siwei Lyu",
            "Siyi Li",
            "Stefan Becker",
            "Stuart Golodetz",
            "Sumithra Kakanuru",
            "Sunglok Choi",
            "Tao Hu",
            "Thomas Mauthner",
            "Tianzhu Zhang",
            "Tony P. Pridmore",
            "Vincenzo Santopietro",
            "Weiming Hu",
            "Wolfgang H{\\&quot;u}bner",
            "Xiangyuan Lan",
            "Xiaomeng Wang",
            "Y. Demiris",
            "Yifan Wang",
            "Yuankai Qi",
            "Ze-jian",
            "Yuan",
            "Zexiong Cai",
            "Zhan Xu",
            "Zhenyu He",
            "Zhizhen Chi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "2bcf2bd59219d89f335cbc8d1dd4f431076b4c4c",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2013-Challenge-Kristan-Matas/4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "ID": "4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "Title": "The Visual Object Tracking VOT2013 Challenge Results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) workshop was organized in\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "333",
        "Reference Count": "137",
        "Authors": [
            "Matej Kristan",
            "Juan E. Sala Matas",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Luka Cehovin",
            "Georg Nebehay",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustavo Javier Fernandez",
            "Alan Luke{\\vz}i{\\vc}",
            "Aleksandar Dimitriev",
            "Alfredo Petrosino",
            "Amir Saffari",
            "Bo Li",
            "Bohyung Han",
            "Cherkeng Heng",
            "Christophe Garcia",
            "Dominik Pangersic",
            "Gustav H{\\&quot;a}ger",
            "Fahad Shahbaz Khan",
            "Franc Oven",
            "Horst Possegger",
            "Horst Bischof",
            "Hyeonseob Nam",
            "Jianke Zhu",
            "Jijia Li",
            "Jin Young Choi",
            "Jinwoo Choi",
            "Jo{\\~a}o F. Henriques",
            "Joost van de Weijer",
            "Jorge Batista",
            "Karel Lebeda",
            "Kristoffer {\\&quot;O}fj{\\&quot;a}ll",
            "Kwang Moo Yi",
            "Lei Qin",
            "Longyin Wen",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Michael Felsberg",
            "Ming-Ming Cheng",
            "Philip H. S. Torr",
            "Qingming Huang",
            "R. Bowden",
            "Sam Hare",
            "Samantha YueYing Lim",
            "Seunghoon Hong",
            "Shengcai Liao",
            "Simon Hadfield",
            "S. Li",
            "Stefan Duffner",
            "Stuart Golodetz",
            "Thomas Mauthner",
            "Vibhav Vineet",
            "Weiyao Lin",
            "Yang Li",
            "Yuankai Qi",
            "Zhen Lei",
            "Zhi Heng Niu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "e3c433ab9608d7329f944552ba1721e277a42d74",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Visual-Object-Tracking-Benchmark-Moudgil-Gandhi/19d6b9725a59f4b624205829d5f03ac893ca1367",
        "ID": "19d6b9725a59f4b624205829d5f03ac893ca1367",
        "Title": "Long-Term Visual Object Tracking Benchmark",
        "Abstract": "We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term\u2026\u00a0",
        "Publication Year": "4 December 2017",
        "Citation Count": "74",
        "Reference Count": "47",
        "Authors": [
            "A. Moudgil",
            "Vineet Gandhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2013-Challenge-Kristan-Matas/4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "ID": "4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "Title": "The Visual Object Tracking VOT2013 Challenge Results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) workshop was organized in\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "333",
        "Reference Count": "137",
        "Authors": [
            "Matej Kristan",
            "Juan E. Sala Matas",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Luka Cehovin",
            "Georg Nebehay",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustavo Javier Fernandez",
            "Alan Luke{\\vz}i{\\vc}",
            "Aleksandar Dimitriev",
            "Alfredo Petrosino",
            "Amir Saffari",
            "Bo Li",
            "Bohyung Han",
            "Cherkeng Heng",
            "Christophe Garcia",
            "Dominik Pangersic",
            "Gustav H{\\&quot;a}ger",
            "Fahad Shahbaz Khan",
            "Franc Oven",
            "Horst Possegger",
            "Horst Bischof",
            "Hyeonseob Nam",
            "Jianke Zhu",
            "Jijia Li",
            "Jin Young Choi",
            "Jinwoo Choi",
            "Jo{\\~a}o F. Henriques",
            "Joost van de Weijer",
            "Jorge Batista",
            "Karel Lebeda",
            "Kristoffer {\\&quot;O}fj{\\&quot;a}ll",
            "Kwang Moo Yi",
            "Lei Qin",
            "Longyin Wen",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Michael Felsberg",
            "Ming-Ming Cheng",
            "Philip H. S. Torr",
            "Qingming Huang",
            "R. Bowden",
            "Sam Hare",
            "Samantha YueYing Lim",
            "Seunghoon Hong",
            "Shengcai Liao",
            "Simon Hadfield",
            "S. Li",
            "Stefan Duffner",
            "Stuart Golodetz",
            "Thomas Mauthner",
            "Vibhav Vineet",
            "Weiyao Lin",
            "Yang Li",
            "Yuankai Qi",
            "Zhen Lei",
            "Zhi Heng Niu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "e3c433ab9608d7329f944552ba1721e277a42d74",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-VOT2013-challenge%3A-overview-and-additional-Kristan-Pflugfelder/4dff84213493bb177dc6bff266a9893538a1f879",
        "ID": "4dff84213493bb177dc6bff266a9893538a1f879",
        "Title": "The VOT2013 challenge: overview and additional results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) challenge and workshop\u2026\u00a0",
        "Publication Year": "2014",
        "Citation Count": "22",
        "Reference Count": "47",
        "Authors": [
            "Matej Kristan",
            "Roman P. Pflugfelder",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Fatih Murat Porikli",
            "Luka Cehovin",
            "Georg Nebehay",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "6169efdeca33714833b120152ae591b8a5f159fa",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "82635fb63640ae95f90ee9bdc07832eb461ca881",
            "edf6607f0c819390a13e60b722cc40f97359c9c4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2014-challenge-Kristan-Pflugfelder/17f16b89edaed5d16867287ed8a85e917304b4ba",
        "ID": "17f16b89edaed5d16867287ed8a85e917304b4ba",
        "Title": "The Visual Object Tracking VOT2014 challenge results",
        "Abstract": ". The Visual Object Tracking challenge 2014, VOT2014, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 38 trackers are\u00a0",
        "Publication Year": "2014",
        "Citation Count": "267",
        "Reference Count": "70",
        "Authors": [
            "Matej Kristan",
            "Roman P. Pflugfelder",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Luk{\\&#x27;a}",
            "{\\vC}ehovin",
            "Georg Nebehay",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustavo Javier Fernandez",
            "Alan Luke{\\vz}i{\\vc}",
            "Aleksandar Dimitriev",
            "Alfredo Petrosino",
            "Amir Saffari",
            "Bo Li",
            "Bohyung",
            "Han",
            "Cherkeng Heng",
            "Christophe Garcia",
            "Dominik Pangersic",
            "Gustav",
            "H{\\&quot;a}ger",
            "Fahad Shahbaz Khan",
            "Franc Oven",
            "Horst Possegger",
            "Horst",
            "Bischof",
            "Hyeonseob Nam",
            "Jianke Zhu",
            "Jijiao Li",
            "Jin Young Choi",
            "Jinwoo Choi",
            "Jo{\\~a}o F. Henriques",
            "Joost van de Weijer",
            "Jorge Batista",
            "Karel Lebeda",
            "Kristoffer {\\&quot;O}fj{\\&quot;a}ll",
            "Kwang Moo Yi",
            "Lei Qin",
            "Longyin",
            "Wen",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Michael Felsberg",
            "Ming-Ming Cheng",
            "Philip H. S. Torr",
            "Qi Huang",
            "R. Bowden",
            "Sam Hare",
            "Samantha YueYing Lim",
            "Seunghoon Hong",
            "Shengcai Liao",
            "Simon Hadfield",
            "S. Li",
            "Stefan Duffner",
            "Stuart Golodetz",
            "Thomas",
            "Mauthner",
            "Vibhav Vineet",
            "Weiyao Lin",
            "Yang Li",
            "Yuankai Qi",
            "Zhen",
            "Lei",
            "Zhiheng Niu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1c42b5543c315556c8a961b1a4ee8bc027f70b22",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "f5dbe4550d24d5374d9e10fce44a35b105c7ee07"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Online-Object-Tracking-with-Proposal-Selection-Hua-Karteek/f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
        "ID": "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
        "Title": "Online Object Tracking with Proposal Selection",
        "Abstract": "Tracking-by-detection approaches are some of the most successful object trackers in recent years. Their success is largely determined by the detector model they learn initially and then update over time. However, under challenging conditions where an object can undergo transformations, e.g., severe rotation, these methods are found to be lacking. In this paper, we address this problem by formulating it as a proposal selection task and making two contributions. The first one is introducing novel\u2026\u00a0",
        "Publication Year": "30 September 2015",
        "Citation Count": "104",
        "Reference Count": "52",
        "Authors": [
            "Yang Hua",
            "Alahari Karteek",
            "Cordelia Schmid"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "d806cde30daef5ca1255c6a36c34c2931fd63604",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "b6d31905b671e6d442311c0e275772652df3abb6",
            "fe2aaad872a2cf08c09dd52ca972f323666306db",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "1183db5f409e8498d1a0f542703f908275a6dc34",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "894767a3911ce9295844579380b4a727f7a2a0bf"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Tracking-through-Failure-Cases-Lebeda-Hadfield/9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "ID": "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "Title": "Long-Term Tracking through Failure Cases",
        "Abstract": "Long term tracking of an object, given only a single instance in an initial frame, remains an open problem. We propose a visual tracking algorithm, robust to many of the difficulties which often occur in real-world scenes. Correspondences of edge-based features are used, to overcome the reliance on the texture of the tracked object and improve invariance to lighting. Furthermore we address long-term stability, enabling the tracker to recover from drift and to provide redetection following\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "54",
        "Reference Count": "17",
        "Authors": [
            "Karel Lebeda",
            "Simon Hadfield",
            "Jiri Matas",
            "R. Bowden"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "00058304b7c51b9dcf837d4125cab0a4b0588aef",
            "5b9ace65f7368f6dc6907c8f6f7c3b0c248d9bc4",
            "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca",
            "4411f262853bf7f1eb8e2efe03eb0402f5e9ad2c",
            "fcba52c59e8537e48e747207837cefd04786bd3d",
            "948a74b25508ab674be06f6a94ca8bc07a082361",
            "dfa5a0cce66f9e840dd98ac8094434efcc4a9de5",
            "779220bb5190b976e025dc649b2e9a0e4b3597b9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Novel-Performance-Evaluation-Methodology-for-Kristan-Matas/0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
        "ID": "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
        "Title": "A Novel Performance Evaluation Methodology for Single-Target Trackers",
        "Abstract": "This paper addresses the problem of single-target tracker performance evaluation. We consider the performance measures, the dataset and the evaluation system to be the most important components of tracker evaluation and propose requirements for each of them. The requirements are the basis of a new evaluation methodology that aims at a simple and easily interpretable tracker comparison. The ranking-based methodology addresses tracker equivalence in terms of statistical significance and practical\u2026\u00a0",
        "Publication Year": "4 March 2015",
        "Citation Count": "548",
        "Reference Count": "88",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Roman P. Pflugfelder",
            "Gustavo Javier Fernandez",
            "Georg Nebehay",
            "Fatih Murat Porikli",
            "Luka Cehovin"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "edf6607f0c819390a13e60b722cc40f97359c9c4",
            "2258e01865367018ed6f4262c880df85b94959f8",
            "a52a6cf39054e6f406f67b57cc895e9df1163fc8",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "8f1a4c9be59b43175c86954829690084ac1e8a1a",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "681ee0059ed573265847785d110237861458304e",
            "0cae491292feccbc9ad1d864cf8b7144923ce6de",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Using-Discriminative-Motion-Context-for-Online-Duffner-Garcia/7b75da6f5edac80575d9dcf63db164ce24933907",
        "ID": "7b75da6f5edac80575d9dcf63db164ce24933907",
        "Title": "Using Discriminative Motion Context for Online Visual Object Tracking",
        "Abstract": "In this paper, we propose an algorithm for online, real-time tracking of arbitrary objects in videos from unconstrained environments. The method is based on a particle filter framework using different visual features and motion prediction models. We effectively integrate a discriminative online learning classifier into the model and propose a new method to collect negative training examples for updating the classifier at each video frame. Instead of taking negative examples only from the\u2026\u00a0",
        "Publication Year": "1 December 2016",
        "Citation Count": "19",
        "Reference Count": "60",
        "Authors": [
            "Stefan Duffner",
            "Christophe Garcia"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "f9dbc7f2ef8ed42ff3fdc08d12116761fbbb4865",
            "421bf4eeba623f722bf98340d71e3d229881e92d",
            "27b6ed73dce051539494100d2dfdaca27d671556",
            "c559e4099a6351837753b0a413f9bafed90f5dcd",
            "d11e63d81ca01288ff55a8ae2a9eddba7c9c1f6c",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "3d98b9822e6efc2eec421e0bfd7546fd4ba30407",
            "1183db5f409e8498d1a0f542703f908275a6dc34",
            "452e7a99b67efbdca55008d40e859c8156bfab9f",
            "d806cde30daef5ca1255c6a36c34c2931fd63604"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT-2017-challenge-Kristan-Leonardis/53329e5c79c1128c7b252a12b182c472a3413bfa",
        "ID": "53329e5c79c1128c7b252a12b182c472a3413bfa",
        "Title": "The Visual Object Tracking VOT 2017 challenge results",
        "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \u201creal-time\u201d experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "38",
        "Reference Count": "81",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin",
            "Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "Andrej Muhic",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea",
            "Vedaldi",
            "Antoine Manzanera",
            "Antoine Tran",
            "A. Aydin Alatan",
            "Bogdan Cosmin Mocanu",
            "Boyu Chen",
            "Chang Huang",
            "Changsheng Xu",
            "Chong Sun",
            "Dalong Du",
            "David Zhang",
            "Dawei Du",
            "Deepak",
            "Mishra",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Francesco Battistone",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Goutam Bhat",
            "Guan Huang",
            "Guilherme Sousa Bastos",
            "Guna",
            "Seetharaman",
            "Hongliang Zhang",
            "Houqiang Li",
            "Huchuan Lu",
            "Isabela Drummond",
            "Jack",
            "Valmadre",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Y. Lee",
            "Jana Noskova",
            "Jianke Zhu",
            "Jin Gao",
            "Jingyu Liu",
            "Ji-Wan Kim",
            "Jo{\\~a}o F. Henriques",
            "Junfei Zhuang",
            "Junliang Xing",
            "Junyu Gao",
            "Kai Chen",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Kris Kitani",
            "Lei",
            "Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh Poostchi",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Ming-Hsuan Yang",
            "Nianhao Xie",
            "Ning",
            "Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "M PallaviVenugopal",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Qifeng Yu",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "R. Bowden",
            "Ri-sheng",
            "Liu",
            "Ruxandra Tapu",
            "Simon Hadfield",
            "Siwei Lyu",
            "Stuart Golodetz",
            "Sunglok Choi",
            "Tianzhu",
            "Titus B. Zaharia",
            "Vincenzo Santopietro",
            "Wei Zou",
            "Weiming Hu",
            "Wenbing Tao",
            "Wenbo",
            "Li",
            "Wen-gang Zhou",
            "Xianguo Yu",
            "Xiao Bian",
            "Yang Li",
            "Yifan Xing",
            "Yingruo Fan",
            "Zheng",
            "Zhu",
            "Zhipeng Zhang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-object-tracking-challenges-revisited%3A-VOT-Bei-Zhen/4b90dfbd6983cf9d47d1053efe630c515f9833b5",
        "ID": "4b90dfbd6983cf9d47d1053efe630c515f9833b5",
        "Title": "Visual object tracking challenges revisited: VOT vs. OTB",
        "Abstract": "Numerous benchmark datasets and evaluation toolkits have been designed to facilitate visual object tracking evaluation. However, it is not clear which evaluation protocols are preferred for different tracking objectives. Even worse, different evaluation protocols sometimes yield contradictory conclusions, further hampering reliable evaluation. Therefore, we 1) introduce the new concept of mirror tracking to measure the robustness of a tracker and identify its over-fitting scenarios; 2) measure\u2026\u00a0",
        "Publication Year": "27 September 2018",
        "Citation Count": "5",
        "Reference Count": "31",
        "Authors": [
            "Sun Bei",
            "Zuo Zhen",
            "Luo Wusheng",
            "Du Liebo",
            "Lu Qin"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "bf97833a354d7faa3793599ac5c1ec1eb3eb7e07",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "ce8c76bfedc5d86faabf0d49dc42a4924f75876d",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Motion-Prediction-in-Visual-Object-Tracking-Wang-He/985b3593bb5981d933c6002e4e316a1d8f448c5c",
        "ID": "985b3593bb5981d933c6002e4e316a1d8f448c5c",
        "Title": "Motion Prediction in Visual Object Tracking",
        "Abstract": "Visual object tracking (VOT) is an essential component for many applications, such as autonomous driving or assistive robotics. However, recent works tend to develop accurate systems based on more computationally expensive feature extractors for better instance matching. In contrast, this work addresses the importance of motion prediction in VOT. We use an off-the-shelf object detector to obtain instance bounding boxes. Then, a combination of camera motion decouple and Kalman filter is used for\u2026\u00a0",
        "Publication Year": "1 July 2020",
        "Citation Count": "3",
        "Reference Count": "55",
        "Authors": [
            "Jianren Wang",
            "Yihui He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "ce8c76bfedc5d86faabf0d49dc42a4924f75876d",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "91a91387f3c886507d4076ef993718c6b7353e99",
            "01f46bd91e053ce0c92af126bb87d7381a9fbe29",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "d721f4d64b8e722222c876f0a0f226ed49476347"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2015-Challenge-Kristan-Matas/15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
        "ID": "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
        "Title": "The Visual Object Tracking VOT2015 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 pre-decessor are: (i) a new VOT2015 dataset twice\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "357",
        "Reference Count": "84",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Luka Cehovin",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Georg Nebehay",
            "Roman P. Pflugfelder",
            "Abhinav Kumar Gupta",
            "Adel Bibi",
            "Alan",
            "Luke{\\vz}i{\\vc}",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Amir Saffari",
            "Alfredo Petrosino",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Anton",
            "Varfolomieiev",
            "Atilla Baskurt",
            "Baojun Zhao",
            "Bernard Ghanem",
            "Brais Mart{\\&#x27;i}nez",
            "ByeongJu",
            "Lee",
            "Bohyung Han",
            "Chaohui Wang",
            "Christophe Garcia",
            "Chunyuan Zhang",
            "Cordelia",
            "Schmid",
            "Dacheng Tao",
            "Daijin Kim",
            "Dafei Huang",
            "Danil V. Prokhorov",
            "Dawei Du",
            "Dit-Yan",
            "Yeung",
            "Eraldo Ribeiro",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Filiz Bunyak",
            "Gao Zhu",
            "Guna",
            "Seetharaman",
            "Hilke Kieritz",
            "Hing Tuen Yau",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst Possegger",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Ivan Bogun",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Yeong Lee",
            "Jianke Zhu",
            "Jianping Shi",
            "Jiatong Li",
            "J E Jia",
            "Jiayi Feng",
            "Jin Gao",
            "Jin",
            "Youngjoon Choi",
            "Ji-Wan Kim",
            "Jochen von Lang",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Jongwon Choi",
            "Junliang Xing",
            "Kai",
            "Xue",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Alahari Karteek",
            "Ke Gao",
            "Kimin Yun",
            "Kin",
            "Hong Wen Benedict Wong",
            "Lei Luo",
            "Liang Ma",
            "Lipeng Ke",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh",
            "Pootschi",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Mei Wen",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel F. Valstar",
            "Mingxi Tang",
            "Mr Chang",
            "Muhammad Haris Khan",
            "Nana Fan",
            "Naiyan",
            "Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan",
            "Pelapur",
            "R. Bowden",
            "Robert Lagani{\\`e}re",
            "Salma Moujtahid",
            "Sam Hare",
            "Simon Hadfield",
            "Siwei Lyu",
            "Siyi Li",
            "Song Zhu",
            "Stefan Becker",
            "Stefan Duffner",
            "Stephen L. Hicks",
            "Stuart Golodetz",
            "Sun Young Choi",
            "Tianfu Wu",
            "Thomas Mauthner",
            "Tony P. Pridmore",
            "Weiming",
            "Hu",
            "Wolfgang H{\\&quot;u}bner",
            "Xiaomeng Wang",
            "Xin Li",
            "Xinchu Shi",
            "Xuehua Zhao",
            "Xue Mei",
            "Yao",
            "Shizeng",
            "Yang Hua",
            "Yang Li",
            "Yangchun Lu",
            "Yuezun Li",
            "Zhaoyun Chen",
            "Zehua Huang",
            "Zhe",
            "Chen",
            "Zhe Zhang",
            "Zhenyu He",
            "Zhibin Hong"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "7b75da6f5edac80575d9dcf63db164ce24933907"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2013-Challenge-Kristan-Matas/4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "ID": "4b1a47709d0546e5bc614bf9a521c550e6881d04",
        "Title": "The Visual Object Tracking VOT2013 Challenge Results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) workshop was organized in\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "333",
        "Reference Count": "137",
        "Authors": [
            "Matej Kristan",
            "Juan E. Sala Matas",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Luka Cehovin",
            "Georg Nebehay",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustavo Javier Fernandez",
            "Alan Luke{\\vz}i{\\vc}",
            "Aleksandar Dimitriev",
            "Alfredo Petrosino",
            "Amir Saffari",
            "Bo Li",
            "Bohyung Han",
            "Cherkeng Heng",
            "Christophe Garcia",
            "Dominik Pangersic",
            "Gustav H{\\&quot;a}ger",
            "Fahad Shahbaz Khan",
            "Franc Oven",
            "Horst Possegger",
            "Horst Bischof",
            "Hyeonseob Nam",
            "Jianke Zhu",
            "Jijia Li",
            "Jin Young Choi",
            "Jinwoo Choi",
            "Jo{\\~a}o F. Henriques",
            "Joost van de Weijer",
            "Jorge Batista",
            "Karel Lebeda",
            "Kristoffer {\\&quot;O}fj{\\&quot;a}ll",
            "Kwang Moo Yi",
            "Lei Qin",
            "Longyin Wen",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Michael Felsberg",
            "Ming-Ming Cheng",
            "Philip H. S. Torr",
            "Qingming Huang",
            "R. Bowden",
            "Sam Hare",
            "Samantha YueYing Lim",
            "Seunghoon Hong",
            "Shengcai Liao",
            "Simon Hadfield",
            "S. Li",
            "Stefan Duffner",
            "Stuart Golodetz",
            "Thomas Mauthner",
            "Vibhav Vineet",
            "Weiyao Lin",
            "Yang Li",
            "Yuankai Qi",
            "Zhen Lei",
            "Zhi Heng Niu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "e3c433ab9608d7329f944552ba1721e277a42d74",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Tracking-through-Failure-Cases-Lebeda-Hadfield/9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "ID": "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "Title": "Long-Term Tracking through Failure Cases",
        "Abstract": "Long term tracking of an object, given only a single instance in an initial frame, remains an open problem. We propose a visual tracking algorithm, robust to many of the difficulties which often occur in real-world scenes. Correspondences of edge-based features are used, to overcome the reliance on the texture of the tracked object and improve invariance to lighting. Furthermore we address long-term stability, enabling the tracker to recover from drift and to provide redetection following\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "54",
        "Reference Count": "17",
        "Authors": [
            "Karel Lebeda",
            "Simon Hadfield",
            "Jiri Matas",
            "R. Bowden"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "00058304b7c51b9dcf837d4125cab0a4b0588aef",
            "5b9ace65f7368f6dc6907c8f6f7c3b0c248d9bc4",
            "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca",
            "4411f262853bf7f1eb8e2efe03eb0402f5e9ad2c",
            "fcba52c59e8537e48e747207837cefd04786bd3d",
            "948a74b25508ab674be06f6a94ca8bc07a082361",
            "dfa5a0cce66f9e840dd98ac8094434efcc4a9de5",
            "779220bb5190b976e025dc649b2e9a0e4b3597b9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/MOTChallenge-2015%3A-Towards-a-Benchmark-for-Tracking-Leal-Taix%C3%A9-Milan/5bae9822d703c585a61575dced83fa2f4dea1c6d",
        "ID": "5bae9822d703c585a61575dced83fa2f4dea1c6d",
        "Title": "MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking",
        "Abstract": "In the recent past, the computer vision community has developed centralized benchmarks for the performance evaluation of a variety of tasks, including generic object and pedestrian detection, 3D reconstruction, optical flow, single-object short-term tracking, and stereo estimation. Despite potential pitfalls of such benchmarks, they have proved to be extremely helpful to advance the state of the art in the respective area. Interestingly, there has been rather limited work on the standardization\u2026\u00a0",
        "Publication Year": "8 April 2015",
        "Citation Count": "614",
        "Reference Count": "57",
        "Authors": [
            "Laura Leal-Taix{\\&#x27;e}",
            "Anton Milan",
            "Ian D. Reid",
            "Stefan Roth",
            "Konrad Schindler"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3e083dc8aeb7983a5cdff146985363d38caf0886",
            "2258e01865367018ed6f4262c880df85b94959f8",
            "de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42",
            "aa574e55ea3401ec9bc500eed990e4f402730d26",
            "616fda61990097f0401b33dbf01541bd83a939a0",
            "0302bb2d5476540cfb21467473f5eca843caf90b",
            "5b1e33f60514a307054de5642a13051c1e1438b6",
            "9b49f70bcaf6e473930681b9a0562f130ae01533",
            "b238f3f2a487271973c573634611229c432cf467",
            "f042e85c26cd3638fcdc6599aa546d85045a7c5d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Single-Object-Long-term-Tracker-for-Smart-Control-a-Gonz%C3%A1lez-Nieto/f15d5c0a9d2f3678b4c16330da29b3b4511fdef5",
        "ID": "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5",
        "Title": "Single Object Long-term Tracker for Smart Control of a PTZ camera",
        "Abstract": "In this paper, we present a single-object long-term tracker that supports high appearance changes in the tracked target, occlusions, and is also capable of recovering a target lost during the tracking process. The initial motivation was real time automatic speaker tracking by a static camera in order to control a PTZ camera capturing a lecture. The algorithm consists of a novel combination of state-of-the-art techniques. Subjective evaluation, over existing and newly recorded sequences, shows\u2026\u00a0",
        "Publication Year": "4 November 2014",
        "Citation Count": "20",
        "Reference Count": "35",
        "Authors": [
            "Antonio Gonz{\\&#x27;a}lez",
            "Rafael Martin Nieto",
            "Jes{\\&#x27;u}s Besc{\\&#x27;o}s",
            "Jos{\\&#x27;e} Mar{\\&#x27;i}a Mart{\\&#x27;i}nez Sanchez"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "aefb61185c181edf073dd54045030c406d9205b0",
            "aff9ed00a2196b4aa7a7968ced25207eb055695c",
            "2cfa006b33084abe8160b001f9a24944cda25d05",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "e11dab9ddf9ec9b2a0fa35e4b91656ee2ad63aa0",
            "5f3bda82a3f43cae7deae1dabc7d10ff3dc7a1ae",
            "bb9535eb9e64cf2c0ec59f550dbfdbde02da76b9",
            "5cd62c4ace35e93dadb4d69fe76914edd1d331bb",
            "5254cfffad6e2b4f26dd8d2f32fbd62a6d4354ee"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Texture-Independent-Long-Term-Tracking-Using-Lebeda-Hadfield/16be98fa5924131816bc991a2c7ed91b8c69eaaa",
        "ID": "16be98fa5924131816bc991a2c7ed91b8c69eaaa",
        "Title": "Texture-Independent Long-Term Tracking Using Virtual Corners",
        "Abstract": "Long-term tracking of an object, given only a single instance in an initial frame, remains an open problem. We propose a visual tracking algorithm, robust to many of the difficulties that often occur in real-world scenes. Correspondences of edge-based features are used, to overcome the reliance on the texture of the tracked object and improve invariance to lighting. Furthermore, we address long-term stability, enabling the tracker to recover from drift and to provide redetection following\u2026\u00a0",
        "Publication Year": "1 January 2016",
        "Citation Count": "26",
        "Reference Count": "34",
        "Authors": [
            "Karel Lebeda",
            "Simon Hadfield",
            "Jiri Matas",
            "R. Bowden"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "38c32f42794bc1162084c4d16e808114f21b796b",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "36b4ed1c2cdcd5acff711eb7d1fe712d4a7d2854",
            "00058304b7c51b9dcf837d4125cab0a4b0588aef",
            "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca",
            "4411f262853bf7f1eb8e2efe03eb0402f5e9ad2c",
            "948a74b25508ab674be06f6a94ca8bc07a082361",
            "c63a34ac6a4e049118070e707ca7679fbb132d33"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-VOT2013-challenge%3A-overview-and-additional-Kristan-Pflugfelder/4dff84213493bb177dc6bff266a9893538a1f879",
        "ID": "4dff84213493bb177dc6bff266a9893538a1f879",
        "Title": "The VOT2013 challenge: overview and additional results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) challenge and workshop\u2026\u00a0",
        "Publication Year": "2014",
        "Citation Count": "22",
        "Reference Count": "47",
        "Authors": [
            "Matej Kristan",
            "Roman P. Pflugfelder",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Fatih Murat Porikli",
            "Luka Cehovin",
            "Georg Nebehay",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "6169efdeca33714833b120152ae591b8a5f159fa",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "82635fb63640ae95f90ee9bdc07832eb461ca881",
            "edf6607f0c819390a13e60b722cc40f97359c9c4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT-2016-Challenge-Kristan-Leonardis/6179ac06f1a8fd1ac6b693b02824948dff438d54",
        "ID": "6179ac06f1a8fd1ac6b693b02824948dff438d54",
        "Title": "The Visual Object Tracking VOT 2016 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply prelearned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a short\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "74",
        "Reference Count": "109",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman",
            "Pflugfelder",
            "Luka Cehovin",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Gustavo Javier Fernandez",
            "Abhinav Kumar Gupta",
            "Alfredo Petrosino",
            "Alireza",
            "Memarmoghadam",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Andrea",
            "Vedaldi",
            "Andreas Robinson",
            "Andy Jinhua Ma",
            "Anton Yuriiovych Varfolomieiev",
            "Aydin",
            "Alatan",
            "Aykut Erdem",
            "Bernard Ghanem",
            "Bin Liu",
            "Bohyung Han",
            "Brais Mart{\\&#x27;i}nez",
            "Chang-Ming Chang",
            "Changsheng Xu",
            "Chong Sun",
            "Daijin Kim",
            "Dapeng Chen",
            "Dawei Du",
            "Deepak Mishra",
            "Dit-Yan",
            "Yeung",
            "Erhan Gundogdu",
            "Erkut Erdem",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Fei Zhao",
            "Filiz Bunyak",
            "Francesco Battistone",
            "Gao Zhu",
            "Giorgio Roffo",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Guilherme Sousa Bastos",
            "Guna Seetharaman",
            "Henry Medeiros",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst",
            "Possegger",
            "Huchuan Lu",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Hyung Jin",
            "Chang",
            "Isabela Drummond",
            "Jack Valmadre",
            "Jae-chan Jeong",
            "Jae-Y. Lee",
            "Jianke Zhu",
            "Jiayi Feng",
            "Jin Gao",
            "Jin Young",
            "Choi",
            "Jingjing Xiao",
            "Ji-Wan Kim",
            "Jiyeoup Jeong",
            "Jo{\\~a}o F. Henriques",
            "Jochen Lang",
            "Jongwon Choi",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Junliang Xing",
            "Junyu",
            "Gao",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Krystian",
            "Miko\u0142ajczyk",
            "Lei Qin",
            "Lijun Wang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Madan Kumar Rapuru",
            "Mahdieh Poostchi",
            "Mario Edoardo Maresca",
            "Martin",
            "Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel",
            "Valstar",
            "Mooyeol Baek",
            "M. H. Khan",
            "Naiyan",
            "Wang",
            "Nana Fan",
            "Noor M. Al-Shakarji",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Osman Akin",
            "Payman Moallem",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Pong Chi Yuen",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan Pelapur",
            "Richard",
            "Bowden",
            "Robert Lagani{\\`e}re",
            "R. Stolkin",
            "Ryan Walsh",
            "Brock Sebastian",
            "Krah",
            "Shengkun Li",
            "Shengping Zhang",
            "Shizeng Yao",
            "Simon Hadfield",
            "Simone Melzi",
            "Siwei Lyu",
            "Siyi Li",
            "Stefan Becker",
            "Stuart Golodetz",
            "Sumithra Kakanuru",
            "Sunglok Choi",
            "Tao Hu",
            "Thomas Mauthner",
            "Tianzhu Zhang",
            "Tony P. Pridmore",
            "Vincenzo Santopietro",
            "Weiming Hu",
            "Wolfgang H{\\&quot;u}bner",
            "Xiangyuan Lan",
            "Xiaomeng Wang",
            "Y. Demiris",
            "Yifan Wang",
            "Yuankai Qi",
            "Ze-jian",
            "Yuan",
            "Zexiong Cai",
            "Zhan Xu",
            "Zhenyu He",
            "Zhizhen Chi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "2bcf2bd59219d89f335cbc8d1dd4f431076b4c4c",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2015-Challenge-Kristan-Matas/15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
        "ID": "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
        "Title": "The Visual Object Tracking VOT2015 Challenge Results",
        "Abstract": "The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 pre-decessor are: (i) a new VOT2015 dataset twice\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "357",
        "Reference Count": "84",
        "Authors": [
            "Matej Kristan",
            "Jiri Matas",
            "Ale{\\vs} Leonardis",
            "Michael Felsberg",
            "Luka Cehovin",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Georg Nebehay",
            "Roman P. Pflugfelder",
            "Abhinav Kumar Gupta",
            "Adel Bibi",
            "Alan",
            "Luke{\\vz}i{\\vc}",
            "{\\&#x27;A}lvaro Garc{\\&#x27;i}a-Mart{\\&#x27;i}n",
            "Amir Saffari",
            "Alfredo Petrosino",
            "Andr{\\&#x27;e}s Sol{\\&#x27;i}s Montero",
            "Anton",
            "Varfolomieiev",
            "Atilla Baskurt",
            "Baojun Zhao",
            "Bernard Ghanem",
            "Brais Mart{\\&#x27;i}nez",
            "ByeongJu",
            "Lee",
            "Bohyung Han",
            "Chaohui Wang",
            "Christophe Garcia",
            "Chunyuan Zhang",
            "Cordelia",
            "Schmid",
            "Dacheng Tao",
            "Daijin Kim",
            "Dafei Huang",
            "Danil V. Prokhorov",
            "Dawei Du",
            "Dit-Yan",
            "Yeung",
            "Eraldo Ribeiro",
            "Fahad Shahbaz Khan",
            "Fatih Murat Porikli",
            "Filiz Bunyak",
            "Gao Zhu",
            "Guna",
            "Seetharaman",
            "Hilke Kieritz",
            "Hing Tuen Yau",
            "Hongdong Li",
            "Honggang Qi",
            "Horst Bischof",
            "Horst Possegger",
            "Hyemin Lee",
            "Hyeonseob Nam",
            "Ivan Bogun",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Yeong Lee",
            "Jianke Zhu",
            "Jianping Shi",
            "Jiatong Li",
            "J E Jia",
            "Jiayi Feng",
            "Jin Gao",
            "Jin",
            "Youngjoon Choi",
            "Ji-Wan Kim",
            "Jochen von Lang",
            "Jos{\\&#x27;e} M. Mart{\\&#x27;i}nez",
            "Jongwon Choi",
            "Junliang Xing",
            "Kai",
            "Xue",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Alahari Karteek",
            "Ke Gao",
            "Kimin Yun",
            "Kin",
            "Hong Wen Benedict Wong",
            "Lei Luo",
            "Liang Ma",
            "Lipeng Ke",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh",
            "Pootschi",
            "Mario Edoardo Maresca",
            "Martin Danelljan",
            "Mei Wen",
            "Mengdan Zhang",
            "Michael Arens",
            "Michel F. Valstar",
            "Mingxi Tang",
            "Mr Chang",
            "Muhammad Haris Khan",
            "Nana Fan",
            "Naiyan",
            "Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "Rengarajan",
            "Pelapur",
            "R. Bowden",
            "Robert Lagani{\\`e}re",
            "Salma Moujtahid",
            "Sam Hare",
            "Simon Hadfield",
            "Siwei Lyu",
            "Siyi Li",
            "Song Zhu",
            "Stefan Becker",
            "Stefan Duffner",
            "Stephen L. Hicks",
            "Stuart Golodetz",
            "Sun Young Choi",
            "Tianfu Wu",
            "Thomas Mauthner",
            "Tony P. Pridmore",
            "Weiming",
            "Hu",
            "Wolfgang H{\\&quot;u}bner",
            "Xiaomeng Wang",
            "Xin Li",
            "Xinchu Shi",
            "Xuehua Zhao",
            "Xue Mei",
            "Yao",
            "Shizeng",
            "Yang Hua",
            "Yang Li",
            "Yangchun Lu",
            "Yuezun Li",
            "Zhaoyun Chen",
            "Zehua Huang",
            "Zhe",
            "Chen",
            "Zhe Zhang",
            "Zhenyu He",
            "Zhibin Hong"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "4dff84213493bb177dc6bff266a9893538a1f879",
            "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "7b75da6f5edac80575d9dcf63db164ce24933907"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT-2017-challenge-Kristan-Leonardis/53329e5c79c1128c7b252a12b182c472a3413bfa",
        "ID": "53329e5c79c1128c7b252a12b182c472a3413bfa",
        "Title": "The Visual Object Tracking VOT 2017 challenge results",
        "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \u201creal-time\u201d experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "38",
        "Reference Count": "81",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin",
            "Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "Andrej Muhic",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea",
            "Vedaldi",
            "Antoine Manzanera",
            "Antoine Tran",
            "A. Aydin Alatan",
            "Bogdan Cosmin Mocanu",
            "Boyu Chen",
            "Chang Huang",
            "Changsheng Xu",
            "Chong Sun",
            "Dalong Du",
            "David Zhang",
            "Dawei Du",
            "Deepak",
            "Mishra",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Francesco Battistone",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Goutam Bhat",
            "Guan Huang",
            "Guilherme Sousa Bastos",
            "Guna",
            "Seetharaman",
            "Hongliang Zhang",
            "Houqiang Li",
            "Huchuan Lu",
            "Isabela Drummond",
            "Jack",
            "Valmadre",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Y. Lee",
            "Jana Noskova",
            "Jianke Zhu",
            "Jin Gao",
            "Jingyu Liu",
            "Ji-Wan Kim",
            "Jo{\\~a}o F. Henriques",
            "Junfei Zhuang",
            "Junliang Xing",
            "Junyu Gao",
            "Kai Chen",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Kris Kitani",
            "Lei",
            "Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh Poostchi",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Ming-Hsuan Yang",
            "Nianhao Xie",
            "Ning",
            "Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "M PallaviVenugopal",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Qifeng Yu",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "R. Bowden",
            "Ri-sheng",
            "Liu",
            "Ruxandra Tapu",
            "Simon Hadfield",
            "Siwei Lyu",
            "Stuart Golodetz",
            "Sunglok Choi",
            "Tianzhu",
            "Titus B. Zaharia",
            "Vincenzo Santopietro",
            "Wei Zou",
            "Weiming Hu",
            "Wenbing Tao",
            "Wenbo",
            "Li",
            "Wen-gang Zhou",
            "Xianguo Yu",
            "Xiao Bian",
            "Yang Li",
            "Yifan Xing",
            "Yingruo Fan",
            "Zheng",
            "Zhu",
            "Zhipeng Zhang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-object-tracking-challenges-revisited%3A-VOT-Bei-Zhen/4b90dfbd6983cf9d47d1053efe630c515f9833b5",
        "ID": "4b90dfbd6983cf9d47d1053efe630c515f9833b5",
        "Title": "Visual object tracking challenges revisited: VOT vs. OTB",
        "Abstract": "Numerous benchmark datasets and evaluation toolkits have been designed to facilitate visual object tracking evaluation. However, it is not clear which evaluation protocols are preferred for different tracking objectives. Even worse, different evaluation protocols sometimes yield contradictory conclusions, further hampering reliable evaluation. Therefore, we 1) introduce the new concept of mirror tracking to measure the robustness of a tracker and identify its over-fitting scenarios; 2) measure\u2026\u00a0",
        "Publication Year": "27 September 2018",
        "Citation Count": "5",
        "Reference Count": "31",
        "Authors": [
            "Sun Bei",
            "Zuo Zhen",
            "Luo Wusheng",
            "Du Liebo",
            "Lu Qin"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "350d507f5d899e4d7293b1aa951aa0f81b9fd30a",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "bf97833a354d7faa3793599ac5c1ec1eb3eb7e07",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "ce8c76bfedc5d86faabf0d49dc42a4924f75876d",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-VOT2013-challenge%3A-overview-and-additional-Kristan-Pflugfelder/4dff84213493bb177dc6bff266a9893538a1f879",
        "ID": "4dff84213493bb177dc6bff266a9893538a1f879",
        "Title": "The VOT2013 challenge: overview and additional results",
        "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) challenge and workshop\u2026\u00a0",
        "Publication Year": "2014",
        "Citation Count": "22",
        "Reference Count": "47",
        "Authors": [
            "Matej Kristan",
            "Roman P. Pflugfelder",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Fatih Murat Porikli",
            "Luka Cehovin",
            "Georg Nebehay",
            "Gustavo Javier Fernandez",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "6169efdeca33714833b120152ae591b8a5f159fa",
            "2822a883d149956934a20614d6934c6ddaac6857",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "82635fb63640ae95f90ee9bdc07832eb461ca881",
            "edf6607f0c819390a13e60b722cc40f97359c9c4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Tracking%3A-An-Experimental-Survey-Smeulders-Chu/eda3368a5198ca55768b07b6f5667aea28baf2cd",
        "ID": "eda3368a5198ca55768b07b6f5667aea28baf2cd",
        "Title": "Visual Tracking: An Experimental Survey",
        "Abstract": "There is a large variety of trackers, which have been proposed in the literature during the last two decades with some mixed success. Object tracking in realistic scenarios is a difficult problem, therefore, it remains a most active area of research in computer vision. A good tracker should perform well in a large number of videos involving illumination changes, occlusion, clutter, camera motion, low contrast, specularities, and at least six more aspects. However, the performance of proposed\u2026\u00a0",
        "Publication Year": "1 July 2014",
        "Citation Count": "1,443",
        "Reference Count": "120",
        "Authors": [
            "Arnold W. M. Smeulders",
            "Dung Manh Chu",
            "Rita Cucchiara",
            "Simone Calderara",
            "Afshin Dehghan",
            "Mubarak Shah"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2258e01865367018ed6f4262c880df85b94959f8",
            "b762ecb0624005831f2f3d8eb626d53e8eca4b6c",
            "a52a6cf39054e6f406f67b57cc895e9df1163fc8",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "45e098084c676eee87a71806b7eb7ec03f0410c9",
            "68cc57640bfd04f697048534f82d16bf10a002ec",
            "8f1a4c9be59b43175c86954829690084ac1e8a1a",
            "da199480427da6b4c3800b11a91ef7f9bbbc90ee",
            "21d467174bdcf882eefcae2f10c23a1af5b3e73d",
            "070375a20acf9252f903164586c75110472cd84f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Online-Object-Tracking-with-Proposal-Selection-Hua-Karteek/f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
        "ID": "f3c842c88b14cfcc631e5c2cab5f376b9efa09e3",
        "Title": "Online Object Tracking with Proposal Selection",
        "Abstract": "Tracking-by-detection approaches are some of the most successful object trackers in recent years. Their success is largely determined by the detector model they learn initially and then update over time. However, under challenging conditions where an object can undergo transformations, e.g., severe rotation, these methods are found to be lacking. In this paper, we address this problem by formulating it as a proposal selection task and making two contributions. The first one is introducing novel\u2026\u00a0",
        "Publication Year": "30 September 2015",
        "Citation Count": "104",
        "Reference Count": "52",
        "Authors": [
            "Yang Hua",
            "Alahari Karteek",
            "Cordelia Schmid"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "d806cde30daef5ca1255c6a36c34c2931fd63604",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "b6d31905b671e6d442311c0e275772652df3abb6",
            "fe2aaad872a2cf08c09dd52ca972f323666306db",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "1183db5f409e8498d1a0f542703f908275a6dc34",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "894767a3911ce9295844579380b4a727f7a2a0bf"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Finding-the-Best-from-the-Second-Bests-Inhibiting-Pang-Ling/882c5e862f2256e10bb7dd74d5bbc984b01489fe",
        "ID": "882c5e862f2256e10bb7dd74d5bbc984b01489fe",
        "Title": "Finding the Best from the Second Bests - Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms",
        "Abstract": "Evaluating visual tracking algorithms, or trackers for short, is of great importance in computer vision. However, it is hard to fairly compare trackers due to many parameters need to be tuned in the experimental configurations. On the other hand, when introducing a new tracker, a recent trend is to validate it by comparing it with several existing ones. Such an evaluation may have subjective biases towards the new tracker which typically performs the best. This is mainly due to the difficulty\u2026\u00a0",
        "Publication Year": "1 December 2013",
        "Citation Count": "84",
        "Reference Count": "81",
        "Authors": [
            "Yu Pang",
            "Haibin Ling"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "bf5e48bcaddc8d8bfb2c5b138efdb90e94f8258f",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0",
            "eaf10795a2a34ba6638fd79815d4b81e20eb5955",
            "e13fc55a4dfbf933665e4555dafba558a17f9fa7",
            "a1edc13e5c2517b57d432f4a6c6b693152e8c4bb",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "f342285b29a207f6918f49b12fd49aa7d9eb0d38",
            "7023060f0672f4686074f8739a73db683d05f676",
            "20402c2004cfb2e9caa433d9ca2fb61ff30b302e",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Tracking-through-Failure-Cases-Lebeda-Hadfield/9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "ID": "9926020dda21874dc7a5ef1511bae6c4cef5ecb9",
        "Title": "Long-Term Tracking through Failure Cases",
        "Abstract": "Long term tracking of an object, given only a single instance in an initial frame, remains an open problem. We propose a visual tracking algorithm, robust to many of the difficulties which often occur in real-world scenes. Correspondences of edge-based features are used, to overcome the reliance on the texture of the tracked object and improve invariance to lighting. Furthermore we address long-term stability, enabling the tracker to recover from drift and to provide redetection following\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "54",
        "Reference Count": "17",
        "Authors": [
            "Karel Lebeda",
            "Simon Hadfield",
            "Jiri Matas",
            "R. Bowden"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "00058304b7c51b9dcf837d4125cab0a4b0588aef",
            "5b9ace65f7368f6dc6907c8f6f7c3b0c248d9bc4",
            "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca",
            "4411f262853bf7f1eb8e2efe03eb0402f5e9ad2c",
            "fcba52c59e8537e48e747207837cefd04786bd3d",
            "948a74b25508ab674be06f6a94ca8bc07a082361",
            "dfa5a0cce66f9e840dd98ac8094434efcc4a9de5",
            "779220bb5190b976e025dc649b2e9a0e4b3597b9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Distractor-Aware-Fast-Tracking-via-Dynamic-and-MOT-Zhang-Zhong/16cf8225d1b86c54a18b917a9475bfbd68b46306",
        "ID": "16cf8225d1b86c54a18b917a9475bfbd68b46306",
        "Title": "Distractor-Aware Fast Tracking via Dynamic Convolutions and MOT Philosophy",
        "Abstract": "A practical long-term tracker typically contains three key properties, i.e. an efficient model design, an effective global re-detection strategy and a robust distractor awareness mechanism. However, most state-of-the-art long-term trackers (e.g., Pseudo and re-detecting based ones) do not take all three key properties into account and therefore may either be time-consuming or drift to distractors. To address the issues, we propose a two-task tracking framework (named DMTrack), which utilizes\u2026\u00a0",
        "Publication Year": "25 April 2021",
        "Citation Count": "14",
        "Reference Count": "47",
        "Authors": [
            "Zikai Zhang",
            "Bineng Zhong",
            "Shengping Zhang",
            "Zhenjun Tang",
            "Xin Liu",
            "Zhaoxiang Zhang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "776bc8955e801f6965e85b35d8e2dd6f2f1498ad",
            "ae066f27f2edc1c51847ce4cb21b6e1a3db44fa2",
            "adacccd99a42c3145ec6392a1a6b08878376e38b",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "a62e40be6c2078ace369ce58801b3d5d1dd1a351",
            "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508",
            "09b734072ad4f610478847c9cdc59a4a0c309b37",
            "069ccdbab6ea6ca2d9c3b75c76360ca1e4e9a5e9",
            "060239a69c0a975aaeb603630b40065acf3f8fde",
            "3d372b63020c4d2c9510624f370b50d9f292bcde"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Efficient-and-Practical-Correlation-Filter-Tracking-Zhu-Jiang/638d68827478d39e71eb9b780daab8eaa1c5b06d",
        "ID": "638d68827478d39e71eb9b780daab8eaa1c5b06d",
        "Title": "Efficient and Practical Correlation Filter Tracking",
        "Abstract": "Visual tracking is a basic task in many applications. However, the heavy computation and low speed of many recent trackers limit their applications in some computing power restricted scenarios. On the other hand, the simple update scheme of most correlation filter-based trackers restricts their robustness during target deformation and occlusion. In this paper, we explore the update scheme of correlation filter-based trackers and propose an efficient and adaptive training sample update scheme\u2026\u00a0",
        "Publication Year": "25 January 2021",
        "Citation Count": "3",
        "Reference Count": "47",
        "Authors": [
            "Cheng-Fei Zhu",
            "Shan Jiang",
            "Shuxiao Li",
            "Xiaosong Lan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2bdadde60883c9f5b6ea6091fc3e2a61d27b06c1",
            "6410c97ae03d356e14544c8e95f5367fb7ebb6e6",
            "bcfc93fa80f35fbc0621a6df2ecb1d1119a1ebb9",
            "46fc2e550dd695eaa899a07a01e306a48b73b656",
            "0cae491292feccbc9ad1d864cf8b7144923ce6de",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0",
            "68c8d13f396272424f4bcba93c2ce34d052b6511",
            "e4a990ea93acda817e2d1bc9635ebc33d5cf335c",
            "ece7625a346edbc5f6fab541c0c246ec06939121",
            "01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Channel-Coded-Distribution-Field-Tracking-for-Berg-Ahlberg/7c78f89fb80449c862ed28d6253d791675319f9b",
        "ID": "7c78f89fb80449c862ed28d6253d791675319f9b",
        "Title": "Channel Coded Distribution Field Tracking for Thermal Infrared Imagery",
        "Abstract": "We address short-term, single-object tracking, a topic that is currently seeing fast progress for visual video, for the case of thermal infrared (TIR) imagery. The fast progress has been possible thanks to the development of new template-based tracking methods with online template updates, methods which have not been explored for TIR tracking. Instead, tracking methods used for TIR are often subject to a number of constraints, e.g., warm objects, low spatial resolution, and static camera. As\u2026\u00a0",
        "Publication Year": "1 June 2016",
        "Citation Count": "32",
        "Reference Count": "31",
        "Authors": [
            "Amanda Berg",
            "J{\\&quot;o}rgen Ahlberg",
            "Michael Felsberg"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "a8ccbb0981b104cc0f753514cc28c01e5309dc41",
            "201d116761d9d300193df370107f26d7d475023b",
            "c26eaf62a20ebac360148276a1f098d92c7b0738",
            "20402c2004cfb2e9caa433d9ca2fb61ff30b302e",
            "ffe41ef4b9f2318898947647d3a390d2a6f81d96",
            "d522a63baa5396cf7a7097718598c3b94e7221dc",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "d124edd58fb0602a8df087d004f8e21d6ba43de1"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Object-tracking-in-thermal-imaging-using-kemelized-Stojanovi%C4%87-Vlahovi%C4%87/d30c23f394220f034607972c67e34bfb75eec3b5",
        "ID": "d30c23f394220f034607972c67e34bfb75eec3b5",
        "Title": "Object tracking in thermal imaging using kemelized correlation filters",
        "Abstract": "Object tracking algorithms in thermal imaging are very important in both civil and military applications, especially in the domain of surveillance and monitoring. Compared with visual object tracking, thermal infrared tracking has several advantages, but also possesses certain undesirable properties which makes the tracking task more challenging. With the aim of overcoming them, we apply a state-of-the-art Kernelized Correlation Filters (KCF) based tracking algorithm, which demonstrates high\u2026\u00a0",
        "Publication Year": "1 March 2018",
        "Citation Count": "5",
        "Reference Count": "20",
        "Authors": [
            "Milan S. Stojanovi{\\&#x27;c}",
            "Nata{\\vs}a Vlahovi{\\&#x27;c}",
            "Milo{\\vs} S. Stankovi{\\&#x27;c}",
            "Sr\u0111an Stankovi{\\&#x27;c}"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "7c78f89fb80449c862ed28d6253d791675319f9b",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "6a699d87bb55477cbe7bfb45b7991b889fd976b6",
            "4c954e814ad6e8624fed1e8b2747a631307813f8",
            "f5dbe4550d24d5374d9e10fce44a35b105c7ee07",
            "65c9b4b1d49f46b3f8f64a5f617acfc14f85d031",
            "0cae491292feccbc9ad1d864cf8b7144923ce6de",
            "02b1d5d4d253ef89b3edede7ec36b19b1da723e0",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT-2017-challenge-Kristan-Leonardis/53329e5c79c1128c7b252a12b182c472a3413bfa",
        "ID": "53329e5c79c1128c7b252a12b182c472a3413bfa",
        "Title": "The Visual Object Tracking VOT 2017 challenge results",
        "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \u201creal-time\u201d experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "38",
        "Reference Count": "81",
        "Authors": [
            "Matej Kristan",
            "Ale{\\vs} Leonardis",
            "Jiri Matas",
            "Michael Felsberg",
            "Roman P. Pflugfelder",
            "Luka Cehovin",
            "Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Gustav H{\\&quot;a}ger",
            "Alan Luke{\\vz}i{\\vc}",
            "Abdelrahman Eldesokey",
            "Gustavo Javier Fernandez",
            "Andrej Muhic",
            "Alfredo Petrosino",
            "Alireza Memarmoghadam",
            "Andrea",
            "Vedaldi",
            "Antoine Manzanera",
            "Antoine Tran",
            "A. Aydin Alatan",
            "Bogdan Cosmin Mocanu",
            "Boyu Chen",
            "Chang Huang",
            "Changsheng Xu",
            "Chong Sun",
            "Dalong Du",
            "David Zhang",
            "Dawei Du",
            "Deepak",
            "Mishra",
            "Erhan Gundogdu",
            "Erik Velasco-Salido",
            "Fahad Shahbaz Khan",
            "Francesco Battistone",
            "Gorthi Rama Krishna Sai Subrahmanyam",
            "Goutam Bhat",
            "Guan Huang",
            "Guilherme Sousa Bastos",
            "Guna",
            "Seetharaman",
            "Hongliang Zhang",
            "Houqiang Li",
            "Huchuan Lu",
            "Isabela Drummond",
            "Jack",
            "Valmadre",
            "Jae-chan Jeong",
            "Jae Il Cho",
            "Jae-Y. Lee",
            "Jana Noskova",
            "Jianke Zhu",
            "Jin Gao",
            "Jingyu Liu",
            "Ji-Wan Kim",
            "Jo{\\~a}o F. Henriques",
            "Junfei Zhuang",
            "Junliang Xing",
            "Junyu Gao",
            "Kai Chen",
            "Kannappan Palaniappan",
            "Karel Lebeda",
            "Ke Gao",
            "Kris Kitani",
            "Lei",
            "Zhang",
            "Lijun Wang",
            "Lingxiao Yang",
            "Longyin Wen",
            "Luca Bertinetto",
            "Mahdieh Poostchi",
            "Martin Danelljan",
            "Matthias Mueller",
            "Mengdan Zhang",
            "Ming-Hsuan Yang",
            "Nianhao Xie",
            "Ning",
            "Wang",
            "Ond\u0159ej Mik{\\vs}{\\&#x27;i}k",
            "Payman Moallem",
            "M PallaviVenugopal",
            "Pedro Senna",
            "Philip H. S. Torr",
            "Qiang Wang",
            "Qifeng Yu",
            "Qingming Huang",
            "Rafael Mart{\\&#x27;i}n-Nieto",
            "R. Bowden",
            "Ri-sheng",
            "Liu",
            "Ruxandra Tapu",
            "Simon Hadfield",
            "Siwei Lyu",
            "Stuart Golodetz",
            "Sunglok Choi",
            "Tianzhu",
            "Titus B. Zaharia",
            "Vincenzo Santopietro",
            "Wei Zou",
            "Weiming Hu",
            "Wenbing Tao",
            "Wenbo",
            "Li",
            "Wen-gang Zhou",
            "Xianguo Yu",
            "Xiao Bian",
            "Yang Li",
            "Yifan Xing",
            "Yingruo Fan",
            "Zheng",
            "Zhu",
            "Zhipeng Zhang",
            "Zhiqun He"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "6767812e114c426d45ea83894b156f7906e525cd",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5bae9822d703c585a61575dced83fa2f4dea1c6d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Evaluating-template-rescaling-in-short-term-Ahlberg-Berg/b0304b21630811a8b08c3319a42cf225f8e908c1",
        "ID": "b0304b21630811a8b08c3319a42cf225f8e908c1",
        "Title": "Evaluating template rescaling in short-term single-object tracking",
        "Abstract": "In recent years, short-term single-object tracking has emerged has a popular research topic, as it constitutes the core of more general tracking systems. Many such tracking methods are based on matching a part of the image with a template that is learnt online and represented by, for example, a correlation filter or a distribution field. In order for such a tracker to be able to not only find the position, but also the scale, of the tracked object in the next frame, some kind of scale\u2026\u00a0",
        "Publication Year": "1 August 2015",
        "Citation Count": "3",
        "Reference Count": "9",
        "Authors": [
            "J{\\&quot;o}rgen Ahlberg",
            "Amanda Berg"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "20402c2004cfb2e9caa433d9ca2fb61ff30b302e",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "a8ccbb0981b104cc0f753514cc28c01e5309dc41",
            "17f16b89edaed5d16867287ed8a85e917304b4ba",
            "1c42b5543c315556c8a961b1a4ee8bc027f70b22",
            "55010ae70db0de34b03a89a76f4529ae57b5e4a3"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/CAMEL-Dataset-for-Visual-and-Thermal-Infrared-and-Gebhardt-Wolf/2189f30b56f1c6d7c468eb5f4228f1022f7d5024",
        "ID": "2189f30b56f1c6d7c468eb5f4228f1022f7d5024",
        "Title": "CAMEL Dataset for Visual and Thermal Infrared Multiple Object Detection and Tracking",
        "Abstract": "We present a visual-infrared video sequence dataset for object detection and tracking, called the CAMEL dataset1. The dataset consists of 26 video sequences captured in the visible and thermal infrared domains. The sequences include multiple real world urban environments, as well as multiple targets. The goal is to provide a challenging benchmark similar to MOT challenge that includes sequences that have corresponding visual and infrared pairs. Our hope is that this dataset can be used to help\u2026\u00a0",
        "Publication Year": "1 November 2018",
        "Citation Count": "25",
        "Reference Count": "26",
        "Authors": [
            "Evan Gebhardt",
            "Marilyn Claire Wolf"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "dd45fe910a0200d43aaa77362f658542f6e175ff",
            "2c76de57b8b1c9e63b1883cbdea9ec8e68ddf493",
            "201d116761d9d300193df370107f26d7d475023b",
            "d867d7c8cfefe0f5a297a3c613ae6d79c851f4b9",
            "6ecd14681e7894a2adb590f4ce201e45436053d3",
            "9f394da08dc44501cc19bc9d2183ecba0d01c46d",
            "32ac3830ae51f607845c2c67bb1796acddc4923b",
            "cc4efb1c8d9ff172dfdcda8c5d2962f402603d0e",
            "8f97056221a9e0e8d5f9c7c25d193dac046080ca",
            "b013628703e6d640899b5677ce60b0c3b625db1b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Deep-Features-in-Correlation-Filters-for-Thermal-Stojanovi%C4%87-Vlahovi%C4%87/c4df151b5c99f131e00423e0a50afdb6b4a8d04e",
        "ID": "c4df151b5c99f131e00423e0a50afdb6b4a8d04e",
        "Title": "Deep Features in Correlation Filters for Thermal Image Tracking",
        "Abstract": "Object tracking using thermal infrared cameras has specific properties and challenges which distinguish it from the commonly used visual tracking. Recently, correlation filters (CF) based on deep features have been successfully applied in certain visual tracking scenarios. In this paper, we demonstrate that the success of these methods essentially depends on the way of how the deep features have been obtained. Indeed, the trackers based on CF and deep features use the pre-trained networks\u2026\u00a0",
        "Publication Year": "1 November 2018",
        "Citation Count": "One",
        "Reference Count": "28",
        "Authors": [
            "Milan S. Stojanovi{\\&#x27;c}",
            "Nata{\\vs}a Vlahovi{\\&#x27;c}",
            "Milo{\\vs} S. Stankovi{\\&#x27;c}",
            "Sr\u0111an Stankovi{\\&#x27;c}"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "4c954e814ad6e8624fed1e8b2747a631307813f8",
            "311bc4e48838d8e5ef619df3ce0bc598aba788a1",
            "02b1d5d4d253ef89b3edede7ec36b19b1da723e0",
            "bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0",
            "5c8a6874011640981e4103d120957802fa28f004",
            "f5dbe4550d24d5374d9e10fce44a35b105c7ee07",
            "7c78f89fb80449c862ed28d6253d791675319f9b",
            "d30c23f394220f034607972c67e34bfb75eec3b5",
            "09769e80cdf027db32a1fcb695a1aa0937214763",
            "65c9b4b1d49f46b3f8f64a5f617acfc14f85d031"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Comparison-of-infrared-and-visible-imagery-for-with-Gundogdu-Ozkan/6a699d87bb55477cbe7bfb45b7991b889fd976b6",
        "ID": "6a699d87bb55477cbe7bfb45b7991b889fd976b6",
        "Title": "Comparison of infrared and visible imagery for object tracking: Toward trackers with superior IR performance",
        "Abstract": "The subject of this paper is the visual object tracking in infrared (IR) videos. Our contribution is twofold. First, the performance behaviour of the state-of-the-art trackers is investigated via a comparative study using IR-visible band video conjugates, i.e., video pairs captured observing the same scene simultaneously, to identify the IR specific challenges. Second, we propose a novel ensemble based tracking method that is tuned to IR data. The proposed algorithm sequentially constructs and\u2026\u00a0",
        "Publication Year": "7 June 2015",
        "Citation Count": "37",
        "Reference Count": "25",
        "Authors": [
            "Erhan Gundogdu",
            "Huseyin Ozkan",
            "Huseyin Seckin Demir",
            "Hamza Ergezer",
            "Erdem Akag{\\&quot;u}nd{\\&quot;u}z",
            "S. Kubilay Pakin"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "421bf4eeba623f722bf98340d71e3d229881e92d",
            "460a435a492107e9c8ec23ae8e79b0420de619e9",
            "5616a93e3b8204d340a4d61269d4c4bd8425f0c3",
            "b7cd6c2234ea8f5b7d75acc454e35158ffbd42d3",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "29e1e20323f7cb6c15c6acf5cc6573a2f84e6478"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/People-detection-and-tracking-from-aerial-thermal-Portmann-Lynen/201d116761d9d300193df370107f26d7d475023b",
        "ID": "201d116761d9d300193df370107f26d7d475023b",
        "Title": "People detection and tracking from aerial thermal views",
        "Abstract": "Detection and tracking of people in visible-light images has been subject to extensive research in the past decades with applications ranging from surveillance to search-and-rescue. Following the growing availability of thermal cameras and the distinctive thermal signature of humans, research effort has been focusing on developing people detection and tracking methodologies applicable to this sensing modality. However, a plethora of challenges arise on the transition from visible-light to\u2026\u00a0",
        "Publication Year": "29 September 2014",
        "Citation Count": "159",
        "Reference Count": "17",
        "Authors": [
            "J{\\~A}\u00bcrg Portmann",
            "Simon Lynen",
            "Margarita Chli",
            "Roland Y. Siegwart"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c26eaf62a20ebac360148276a1f098d92c7b0738",
            "1b7a5f9b9b18ad42608261f7fc7c4879087e7b8a",
            "ccbc65d05e753b097a6c6b1ece25624e2ee39d5d",
            "394b9fed48a08ca7f740b5bc26e9386a2f7a73c0",
            "5224b79368dba945a9e90506f23a1cfa91f6f404",
            "34e0ba2daabfa4d3d22913ade8265aff50b5f917",
            "20a056df333294e2fc34bb170d1a20c64202024c",
            "7f9844f16b6c011e561ee2afef9157405c1d7e0d",
            "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "cec734d7097ab6b1e60d95228ffd64248eb89d66"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Online-Object-Tracking%3A-A-Benchmark-Wu-Lim/bfba194dfd9c7c27683082aa8331adc4c5963a0d",
        "ID": "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
        "Title": "Online Object Tracking: A Benchmark",
        "Abstract": "Object tracking is one of the most important components in numerous applications of computer vision. While much progress has been made in recent years with efforts on sharing code and datasets, it is of great importance to develop a library and benchmark to gauge the state of the art. After briefly reviewing recent advances of online object tracking, we carry out large scale experiments with various evaluation criteria to understand how these algorithms perform. The test image sequences are\u2026\u00a0",
        "Publication Year": "23 June 2013",
        "Citation Count": "3,598",
        "Reference Count": "66",
        "Authors": [
            "Yi Wu",
            "Jongwoo Lim",
            "Ming-Hsuan Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2822a883d149956934a20614d6934c6ddaac6857",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "237c54150e151e2c9cbfe427219a2ab5864505c6",
            "2d705458ebae2cb368a6417fe879b2400bf457c9",
            "a65c76169bdb8479353806556f61bf94fdec7e10",
            "d908f10ca52c19cd98edeef4323fb5619cfcdf9a",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "e13fc55a4dfbf933665e4555dafba558a17f9fa7",
            "257cfe2995243b2a5f91a7a423bf2853e1c05420",
            "421bf4eeba623f722bf98340d71e3d229881e92d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Local-Feature-Based-Person-Detection-and-Tracking-Jungling-Arens/c26eaf62a20ebac360148276a1f098d92c7b0738",
        "ID": "c26eaf62a20ebac360148276a1f098d92c7b0738",
        "Title": "Local Feature Based Person Detection and Tracking Beyond the Visible Spectrum",
        "Abstract": "One challenging field in computer vision is the automatic detection and tracking of objects in image sequences. Promising performance of local features and local feature based object detection approaches in the visible spectrum encourage the application of the same principles to data beyond the visible spectrum. Since these dedicated object detectors neither make assumptions on a static background nor a stationary camera, it is reasonable to use these object detectors as a basis for tracking\u2026\u00a0",
        "Publication Year": "2011",
        "Citation Count": "13",
        "Reference Count": "39",
        "Authors": [
            "Kai Jungling",
            "Michael Arens"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "275260b6118b56ee2a3d6bbdf250d0e424b4223c",
            "e87b897964abb2a093d503ad1ffc956b8129d420",
            "ccbc65d05e753b097a6c6b1ece25624e2ee39d5d",
            "49bdd3fb166e0faf7ad1c917aee32c22ebc0f9db",
            "461efc87636ff4e48323ffcb9f8fdf79cf736fb0",
            "b6d31905b671e6d442311c0e275772652df3abb6",
            "c3833f53c947bf89e2c06fd152ca4c7e5a651d6e",
            "d38345663f133ea519213362ac684e83e24d3464",
            "91335d9335e4fd06de48d769d1b79eaded4e431b",
            "192a2a35dae3f63b0cd1ddcb7d21da23c50e7bc4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Enhanced-Distribution-Field-Tracking-Using-Channel-Felsberg/a8ccbb0981b104cc0f753514cc28c01e5309dc41",
        "ID": "a8ccbb0981b104cc0f753514cc28c01e5309dc41",
        "Title": "Enhanced Distribution Field Tracking Using Channel Representations",
        "Abstract": "Visual tracking of objects under varying lighting conditions and changes of the object appearance, such as articulation and change of aspect, is a challenging problem. Due to its robustness and speed, distribution field tracking is among the state-of-the-art approaches for tracking objects with constant size in grayscale sequences. According to the theory of averaged shifted histograms, distribution fields are an approximation of kernel density estimates. Another, more efficient approximation\u2026\u00a0",
        "Publication Year": "2 December 2013",
        "Citation Count": "96",
        "Reference Count": "25",
        "Authors": [
            "Michael Felsberg"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "20402c2004cfb2e9caa433d9ca2fb61ff30b302e",
            "2cfa006b33084abe8160b001f9a24944cda25d05",
            "270d3d614f519f4bcc1b4a28f0d3c5bead86a46b",
            "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "9b2b3e7460f86d252fa5e0bff6b83fc235fbd73e",
            "a9ea6b5ea0335aa92c8cab62f5802b5b3606ea90",
            "eec029c1b57a5b4fc4dab97a84d7e747d1273426",
            "e07bb324fe689cd8e6f61f045c895c9c1e992f6d",
            "389110a28961ebe80d8856cd204f8d8305a260ef"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Particle-Filter-Tracking-of-Camouflaged-Targets-by-Talha-Stolkin/2873de80204743249012f52821419978f4d8b27e",
        "ID": "2873de80204743249012f52821419978f4d8b27e",
        "Title": "Particle Filter Tracking of Camouflaged Targets by Adaptive Fusion of Thermal and Visible Spectra Camera Data",
        "Abstract": "This paper presents a method for tracking a moving target by fusing bi-modal visual information from a deep infra-red thermal imaging camera and a conventional visible spectrum color camera. The tracking method builds on well-known methods for color-based tracking using particle filtering, but it extends these to handle fusion of color and thermal information when evaluating each particle. The key innovation is a method for continuously relearning local background models for each particle in\u2026\u00a0",
        "Publication Year": "1 January 2014",
        "Citation Count": "52",
        "Reference Count": "20",
        "Authors": [
            "Mohammed Talha",
            "R. Stolkin"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "954e7e1d0fb187201276a89fb70f18558f32c91d",
            "4cdc7848bb23f2d43b50950251938bad51090da8",
            "e11dab9ddf9ec9b2a0fa35e4b91656ee2ad63aa0",
            "61ac4095650f35458e627015e42f24555441cc4e",
            "dd4bdfc5d3944e3e9573b887635487d4c5f5330f",
            "af65dc520f7a55349982082ecda4a1b28d4c7513",
            "b990e381353a8a12ca3fc57898506a1ae0af913e",
            "163dcde9f6fe1b7bfbf58a8bd7c06e63ab650cf9",
            "570502599a26bab7281ce7cbc07eb36bf7b12a51",
            "0cff6baa9493a295c1472b63027ddbae3d86a4da"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Visual-Object-Tracking-Benchmark-Moudgil-Gandhi/19d6b9725a59f4b624205829d5f03ac893ca1367",
        "ID": "19d6b9725a59f4b624205829d5f03ac893ca1367",
        "Title": "Long-Term Visual Object Tracking Benchmark",
        "Abstract": "We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term\u2026\u00a0",
        "Publication Year": "4 December 2017",
        "Citation Count": "74",
        "Reference Count": "47",
        "Authors": [
            "A. Moudgil",
            "Vineet Gandhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/TAO%3A-A-Large-Scale-Benchmark-for-Tracking-Any-Dave-Khurana/982cb4421cedce057ae2fc864efac8e43d9c0a5a",
        "ID": "982cb4421cedce057ae2fc864efac8e43d9c0a5a",
        "Title": "TAO: A Large-Scale Benchmark for Tracking Any Object",
        "Abstract": "For many years, multi-object tracking benchmarks have focused on a handful of categories. Motivated primarily by surveillance and self-driving applications, these datasets provide tracks for people, vehicles, and animals, ignoring the vast majority of objects in the world. By contrast, in the related field of object detection, the introduction of large-scale, diverse datasets (e.g., COCO) have fostered significant progress in developing highly robust solutions. To bridge this gap, we introduce\u2026\u00a0",
        "Publication Year": "20 May 2020",
        "Citation Count": "90",
        "Reference Count": "80",
        "Authors": [
            "Achal Dave",
            "Tarasha Khurana",
            "Pavel Tokmakov",
            "Cordelia Schmid",
            "Deva Ramanan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "900ab48d25b44c076e31224b7befa503d9550c53",
            "ac0d88ca5f75a4a80da90365c28fa26f1a26d4c4",
            "ddb80e2c3e1c2ba012ff33bafaef86f02b7275b0",
            "50137d663802224e683951c48970496b38b02141",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "fb3948152788cfaf8a829aab2f02a6ec7de7c7d1",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "0246f6754c38324a837c0ebd1b51976f413f80ad"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/LaSOT%3A-A-High-quality-Large-scale-Single-Object-Fan-Bai/07ff215e87b791e725f3b3666ca061e7b3dab1e7",
        "ID": "07ff215e87b791e725f3b3666ca061e7b3dab1e7",
        "Title": "LaSOT: A High-quality Large-scale Single Object Tracking Benchmark",
        "Abstract": "Despite great recent advances in visual tracking, its further development, including both algorithm design and evaluation, is limited due to lack of dedicated large-scale benchmarks. To address this problem, we present LaSOT, a high-quality Large-scale Single Object Tracking benchmark. LaSOT contains a diverse selection of 85 object classes, and offers 1550 totaling more than 3.87 million frames. Each video frame is carefully and manually annotated with a bounding box. This makes LaSOT, to our\u2026\u00a0",
        "Publication Year": "29 September 2020",
        "Citation Count": "2",
        "Reference Count": "97",
        "Authors": [
            "Heng Fan",
            "Hexin Bai",
            "Liting Lin",
            "Fan Yang",
            "Peng Chu",
            "Ge Deng",
            "Sijia Yu",
            "Harshit",
            "Mingzhen Huang",
            "Juehuan Liu",
            "Yong Xu",
            "Chunyuan Liao",
            "Lin Yuan",
            "Haibin Ling"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "900ab48d25b44c076e31224b7befa503d9550c53",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "982cb4421cedce057ae2fc864efac8e43d9c0a5a",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "ac0d88ca5f75a4a80da90365c28fa26f1a26d4c4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/LaSOT%3A-A-High-quality-Large-scale-Single-Object-Fan-Bai/e284bc13c2b76d0d0c7ad61d976f8a9d3eef8461",
        "ID": "e284bc13c2b76d0d0c7ad61d976f8a9d3eef8461",
        "Title": "LaSOT: A High-quality Large-scale Single Object Tracking Benchmark",
        "Abstract": "Despite great recent advances in visual tracking, its further development, including both algorithm design and evaluation, is limited due to lack of dedicated large-scale benchmarks. To address this problem, we present LaSOT , a high-quality La rge-scale S ingle O bject T racking benchmark. LaSOT contains a diverse selection of 85 object classes, and offers 1550 totaling more than 3.87 million frames. Each video frame is carefully and manually annotated with a bounding box. This makes LaSOT, to\u2026\u00a0",
        "Publication Year": "8 September 2020",
        "Citation Count": "56",
        "Reference Count": "95",
        "Authors": [
            "Heng Fan",
            "Hexin Bai",
            "Liting Lin",
            "Fan Yang",
            "Peng Chu",
            "Ge Deng",
            "Sijia Yu",
            "Harshit",
            "Mingzhen Huang",
            "Juehuan Liu",
            "Yong Xu",
            "Chunyuan Liao",
            "Lin Yuan",
            "Haibin Ling"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "07ff215e87b791e725f3b3666ca061e7b3dab1e7",
            "900ab48d25b44c076e31224b7befa503d9550c53",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "982cb4421cedce057ae2fc864efac8e43d9c0a5a",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "5664e24cacf3f6374c26b5597765099ee9537413",
            "91f2b2aeb7e65d0b673ed7e782488b3365027979",
            "ac0d88ca5f75a4a80da90365c28fa26f1a26d4c4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Performance-Evaluation-Methodology-for-Long-Term-Luke%C5%BEi%C4%8D-Zajc/23f8927f996d56f3b5076d8993a70bcfc70182a1",
        "ID": "23f8927f996d56f3b5076d8993a70bcfc70182a1",
        "Title": "Performance Evaluation Methodology for Long-Term Visual Object Tracking",
        "Abstract": "A long-term visual object tracking performance evaluation methodology and a benchmark are proposed. Performance measures are designed by following a long-term tracking definition to maximize the analysis probing strength. The new measures outperform existing ones in interpretation potential and in better distinguishing between different tracking behaviors. We show that these measures generalize the short-term performance measures, thus linking the two tracking problems. Furthermore, the new\u2026\u00a0",
        "Publication Year": "19 June 2019",
        "Citation Count": "6",
        "Reference Count": "45",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Long-Term-Visual-Object-Tracking-Benchmark-Moudgil-Gandhi/19d6b9725a59f4b624205829d5f03ac893ca1367",
        "ID": "19d6b9725a59f4b624205829d5f03ac893ca1367",
        "Title": "Long-Term Visual Object Tracking Benchmark",
        "Abstract": "We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term\u2026\u00a0",
        "Publication Year": "4 December 2017",
        "Citation Count": "74",
        "Reference Count": "47",
        "Authors": [
            "A. Moudgil",
            "Vineet Gandhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "047ea298464b041a90c4ab4e716356c019d613ab",
            "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Visual-Tracking%3A-An-Experimental-Survey-Smeulders-Chu/eda3368a5198ca55768b07b6f5667aea28baf2cd",
        "ID": "eda3368a5198ca55768b07b6f5667aea28baf2cd",
        "Title": "Visual Tracking: An Experimental Survey",
        "Abstract": "There is a large variety of trackers, which have been proposed in the literature during the last two decades with some mixed success. Object tracking in realistic scenarios is a difficult problem, therefore, it remains a most active area of research in computer vision. A good tracker should perform well in a large number of videos involving illumination changes, occlusion, clutter, camera motion, low contrast, specularities, and at least six more aspects. However, the performance of proposed\u2026\u00a0",
        "Publication Year": "1 July 2014",
        "Citation Count": "1,443",
        "Reference Count": "120",
        "Authors": [
            "Arnold W. M. Smeulders",
            "Dung Manh Chu",
            "Rita Cucchiara",
            "Simone Calderara",
            "Afshin Dehghan",
            "Mubarak Shah"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2258e01865367018ed6f4262c880df85b94959f8",
            "b762ecb0624005831f2f3d8eb626d53e8eca4b6c",
            "a52a6cf39054e6f406f67b57cc895e9df1163fc8",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "45e098084c676eee87a71806b7eb7ec03f0410c9",
            "68cc57640bfd04f697048534f82d16bf10a002ec",
            "8f1a4c9be59b43175c86954829690084ac1e8a1a",
            "da199480427da6b4c3800b11a91ef7f9bbbc90ee",
            "21d467174bdcf882eefcae2f10c23a1af5b3e73d",
            "070375a20acf9252f903164586c75110472cd84f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Tracking-for-Half-an-Hour-Tao-Gavves/d3d36c3caa255053877a7e3250d47d906eec81d2",
        "ID": "d3d36c3caa255053877a7e3250d47d906eec81d2",
        "Title": "Tracking for Half an Hour",
        "Abstract": "Long-term tracking requires extreme stability to the multitude of model updates and robustness to the disappearance and loss of the target as such will inevitably happen. For motivation, we have taken 10 randomly selected OTB-sequences, doubled each by attaching a reversed version and repeated each double sequence 20 times. On most of these repetitive videos, the best current tracker performs worse on each loop. This illustrates the difference between optimization for short-term versus long\u2026\u00a0",
        "Publication Year": "28 November 2017",
        "Citation Count": "17",
        "Reference Count": "31",
        "Authors": [
            "Ran Tao",
            "Efstratios Gavves",
            "Arnold W. M. Smeulders"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "1c721511e4c0e21bd264ca71c0d909528511b7ad",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "4cbe61862bb95fc99293c24d6e02afcb50a05461",
            "001d36f857ae634b98e8c629853df324c21f323f",
            "d20d7d3490fd970992b3631048c75a8c5fe2e4e3",
            "c559e4099a6351837753b0a413f9bafed90f5dcd",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Now-you-see-me%3A-evaluating-performance-in-long-term-Luke%C5%BEi%C4%8D-Zajc/3275944117b43cc44beebe7c82bffc13ec8cb0fa",
        "ID": "3275944117b43cc44beebe7c82bffc13ec8cb0fa",
        "Title": "Now you see me: evaluating performance in long-term visual tracking",
        "Abstract": "We propose a new long-term tracking performance evaluation methodology and present a new challenging dataset of carefully selected sequences with many target disappearances. We perform an extensive evaluation of six long-term and nine short-term state-of-the-art trackers, using new performance measures, suitable for evaluating long-term tracking - tracking precision, recall and F-score. The evaluation shows that a good model update strategy and the capability of image-wide re-detection are\u2026\u00a0",
        "Publication Year": "19 April 2018",
        "Citation Count": "54",
        "Reference Count": "34",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Luka Cehovin Zajc",
            "Tom{\\&#x27;a}s Voj{\\&#x27;i}r",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "19d6b9725a59f4b624205829d5f03ac893ca1367",
            "754504cf01ef3846259783e748b1d3ea52fa2c81",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "bfba194dfd9c7c27683082aa8331adc4c5963a0d",
            "1009859c2c69d6b55e03952f863ac81a4dd85d32",
            "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "d3d36c3caa255053877a7e3250d47d906eec81d2",
            "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "681ee0059ed573265847785d110237861458304e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Discriminative-Single-Shot-Segmentation-Network-Luke%C5%BEi%C4%8D-Matas/b68c8d1474bd0f4134cc86fd7e95039a9e648179",
        "ID": "b68c8d1474bd0f4134cc86fd7e95039a9e648179",
        "Title": "A Discriminative Single-Shot Segmentation Network for Visual Object Tracking",
        "Abstract": "Template-based discriminative trackers are currently the dominant tracking paradigm due to their robustness, but are restricted to bounding box tracking and a limited range of transformation models, which reduces their localization accuracy. We propose a discriminative single-shot segmentation tracker \u2013 D3S<inline-formula><tex-math notation=\"LaTeX\">$_2$</tex-math><alternatives><mml:math><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href=\"lukezic-ieq1-3137933\u2026\u00a0",
        "Publication Year": "22 December 2021",
        "Citation Count": "One",
        "Reference Count": "75",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Jiri Matas",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "cce1fecc800d2782da638f3060d5b2e887739f74",
            "b3249763ac9ecc4df6ef96721c8c7410e0f0468a",
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "4b1965a54a064ac9145b1ce404fe33f0120c8ae3",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0",
            "47a58f8bec1d34004a7d7cf837e27a26de64f0f7"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Robust-Visual-Tracking-by-Segmentation-Paul-Danelljan/9286efaa3dba58837b628f61f4940a09b3eeb85c",
        "ID": "9286efaa3dba58837b628f61f4940a09b3eeb85c",
        "Title": "Robust Visual Tracking by Segmentation",
        "Abstract": ". Estimating the target extent poses a fundamental challenge in visual object tracking. Typically, trackers are box-centric and fully rely on a bounding box to define the target in the scene. In practice, objects often have complex shapes and are not aligned with the image axis. In these cases, bounding boxes do not provide an accurate description of the target and often contain a majority of background pixels. We propose a segmentation-centric tracking pipeline that not only produces a highly\u2026\u00a0",
        "Publication Year": "21 March 2022",
        "Citation Count": "7",
        "Reference Count": "62",
        "Authors": [
            "Matthieu Paul",
            "Martin Danelljan",
            "Christoph Mayer",
            "Luc Van Gool"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "2c1228e79722728fe292f2e8bdc7b7fb9ac9c454",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "af235029ee66a4f83048b7278bf4114974277b4b",
            "1190e0210430e8b743af24cdc43efdeef407b669",
            "6b6d31b022b7984a25fa9ee7fef64086ce7c464d",
            "7f66ff8dd0313fc9c7d67be7ea5aecdda956657c",
            "d1e61fa7824709cae37fb59483dd0772e3101c08",
            "01f46bd91e053ce0c92af126bb87d7381a9fbe29"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/AFOD%3A-Adaptive-Focused-Discriminative-Segmentation-Chen-Xu/4a2d0374dac0b4b43de606a610dde145054f01ba",
        "ID": "4a2d0374dac0b4b43de606a610dde145054f01ba",
        "Title": "AFOD: Adaptive Focused Discriminative Segmentation Tracker",
        "Abstract": "Visual object tracking is a fundamental task in computer vision which could be integrated into numerous real-world applications. Traditional object tracking methods focus on providing the bounding box as object position, while some recent trackers start to consider the combination of segmentation module to generate the binary segmentation mask, pursuing more accurate localization. However, how to effectively integrate different information for accurate and robust tracking is an open question\u2026\u00a0",
        "Publication Year": "23 August 2020",
        "Citation Count": "11",
        "Reference Count": "45",
        "Authors": [
            "Yiwei Chen",
            "Jingtao Xu",
            "Jiaqian Yu",
            "Qiang Wang",
            "ByungIn Yoo",
            "Jae-Joon Han"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "f4f34b56ef957981cebc3d901f49ddd638007d8d",
            "1190e0210430e8b743af24cdc43efdeef407b669",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "48e52aef87084fa17e6ccb20ad9b3a8ec45934f0",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "8b74008565b575f9ab7a0962ca5f6955d64db045",
            "320d05db95ab42ade69294abe46cd1aca6aca602"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Discriminative-Segmentation-Tracking-Using-Dual-Xie-Yang/fce918283b949f1c760176fe0a4691143a36f012",
        "ID": "fce918283b949f1c760176fe0a4691143a36f012",
        "Title": "Discriminative Segmentation Tracking Using Dual Memory Banks",
        "Abstract": "Existing template-based trackers usually localize the target in each frame with bounding box, thereby being limited in learning pixel-wise representation and handling complex and non-rigid transformation of the target. Further, existing segmentation tracking methods are still insufficient in modeling and exploiting dense correspondence of target pixels across frames. To overcome these limitations, this work presents a novel discriminative segmentation tracking architecture equipped with dual\u2026\u00a0",
        "Publication Year": "21 September 2020",
        "Citation Count": "3",
        "Reference Count": "44",
        "Authors": [
            "Fei Xie",
            "Wankou Yang",
            "Bo Liu",
            "Kaihua Zhang",
            "Wanli Xue",
            "Wangmeng Zuo"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "26c50d272883fc8f72656526f915bb283f772b27",
            "1190e0210430e8b743af24cdc43efdeef407b669",
            "842b24b04ef2b142d655c7b50cd6ab0835d89330",
            "cce1fecc800d2782da638f3060d5b2e887739f74",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "ec4fc1eb32050a86da7bc4494ce68ace74b7fc9b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/SiamMask%3A-A-Framework-for-Fast-Online-Object-and-Hu-Wang/72cd6429c016e9ae7681247ee4b3ac64e9ce9654",
        "ID": "72cd6429c016e9ae7681247ee4b3ac64e9ce9654",
        "Title": "SiamMask: A Framework for Fast Online Object Tracking and Segmentation",
        "Abstract": "In this article, we introduce SiamMask, a framework to perform both visual object tracking and video object segmentation, in real-time, with the same simple method. We improve the offline training procedure of popular fully-convolutional Siamese approaches by augmenting their losses with a binary segmentation task. Once the offline training is completed, SiamMask only requires a single bounding box for initialization and can simultaneously carry out visual object tracking and segmentation at\u2026\u00a0",
        "Publication Year": "5 July 2022",
        "Citation Count": "4",
        "Reference Count": "106",
        "Authors": [
            "Weiming Hu",
            "Qiang Wang",
            "Li Zhang",
            "Luca Bertinetto",
            "Philip H. S. Torr"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1",
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "e8e7eb0ef502d5a456b2d573eb290791e7657b76",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "19351b059b2fabafd885322d26a39ed469265654",
            "738165f33c50b059e87b14d8b4a129230e14eacd",
            "4a70c20ad66e5f3bb12fccd84c63ba619053c811",
            "1190e0210430e8b743af24cdc43efdeef407b669"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Discriminative-Tracking-with-Yu-Tang/882ba4364a695cc8d2dec70c681f55861a514331",
        "ID": "882ba4364a695cc8d2dec70c681f55861a514331",
        "Title": "High-Performance Discriminative Tracking with Transformers",
        "Abstract": "End-to-end discriminative trackers improve the state of the art significantly, yet the improvement in robustness and efficiency is restricted by the conventional discriminative model, i.e., least-squares based regression. In this paper, we present DTT, a novel single-object discriminative tracker, based on an encoder-decoder Transformer architecture. By self- and encoder-decoder attention mechanisms, our approach is able to exploit the rich scene information in an end-to-end manner, effectively\u2026\u00a0",
        "Publication Year": "1 October 2021",
        "Citation Count": "31",
        "Reference Count": "42",
        "Authors": [
            "Bin Yu",
            "Ming Tang",
            "Linyu Zheng",
            "Guibo Zhu",
            "Jinqiao Wang",
            "Haoan Feng",
            "Xuetao Feng",
            "Hanqing Lu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2c8315ae713b3e27c6e9f291a158134d9c516166",
            "962dc29fdc3fbdc5930a10aba114050b82fe5a3e",
            "320d05db95ab42ade69294abe46cd1aca6aca602",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "45512d44f1205bc92775f2e880858b3f23c9f5fd",
            "cce1fecc800d2782da638f3060d5b2e887739f74",
            "61704c65aedca9c5e570a2027f1cf90ee0c09ba0",
            "000178cd12c8a6e5da8215b6365fae03c20fd18d",
            "738165f33c50b059e87b14d8b4a129230e14eacd",
            "d74169a8fd2f90a06480d1d583d0ae5e980ea951"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Fast-and-Accurate-Online-Video-Object-Segmentation-Cheng-Tsai/12fae9a2c1ed867997e1ca70eba271b3c741c42f",
        "ID": "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
        "Title": "Fast and Accurate Online Video Object Segmentation via Tracking Parts",
        "Abstract": "Online video object segmentation is a challenging task as it entails to process the image sequence timely and accurately. To segment a target object through the video, numerous CNN-based methods have been developed by heavily finetuning on the object mask in the first frame, which is time-consuming for online applications. In this paper, we propose a fast and accurate video object segmentation algorithm that can immediately start the segmentation process once receiving the images. We first\u2026\u00a0",
        "Publication Year": "1 June 2018",
        "Citation Count": "207",
        "Reference Count": "47",
        "Authors": [
            "Jingchun Cheng",
            "Yi-Hsuan Tsai",
            "Wei-Chih Hung",
            "Shengjin Wang",
            "Ming-Hsuan Yang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "0d4b8f60be18585a1d199c63199f99c43d10b7de",
            "1190e0210430e8b743af24cdc43efdeef407b669",
            "19351b059b2fabafd885322d26a39ed469265654",
            "ccb9ffa26b28dffc4f7d613821d1a9f0d60ea3f4",
            "cb1c0d6be4c22c1f18b0ba20dddd93890f17add6",
            "b2bf41bf5e5e44d746c1cac3edd058d7d346980e",
            "c38dbf0bb5a1615b95dc6d3dbc0733dbcd8cf92e",
            "a213ec900a4e245f31413dc35c2c2e9ae2f09c88",
            "203ea8ab1d9c48977be97e6caf3fdbcc84101354",
            "7a59518a2bf7c24f775e3ce7bf98fceefada3e8f"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/High-Performance-Visual-Tracking-with-Siamese-Li-Yan/320d05db95ab42ade69294abe46cd1aca6aca602",
        "ID": "320d05db95ab42ade69294abe46cd1aca6aca602",
        "Title": "High Performance Visual Tracking with Siamese Region Proposal Network",
        "Abstract": "Visual object tracking has been a fundamental topic in recent years and many deep learning based trackers have achieved state-of-the-art performance on multiple benchmarks. However, most of these trackers can hardly get top performance with real-time speed. In this paper, we propose the Siamese region proposal network (Siamese-RPN) which is end-to-end trained off-line with large-scale image pairs. Specifically, it consists of Siamese subnetwork for feature extraction and region proposal\u2026\u00a0",
        "Publication Year": "1 June 2018",
        "Citation Count": "1,566",
        "Reference Count": "41",
        "Authors": [
            "Bo Li",
            "Junjie Yan",
            "Wei Wu",
            "Zheng Zhu",
            "Xiaolin Hu"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "1131c53b9baaa740a4deef4c1282821b23d18687",
            "7ccbb845829234548bfa9b24c61297b4f0cd678e",
            "5404718135548b01516a668e0c022c5cb22b422e",
            "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
            "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "dda27eb7ddc4510f94cac0e5134b5d56aa77b075",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Siamese-Instance-Search-for-Tracking-Tao-Gavves/c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
        "ID": "c316d5ec14e5768d7eda3d8916bddc1de142a1c2",
        "Title": "Siamese Instance Search for Tracking",
        "Abstract": "In this paper we present a tracker, which is radically different from state-of-the-art trackers: we apply no model updating, no occlusion detection, no combination of trackers, no geometric matching, and still deliver state-of-the-art tracking performance, as demonstrated on the popular online tracking benchmark (OTB) and six very challenging YouTube videos. The presented tracker simply matches the initial patch of the target in the first frame with candidates in a new frame and returns the\u2026\u00a0",
        "Publication Year": "19 May 2016",
        "Citation Count": "933",
        "Reference Count": "58",
        "Authors": [
            "Ran Tao",
            "Efstratios Gavves",
            "Arnold W. M. Smeulders"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b2180fc4f5cb46b5b5394487842399c501381d67",
            "b762ecb0624005831f2f3d8eb626d53e8eca4b6c",
            "c559e4099a6351837753b0a413f9bafed90f5dcd",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd",
            "1b3a107739e7f7e05c50999a3d79b8225746f662",
            "fe2aaad872a2cf08c09dd52ca972f323666306db",
            "61394599ed0aabe04b724c7ca3a778825c7e776f",
            "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "b5e17a0ed14349d6c4066d2408409751f9595e04",
            "c63a34ac6a4e049118070e707ca7679fbb132d33"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/TrackingNet%3A-A-Large-Scale-Dataset-and-Benchmark-in-M%C3%BCller-Bibi/8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
        "ID": "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b",
        "Title": "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild",
        "Abstract": "Despite the numerous developments in object tracking, further improvement of current tracking algorithms is limited by small and mostly saturated datasets. As a matter of fact, data-hungry trackers based on deep-learning currently rely on object detection datasets due to the scarcity of dedicated large-scale tracking datasets. In this work, we present TrackingNet, the first large-scale dataset and benchmark for object tracking in the wild. We provide more than 30K videos with more than 14\u2026\u00a0",
        "Publication Year": "28 March 2018",
        "Citation Count": "440",
        "Reference Count": "47",
        "Authors": [
            "Matthias M{\\&quot;u}ller",
            "Adel Bibi",
            "Silvio Giancola",
            "Salman Al-Subaihi",
            "Bernard Ghanem"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "5bae9822d703c585a61575dced83fa2f4dea1c6d",
            "703505a00579c0aa67712836acc41d94fa6d6edc",
            "4b1a47709d0546e5bc614bf9a521c550e6881d04",
            "29d1b9a6e6ff0a4216d10dd31376467d55e788a3",
            "966aad492f75b17f698e981e008b73b51816c6aa",
            "ac0d88ca5f75a4a80da90365c28fa26f1a26d4c4",
            "b7d540cd0de72e984cdec44afa4a4d039cfd5eea",
            "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "7574b7e5a75fdd338c27af5aeb77ab79460c4437",
            "eda3368a5198ca55768b07b6f5667aea28baf2cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Deformable-Parts-Correlation-Filters-for-Robust-Luke%C5%BEi%C4%8D-Zajc/b3249763ac9ecc4df6ef96721c8c7410e0f0468a",
        "ID": "b3249763ac9ecc4df6ef96721c8c7410e0f0468a",
        "Title": "Deformable Parts Correlation Filters for Robust Visual Tracking",
        "Abstract": "Deformable parts models show a great potential in tracking by principally addressing nonrigid object deformations and self occlusions, but according to recent benchmarks, they often lag behind the holistic approaches. The reason is that potentially large number of degrees of freedom have to be estimated for object localization and simplifications of the constellation topology are often assumed to make the inference tractable. We present a new formulation of the constellation model with\u2026\u00a0",
        "Publication Year": "12 May 2016",
        "Citation Count": "109",
        "Reference Count": "57",
        "Authors": [
            "Alan Luke{\\vz}i{\\vc}",
            "Luka {\\vC}ehovin Zajc",
            "Matej Kristan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "63b293b346b5f1c04b6716dfb00b8b343e2a1972",
            "c559e4099a6351837753b0a413f9bafed90f5dcd",
            "236d4de0b1c73217238f370e7d30243c7ee9707a",
            "a9448de3265ed9ecdc11c79273aee92daa31f79a",
            "93a163e4527741fc2027baeaa586d09af12f3a6c",
            "70c3c9b9a40ca55264e454586dca2a6cf416f6e0",
            "9d57723b4908397654fb1846d37db403d8b2b56a",
            "f6f6617ce6270df934403c18517ecfb10d51f438",
            "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca",
            "1183db5f409e8498d1a0f542703f908275a6dc34"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/VideoMatch%3A-Matching-based-Video-Object-Hu-Huang/8b74008565b575f9ab7a0962ca5f6955d64db045",
        "ID": "8b74008565b575f9ab7a0962ca5f6955d64db045",
        "Title": "VideoMatch: Matching based Video Object Segmentation",
        "Abstract": "Video object segmentation is challenging yet important in a wide variety of applications for video analysis. Recent works formulate video object segmentation as a prediction task using deep nets to achieve appealing state-of-the-art performance. Due to the formulation as a prediction task, most of these methods require fine-tuning during test time, such that the deep nets memorize the appearance of the objects of interest in the given video. However, fine-tuning is time-consuming and\u2026\u00a0",
        "Publication Year": "4 September 2018",
        "Citation Count": "201",
        "Reference Count": "61",
        "Authors": [
            "Yuan-Ting Hu",
            "Jia-Bin Huang",
            "Alexander G. Schwing"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "12fae9a2c1ed867997e1ca70eba271b3c741c42f",
            "4a70c20ad66e5f3bb12fccd84c63ba619053c811",
            "1190e0210430e8b743af24cdc43efdeef407b669",
            "ccb9ffa26b28dffc4f7d613821d1a9f0d60ea3f4",
            "da0d85c2431a60d3ef2aa017e565e9a7b6b1bb1a",
            "cf56a043577e41e5e33a4722352108660f80258f",
            "cb1c0d6be4c22c1f18b0ba20dddd93890f17add6",
            "d710777495f51144c5b9f0a7372d16e3843e1b25",
            "493670df447aab3b305411c6c352c91eb7021ecb",
            "e8e7eb0ef502d5a456b2d573eb290791e7657b76"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Automatic-Breast-Tumor-Classification-Using-a-Level-Pashoutan-Shokouhi/64aa7896b11ab90ccb4828c2faa6f86cc5f647cd",
        "ID": "64aa7896b11ab90ccb4828c2faa6f86cc5f647cd",
        "Title": "Automatic Breast Tumor Classification Using a Level Set Method and Feature Extraction in Mammography",
        "Abstract": "Breast cancer is one of the leading factors of cancer-related deaths among women, therefore designing Computer Aided Diagnosis (CADx) systems to detect malignant and benign tumors of breast masses is extensively essential. Using a segmentation method and subsequently a proper feature extraction is crucial to obtain an appropriate performance in CADx system. In this paper, the Mammography Imaging Analysis Society (MIAS) data is used in order to detect whether breast masses are malignant or\u2026\u00a0",
        "Publication Year": "1 November 2017",
        "Citation Count": "4",
        "Reference Count": "27",
        "Authors": [
            "Soheil Pashoutan",
            "Shahriar Baradaran Shokouhi",
            "Meisam Pashoutan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2415fc06de82ab41ad8b9615162247afb02974af",
            "76389ebb7c1496239e66fd663b0e7e43d391bca9",
            "46c409dd878e643271ef63f1817ded8b57abc01e",
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "40bbb7667b260bad22b0e2cb34562f57735d67f8",
            "474ae46626676d01c7b38328c107b1531b181b46",
            "001ec101a06cf8ce254db94a9c6130b5fe43aabe",
            "2dfb1fd3adfa58a3448251e03b1a5a78239958b3",
            "9bf32a68edfea8b8c072bcd3ee0d696687bab403",
            "33350f776b506e0e8cdee488480d0ce7531282ee"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-hybrid-computer-aided-diagnosis-system-for-in-Kumar-Mohanty/6d5cee9e834907d557ad6eaf1a3edfd610fa77c8",
        "ID": "6d5cee9e834907d557ad6eaf1a3edfd610fa77c8",
        "Title": "A hybrid computer-aided diagnosis system for abnormality detection in mammograms",
        "Abstract": "In recent years, breast cancer is one of the most death causing reasons worldwide whosetreatment involves early detection and diagnosis. A Computer-aided Diagnosis (CAD) system is used for the diagnosis of abnormalities present in the human breast in order to reach a decision. Hence, it is considered to be an effective means of reducing the mortality rate. In the proposed scheme, initially, a contourlet-based feature extraction technique is employed. Further, a filter approach, namely, the two\u2026\u00a0",
        "Publication Year": "1 May 2017",
        "Citation Count": "2",
        "Reference Count": "16",
        "Authors": [
            "Vinod Kumar",
            "Figlu Mohanty",
            "Bodhisattva Dash",
            "Suvendu Rup"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "241b3094b2cc3682df765ed3ed70f8a616358729",
            "2415fc06de82ab41ad8b9615162247afb02974af",
            "119e4bce7a27937fb5c266c8d35b124750494a4f",
            "0003a45ae653fcccb568b90dbb339cf5811a18bf",
            "d05cc617a760f6fd42a97b97ec6f85c78a78daba",
            "9609d19b2b6a8bf06c94ba2c722f87c9bb242c29",
            "06e647bea552a623e406f58746a8faab1e07dde4",
            "f0a4d96b5d7f6668d607512f8744e07dbe1c9b27",
            "e23eb86e5759082d38cca9aaf45709b80f9aeead",
            "5075eb283b5257d78c4d6d40d1b728ae316fe5ef"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Automatic-computer-aided-diagnosis-system-for-mass-Lbachir-Daoudi/f647a77af6ee361456d7c9c876d78780413b2695",
        "ID": "f647a77af6ee361456d7c9c876d78780413b2695",
        "Title": "Automatic computer-aided diagnosis system for mass detection and classification in mammography",
        "Abstract": "Mammography is currently the most powerful technique for early detection of breast cancer. To assist radiologists to better interpret mammogram images, computer-aided detection and diagnosis (CAD) systems have been proposed. This paper proposes a complete CAD system for mass detection and diagnosis, which consists of four steps. The first step consists of the preprocessing where the image is enhanced and the noise removed. In the second step, the abnormalities are segmented using the proposed\u2026\u00a0",
        "Publication Year": "11 November 2020",
        "Citation Count": "25",
        "Reference Count": "44",
        "Authors": [
            "Ilhame Ait Lbachir",
            "Imane Daoudi",
            "Saadia Tallal"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "f7c940ebe313088b7638d97c9913dcec9bdbbde9",
            "7b17689f9e3e63e47fe19be3b9a43acac264369c",
            "c9b310d670c105f82fff94f4ae14532714f85934",
            "831a1e8106571d82f22cd8dac7725964852b0154",
            "a179d495a865e84251b1d3e79ed79c31b26bbf7f",
            "662d927da3c17bfde61da5dbc24c037dce30ce25",
            "1f3c875590b851b900ae95e1fe197da4baeaf0be",
            "00498583b8166055d650e5fe9565631f3599eebb",
            "3f09e4926b6a437849f1372bbd91a4cf3435c741",
            "69ab94d05d3da8f07b5b023e8a69f0078f1dbd52"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-Efficient-Method-for-Breast-Mass-Segmentation-in-Hmida-Hamrouni/14f52a48954bdc3fd7ab872a05c49d60da1fdb8d",
        "ID": "14f52a48954bdc3fd7ab872a05c49d60da1fdb8d",
        "Title": "An Efficient Method for Breast Mass Segmentation and Classification in Mammographic Images",
        "Abstract": "According to the World Health Organization, breast\ncancer is the main cause of cancer death among women in\nthe world. Until now, there are no effective ways of preventing\nthis disease. Thus, early screening and detection is the most\neffective method for rising treatment success rates and reducing\ndeath rates due to breast cancer. Mammography is still the most\nused as a diagnostic and screening tool for early breast cancer\ndetection. In this work, we propose a method to segment and\nclassify\u2026\u00a0",
        "Publication Year": "2017",
        "Citation Count": "3",
        "Reference Count": "27",
        "Authors": [
            "Marwa Hmida",
            "Kamel Hamrouni",
            "Basel Solaiman",
            "Sana Boussetta"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d05cc617a760f6fd42a97b97ec6f85c78a78daba",
            "a9d0b3485f3091e832f87edb469c350c90cabae1",
            "3c948ca247c6f55ef994400e713412b5f845dd40",
            "1f4a786c26081086a7e947d0ce001e89862e8e2b",
            "27d4dcb58a1918e098b5e6ddec791ef9e31972fc",
            "9b5d0a48b0feb156a1270da54d90d0963a3f0404",
            "8b317d33282d5f9d2b7d60368c0e5431348c21ce",
            "2415fc06de82ab41ad8b9615162247afb02974af",
            "4a18fe753a3d4f6619928220fb23f7bdd3ba4cff",
            "1a6542d838f48a2905307176e0525a4bf694970e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/DELINEATION-AND-CLASSIFICATION-OF-LIVER-CANCER-SET-Das-Panda/20e8be521ad4aa3dac54b5cc6c3acceba4f298f2",
        "ID": "20e8be521ad4aa3dac54b5cc6c3acceba4f298f2",
        "Title": "DELINEATION AND CLASSIFICATION OF LIVER CANCER USING LEVEL SET METHOD IN CT IMAGES",
        "Abstract": "The paper proposes a modified approach of delineation and classification of two different types of liver cancers viz. Hepatocellular Carcinoma (HCC) and Metastatic Carcinoma (MET) from different slices of computed tomography (CT) scans images. A combined framework of reorganization and extraction of region of interest (ROI), texture feature extraction followed by texture classification by different machine learning approaches has been presented. Initially, adaptive thresholding has been applied\u2026\u00a0",
        "Publication Year": "28 December 2017",
        "Citation Count": "2",
        "Reference Count": "30",
        "Authors": [
            "Amita Das",
            "Sauris Panda",
            "Sukanta Kumar Sabut"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2fee907bce3bcddd475b1f062b00ddacf6383a57",
            "eb49502d0393993eec094f99482557c0601b5e61",
            "9c377d22c968ae21d97e2d4576a944084447c39f",
            "5e8187c85bace848e6d9661707b9d87ac786aaee",
            "e4c2ea600fcfc680514d83288f3dfeffb887e077",
            "7c9ac6e84f8873a16ec8e186f0f9f3ec5340c9f2",
            "2415fc06de82ab41ad8b9615162247afb02974af",
            "66cfefa3ea18690c878e56920831ef1a5b99074d",
            "294478ca3f28fcdd18f47b0459a1f45be4b29767",
            "2b9c1d8b3164eb86c609510f2d9130a08beb75a4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-adaptive-region-growing-algorithm-for-breast-in-Cao-Hao/3c948ca247c6f55ef994400e713412b5f845dd40",
        "ID": "3c948ca247c6f55ef994400e713412b5f845dd40",
        "Title": "An adaptive region growing algorithm for breast masses in mammograms",
        "Abstract": "This study attempted to accurately segment the mammographic masses and distinguish malignant from benign tumors. An adaptive region growing algorithm with hybrid assessment function combined with maximum likelihood analysis and maximum gradient analysis was developed in this paper. In order to accommodate different situations of masses, the likelihood and the edge gradients of segmented masses were weighted adaptively by the use of information entropy. 106 benign and 110 malignant tumors were\u2026\u00a0",
        "Publication Year": "13 May 2010",
        "Citation Count": "25",
        "Reference Count": "31",
        "Authors": [
            "Ying Cao",
            "Xin Hao",
            "Xiaoen Zhu",
            "Shun-ren Xia"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3f116f1763a3604275b06c6ccf0dcd65910d13b5",
            "7642ea8a5bd70c3eede1c1c9bf8b666bf4c5c0a3",
            "5e99438461ae96f4a5816e37a9e01f9d9ae6ab4e",
            "c909583f2560864a2650dc25dbcd09da8eb96fbd",
            "e3f3ff00759dca433cf5740b38dd8dce25ee45a0",
            "a23937d6345c6e707cf17509ec27c76fef4ce7cc",
            "34c44883a6152c5298f2c452670c1127072400e6",
            "a277fe4df26e09a6c375e32d77472ae2c9a7632d",
            "931d0f894fd46ada2051e2b451c1b3ee675a397c",
            "0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-effective-breast-mass-diagnosis-system-using-Tahmasbi-Saki/63a83600a73ffbfd6a58e315a247aa4f3da90a9b",
        "ID": "63a83600a73ffbfd6a58e315a247aa4f3da90a9b",
        "Title": "An effective breast mass diagnosis system using Zernike moments",
        "Abstract": "In this paper, a novel CADx system has been proposed for the diagnosis of masses in mammography images. The objective is intensifying the performance of CADx algorithms as well as reducing the false positive rate by utilizing Zernike moments as descriptors of shape and margin characteristics. The input ROI is segmented manually by expert radiologists. Then, it is subjected to some preprocessing stages such as histogram equalization, translation, and NRL scaling. The outcome of preprocessing\u2026\u00a0",
        "Publication Year": "1 November 2010",
        "Citation Count": "16",
        "Reference Count": "13",
        "Authors": [
            "Amir Tahmasbi",
            "Fatemeh Saki",
            "Shahriar Baradaran Shokouhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ea7685f5ee65c4c152478111b5bfcb23a446d358",
            "34c44883a6152c5298f2c452670c1127072400e6",
            "6a6c0294803a5a31944d98588f482f7cc11f922e",
            "72ca0bf7bee745e58a1b0066bc537c4211e7e463",
            "9c6d488192b0535b032542d16a9d16a423c7a775",
            "72464133722c922e2185635c57d4527f3ad7bbbb",
            "3c1a8b740b14e871f69be07112adab67a7193b3a",
            "9d130db46e078e7996c03735412f2ddb777b9c9d",
            "d8a3550ec5c1726a0eb474630a384b9e38aecfa9",
            "7f575e099af94faca1fe9c9f04ab0ee4081c77f0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Mass-diagnosis-in-mammography-images-using-novel-Tahmasbi-Saki/474ae46626676d01c7b38328c107b1531b181b46",
        "ID": "474ae46626676d01c7b38328c107b1531b181b46",
        "Title": "Mass diagnosis in mammography images using novel FTRD features",
        "Abstract": "In this paper, a novel group of features have been introduced for diagnosing the masses in mammography images. The goal is increasing the performance of CADx algorithms as well as decreasing computational complexity. The proposed features are proper descriptors of mass margin which are called Fourier Transform of Radial Distance (FTRD). The input ROI has been segmented manually by expert radiologists and subjected to some preprocessing stages. In order to extract the proposed features, the\u2026\u00a0",
        "Publication Year": "1 November 2010",
        "Citation Count": "15",
        "Reference Count": "15",
        "Authors": [
            "Amir Tahmasbi",
            "Fatemeh Saki",
            "Shahriar Baradaran Shokouhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "802c5bf4c93b795f9f509a3b90efabc501e21c01",
            "f8b061df30fa1eb1ca444cedf2e9be9d091120f2",
            "d98b3a493bdf327f3447e75b4814339e1b436d05",
            "6a6c0294803a5a31944d98588f482f7cc11f922e",
            "34c44883a6152c5298f2c452670c1127072400e6",
            "7ecef79c3d0752d58a0f286bf425ec1eb42bde07",
            "2dfb1fd3adfa58a3448251e03b1a5a78239958b3",
            "227b786b828240506830fea3660b5dc1de6e2a8e",
            "26c9f47d4356f9b793aafc50e0648a92c4f3f7a4",
            "d8a3550ec5c1726a0eb474630a384b9e38aecfa9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Automated-Deep-Learning-Empowered-Breast-Cancer-Escorcia-Gutierrez-Mansour/ddf4b612c1c944dbf47999b9c319c8186df709e0",
        "ID": "ddf4b612c1c944dbf47999b9c319c8186df709e0",
        "Title": "Automated Deep Learning Empowered Breast Cancer Diagnosis Using Biomedical Mammogram Images",
        "Abstract": ": Biomedical image processing is a hot research topic which helps to majorly assist the disease diagnostic process. At the same time, breast cancer becomes the deadliest disease among women and can be detected by the use of different imaging techniques. Digital mammograms can be used for the earlier identification and diagnostic of breast cancer to minimize the death rate. But the proper identification of breast cancer has mainly relied on the mammography findings and results to increased false\u2026\u00a0",
        "Publication Year": "2022",
        "Citation Count": "11",
        "Reference Count": "25",
        "Authors": [
            "Jos{\\&#x27;e} Escorcia-Gutierrez",
            "Romany Fouad Mansour",
            "Kelvin Bele{\\~n}o",
            "Javier Jim{\\&#x27;e}nez-Cabas",
            "Meglys P{\\&#x27;e}rez",
            "Natasha Madera",
            "Kevin Velasquez"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "34afbba50952c137539d525fa21bab026cce7250",
            "b9e840bab3facd93db9bdf9f3872b987fe7b0e11",
            "31cde645eb10b6dac5ab575267878d262429e310",
            "8133e66c9c03095ef605090e6a72b752dc774d92",
            "3f02ff7afca151f2abfe14a863ef0d4b5a8b1393",
            "f36b3ee8d83ec14808a268183e28f05f4b7b3bc3",
            "3cbe19d5e217d1bc27d45dd867a6e185db9970d3",
            "de3c664200e753d01931229fb9a84346575524e9",
            "87466f870df7165622478e5a8834174ecb8093d2",
            "055f5fd928e3c9725c8ff9785fd6f0d3f503cc32"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Computer-aided-mass-segmentation-in-mammogram-using-Ashok-Vijayan/ea703124880e7bc03792602b500a8ed37b56843a",
        "ID": "ea703124880e7bc03792602b500a8ed37b56843a",
        "Title": "Computer aided mass segmentation in mammogram images using Grey wolf Optimized Region growing technique",
        "Abstract": "One of the dangerous threats, that affect women all around the globe is breast cancer, leading to early mortality in women. According to researchers the survival rate of the breast cancer affected person can be improved by a greater amount by its early detection. Hence, there is need for development of an automated system, which can act as an aid for supporting the radiologists in making proper diagnostic decision. The proposed work involves detection of the breast masses by making use of an\u2026\u00a0",
        "Publication Year": "3 June 2021",
        "Citation Count": "One",
        "Reference Count": "26",
        "Authors": [
            "Ashi Ashok",
            "Devi Vijayan",
            "Lavanya R"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "8271f755d7cea799600e25662dd3f2ac8d23aeb1",
            "8133e66c9c03095ef605090e6a72b752dc774d92",
            "4e70af0046174c2b7e8c28dc31b775470c9ea278",
            "19886c0d6b51b773dec8bc596cc5a3efbc9af88a",
            "9f8034a9f7448f59d0ddd4485d6e01dff2b270f9",
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "173fcccefc89584eb68e089aadc0cac34a396efe",
            "84ea54639224471efa2b97d4a709f6e64c64816b",
            "a311571b9d475601eba635209bf78a90992102d2",
            "7ae2477b1a1df98d85497bf967a8f15738167b68"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Robust-Feature-Extraction-Technique-for-Breast-on-Kumari-Jagadesh/19e8f7afcba501eab8bff7c216ee532f0c73ed4f",
        "ID": "19e8f7afcba501eab8bff7c216ee532f0c73ed4f",
        "Title": "A Robust Feature Extraction Technique for Breast Cancer Detection using Digital Mammograms based on Advanced GLCM Approach",
        "Abstract": "INTRODUCTION: Breast cancer is the most hazardous disease among women worldwide. A simple, cost-effective, and efficient screening called mammographic imaging is used to find the breast abnormalities to detect breast cancer in the early stages so that the patient\u2019s health can be improved. OBJECTIVES: The main challenge is to extract the features by using a novel technique called Advanced Gray-Level Co-occurrence Matrix (AGLCM) from pre-processed images and to classify the images using machine\u2026\u00a0",
        "Publication Year": "11 January 2022",
        "Citation Count": "4",
        "Reference Count": "54",
        "Authors": [
            "L. Kanya Kumari",
            "B. N. Jagadesh"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "771eded215d7834d06b32b251aadc43f84a5be42",
            "870d52e025216445bbc51434527f450c7be630fd",
            "ef808555e64b318b1415bf9c87aeaa208a88f954",
            "7c66be06a11210b10afe5dddde51f7c355b98b14",
            "8133e66c9c03095ef605090e6a72b752dc774d92",
            "fb53de4e80dd721cbc891caed0d63084a32b5a90",
            "14a65f82a9d7e25eeae4bdcf20090a5d6ead1f77",
            "3e5294e4ccec9ad1d2e8d3d6520e6db66209328e",
            "70ffedec6058b04159501170bb1c4e30e1769075",
            "a86be89ac1d21b7db5f0e1f71c752061118cc9d0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-enhancement-of-mammogram-images-for-breast-using-Patel-Hadia/f3eb7b753cf2a9569a1d9fdd11618bce28b1ef46",
        "ID": "f3eb7b753cf2a9569a1d9fdd11618bce28b1ef46",
        "Title": "An enhancement of mammogram images for breast cancer classification using artificial neural networks",
        "Abstract": "Breast cancer is the most driving reason for death in women in both developed and developing nations. For the plan of effective classification of a system, the selection of features method must be used to decrease irregularity part in mammogram images. The proposed approach is used to crop the region of interests (ROIs) manually. Based on that number of features are extracted. In this proposed method a novel hybrid optimum feature selection (HOFS) method is used to find out the significant\u2026\u00a0",
        "Publication Year": "1 June 2021",
        "Citation Count": "7",
        "Reference Count": "43",
        "Authors": [
            "Jalpa J. Patel",
            "Sarman K. Hadia"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b7cd3daaf49d0d68579015680d123044683d70ee",
            "b06a69cf5663829d4f4f8168d820b2f7baf88918",
            "dd7282d139c163df0243f7cb508c7be979aa9fda",
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "4a0c851fbffcfdd4d191cff4b38ac42e1d4d6fc9",
            "95bb0ee471480da79e41ae196bb4da02abe52a27",
            "d592e7ed372adffd2d2d8f5c72565d71e911237e",
            "1ca488cbbc84138e12e405661a2db7fcc9f2e4f1",
            "ca30be76395ba443b24d20d7df5d3b5372df55ff",
            "0fc4a247cce443bc2a3d64818d8981ab8586bb32"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Early-detection-of-breast-cancer-using-hybrid-of-Jahangeer-Rajkumar/169f59ac3987301bfdecd77301eeb16ecc0e9358",
        "ID": "169f59ac3987301bfdecd77301eeb16ecc0e9358",
        "Title": "Early detection of breast cancer using hybrid of series network and VGG-16",
        "Abstract": "Breast cancer is nowadays becoming a serious problem and acts as a main reason for death of women around the world. Hence various devices are being utilized for the detection of breast cancer at an earlier stage and diagnosing it in an earlier stage might even results in complete cure of the disease. Among the wide range of devices available, mammogram is one of the commonly employed and most effective approaches involved in the detection of breast cancer. It records the affected area in the\u2026\u00a0",
        "Publication Year": "30 October 2020",
        "Citation Count": "16",
        "Reference Count": "27",
        "Authors": [
            "Gul Shaira Banu Jahangeer",
            "T. Dhiliphan Rajkumar"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ca6a03d054bf28155509dd61b37878d4e4fcc831",
            "8133e66c9c03095ef605090e6a72b752dc774d92",
            "54bfd99db17b0a85699f3d1a7582f526df46aa6c",
            "5c01842e5431bff0a47140c57b3dd5362107afc6",
            "be4c4ef2c0dd7c52112bebc8b98a74947673a255",
            "3089efdb9f20f81a8264f6e703c9f8fb7db13ee4",
            "f325e6c3ab1f2a85311310aa805eb526e37c4fdf",
            "9a2536a4920e4d7c4f70864ead78f3e44a276a13",
            "d47177c238f633b9092d719438e372eb75acbfa7",
            "b757776861a430dafa3d4ad2729f173716c88e23"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Swarm-Optimized-Neural-Network-System-for-of-in-Dheeba-Selvi/4f325d8be07594c94f0d7568c80c91c55bdb3774",
        "ID": "4f325d8be07594c94f0d7568c80c91c55bdb3774",
        "Title": "A Swarm Optimized Neural Network System for Classification of Microcalcification in Mammograms",
        "Abstract": "Early detection of microcalcification clusters in breast tissue will significantly increase the survival rate of the patients. Radiologists use mammography for breast cancer diagnosis at early stage. It is a very challenging and difficult task for radiologists to correctly classify the abnormal regions in the breast tissue, because mammograms are noisy images. To improve the accuracy rate of detection of breast cancer, a novel intelligent computer aided classifier is used, which detects the\u2026\u00a0",
        "Publication Year": "1 October 2012",
        "Citation Count": "44",
        "Reference Count": "29",
        "Authors": [
            "J. Dheeba",
            "S. Tamil Selvi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "f757d4cf2a1a885810bd0c97f9735612750f329c",
            "d59cb63f4a2a3ee76a2d9ebb9d06b8256fcd33d1",
            "ea7685f5ee65c4c152478111b5bfcb23a446d358",
            "6c1d2c89a4415a2c72c3aa2bbb3e887853235e19",
            "88d38b88e4890b80373eed7070a2096648c5cf30",
            "c5ac9c778de5186dc42e6052bb7f0d28e6b279e5",
            "f876d2b733ed1e307c81df3008d10ffa60675f0b",
            "259ec4ea7081b0c7b653a1ff6e8d017697602969",
            "fb9fc3c0ff27537acd3d5d23d1a37260a22fd4f5",
            "09b9d071e9f4eeaf3e31b23b030e58c3a66443cf"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Mammography-Feature-Analysis-and-Mass-Detection-in-Patel-Sinha/7ff70f493df1a7d5dfc0c437e7fce6a5172be933",
        "ID": "7ff70f493df1a7d5dfc0c437e7fce6a5172be933",
        "Title": "Mammography Feature Analysis and Mass Detection in Breast Cancer Images",
        "Abstract": "This paper introduces a novel approach for accomplishing mammographic feature analysis through detection of tumor, in terms of their size and shape with experimental work for early breast tumor detection. The objective is to detect the abnormal tumor/tissue inside breast tissues using three stages: Preprocessing, Segmentation and post processing stage. By using preprocessing noise are remove and than segmentation is applied to detect the mass, after that post processing is applied to find out\u2026\u00a0",
        "Publication Year": "9 January 2014",
        "Citation Count": "19",
        "Reference Count": "21",
        "Authors": [
            "Bhagwati Charan Patel",
            "G. R. Sinha"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "dcdd9d5a65b026ba7e1818c0755a0adf277e0408",
            "ad6ff09093492fdcc358e23782411f46f6338fce",
            "074959b57cc370ce4f479ffd6c39283ee3a1e18d",
            "34c44883a6152c5298f2c452670c1127072400e6",
            "38f4c3d7720d0c985275d79005e2f443ea9994f5",
            "7b02d997d0c4a4b8c757b6a81c92fc1d5b516efb",
            "ab74c37fd6a7081ce65189b5348222b30bea83a5",
            "9bf32a68edfea8b8c072bcd3ee0d696687bab403",
            "0af04198084525232fc92e77d08a499b1b92203e",
            "fead66a309a3de5959b3794b91ff50d87ef8a8c9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Breast-cancer-detection-in-digital-mammograms-Kashyap-Bajpai/37257b305a7a5962306505b60f3384fc0d03f184",
        "ID": "37257b305a7a5962306505b60f3384fc0d03f184",
        "Title": "Breast cancer detection in digital mammograms",
        "Abstract": "This paper discusses an approach for automatic detection of abnormalities in the mammograms. Image processing techniques have been applied to accurately segment the suspicious region-of-interest (ROI) prior to abnormality detection. Unsharp masking has been applied for enhancement of the mammogram. Noise removal has been done by using median filtering. Discrete wavelet transform has been applied on filtered image to get the accurate result prior to segmentation. Suspicious ROI has been\u2026\u00a0",
        "Publication Year": "1 September 2015",
        "Citation Count": "30",
        "Reference Count": "21",
        "Authors": [
            "Kanchan Lata Kashyap",
            "Manish Kumar Bajpai",
            "Pritee Khanna"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c83e00120d7adcda72ac01b95234134c47cba76a",
            "bb117e2e0bfe250a4efb8364f821ce74e1bd4ef4",
            "ac0ca4295b0622e370c19716071614b6d2d723f9",
            "662d927da3c17bfde61da5dbc24c037dce30ce25",
            "66cb958c5fe045d9037724f38c5ca7b4728a13f1",
            "3160282a3eac679aef350949a5722037b3bd461d",
            "0b2f7082fa8c91aae2ddece6d14b436a61969714",
            "995a9f5653e95ff874e39da5d2d0beeb36aaa950",
            "931d0f894fd46ada2051e2b451c1b3ee675a397c",
            "ea6d7923148a65372a539e686ec813d05233d5a8"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Novel-CNN-Inception-V4-Based-Hybrid-Approach-for-Nazir-Khan/bb1beb57009f356e300ed2c83bb2fc4f8198daf3",
        "ID": "bb1beb57009f356e300ed2c83bb2fc4f8198daf3",
        "Title": "A Novel CNN-Inception-V4-Based Hybrid Approach for Classification of Breast Cancer in Mammogram Images",
        "Abstract": "Breast cancer is the most frequent disease in women, with one in every 19 women at risk. Breast cancer is the fifth leading cause of cancer death in women around the world. The most effective and efficient technique of controlling cancer development is early identification. Mammography helps in the early detection of cancer, which saves lives. Many studies conducted various tests to categorize the tumor and obtained positive findings. However, there are certain limits. Mass categorization in\u2026\u00a0",
        "Publication Year": "6 July 2022",
        "Citation Count": "2",
        "Reference Count": "55",
        "Authors": [
            "Muhammad Saquib Nazir",
            "Usman Ghani Khan",
            "Aqsa Mohiyuddin",
            "Mana Saleh Al Reshan",
            "Asadullah Shaikh",
            "Muhammad Rizwan",
            "Monika D{\\&#x27;a}videkov{\\&#x27;a}"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "0bac967d54ecbca93cadeca63edf273e9ee9b6e6",
            "ce93c9b3ce2b3e2c51260a3a0d98b5f0848e8c27",
            "b4efe64814bb38a0f7bcc5ebcec2b978e71b8472",
            "1a88ddff5eec7c40ec7d1205277871664fa7c68c",
            "0677d83fbc116d6a9eb71ab3e73d45350720033d",
            "f174e9f2ac85407353bf1ea9cde1ee7a769b37fe",
            "ebc0a2c2433ff2c89794882c6c2afd005e24ef3d",
            "f3eb7b753cf2a9569a1d9fdd11618bce28b1ef46",
            "75b2813ee47c9c13dd48a634363dedc91640c093",
            "d6edaac8f8fc254e2c66470bb5e6d4c14f4dfad2"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Brain-stroke-computed-tomography-images-analysis-A-Ali-Abdullah/95b1fce2fbe3b8a6fca7ea83825a0bc7945773e7",
        "ID": "95b1fce2fbe3b8a6fca7ea83825a0bc7945773e7",
        "Title": "Brain stroke computed tomography images analysis using image processing: A Review",
        "Abstract": "Stroke is the second-leading cause of death globally; therefore, it needs immediate treatment to prevent the brain from damage. Neuroimaging technique for stroke detection such as computed tomography (CT) has been widely used for emergency setting that can provide precise information on an obvious difference between white and gray matter. CT is the comprehensively utilized medical imaging technology for bone, soft tissue, and blood vessels imaging. A fully automatic segmentation became a\u2026\u00a0",
        "Publication Year": "1 December 2021",
        "Citation Count": "6",
        "Reference Count": "124",
        "Authors": [
            "Nur Hasanah Ali",
            "Abdul Rahim Abdullah",
            "Norhashimah Mohd Saad",
            "Ahmad Sobri Muda",
            "Tole Sutikno",
            "Mohd Hatta Jopri"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "8616eb1beb47070bb27904bece7a59d31f62a464",
            "a386eb5458eaf568e7d9a3a38916e459ac647f28",
            "83d0fbf72692b78945a3619b6a65848122ba85bd",
            "788ed6e8393baa81ee08b23422fac0a3c10b4e84",
            "43087caea64501a1135571f45b390fcca1faaa8e",
            "f72ed07670225e378aab2313aed6eade277c8289",
            "8c11f4787a8370c4f389f9dd15dbc1d719403854",
            "17bbf150b9819c56a8f155430bfbe222d06c43ef",
            "a3533b506166ac678727119c4748ec562a3b7f46",
            "ec8a0c31aa345707fcabe382e5bdef5c91fddf6b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Expert-System-of-Dengue-Disease-Using-Artificial-Hamdani-Arifin/732ab2c6404f8322d0067f39503bdfd7f3577825",
        "ID": "732ab2c6404f8322d0067f39503bdfd7f3577825",
        "Title": "Expert System of Dengue Disease Using Artificial Neural Network Classifier",
        "Abstract": "Abstract \u2013 Expert systems can be applied to the classification of dengue fever. Dengue is a serious disease that can be fatal if not diagnosed and treated properly. Headache, muscle aches, fever, and rash are some of the most prevalent symptoms. Dengue fever is a disease that is endemic in various South Asian and Southeast Asian nations. Dengue fever (DF), dengue hemorrhagic fever (DHF), and dengue shock syndrome are the three types of dengue (DSS). Currently, these diseases may be classified\u2026\u00a0",
        "Publication Year": "27 May 2022",
        "Citation Count": "One",
        "Reference Count": "23",
        "Authors": [
            "Hamdani Hamdani",
            "Zainal Arifin",
            "Anindita Septiarini"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "765f6b71ac944422b27283711cbd10418e2623cf",
            "1fd4280ef4e01b1293724ec39e28605047219a5d",
            "535a5ff4c41a33b19d61dd12d107c442ef2371e5",
            "ac7200123294565ecfc4bd4983b03007de5df0a8",
            "3e1f5d06ef26fce053a19f5c38a13f12610d3a59",
            "25072fb2dd4ee80eda6b857e341bb3adc24c49ce",
            "04e813c862697d6b075f003f64b47d6bd56432ba",
            "cb6e98bd8ed27aa9f31c1734382bc7d69c54f48c",
            "7e9e795b8047f2a58ff3c312d4ae7aba87dafaae",
            "f3eb7b753cf2a9569a1d9fdd11618bce28b1ef46"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Breast-cancer-diagnosis-from-mammographic-images-Shivhare-Saxena/b7cd3daaf49d0d68579015680d123044683d70ee",
        "ID": "b7cd3daaf49d0d68579015680d123044683d70ee",
        "Title": "Breast cancer diagnosis from mammographic images using optimized feature selection and neural network architecture",
        "Abstract": "Breast cancer is one of the deadly diseases in women that have raised the mortality rate of women. An accurate and early detection of breast cancer using mammogram images is still a complex task. Hence, this article proposes a novel breast cancer detection model, which included five major phases: (a) preprocessing, (b) segmentation, (c) feature extraction, (d) feature selection, and (e) classification. The input mammogram image is initially preprocessed using contrast limited adaptive histogram\u2026\u00a0",
        "Publication Year": "9 August 2020",
        "Citation Count": "13",
        "Reference Count": "43",
        "Authors": [
            "Ekta Shivhare",
            "Vineet Saxena"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "b280eb5c361d2a389e616cd83b5a996fa18cc8d9",
            "2935dc8dcd935cc0fad3151fe828e88bbf262110",
            "204c081fd68838e2e87316e92225fe1b7db1717d",
            "7d7f7fd05b23a5868c74117654e5f7dafb784648",
            "9c795d2f9e945354fdf7363900df364e7cbc4aa0",
            "d59cb63f4a2a3ee76a2d9ebb9d06b8256fcd33d1",
            "ddb2d9e20d2f201cb60cdd6358ac5aff92ad87a1",
            "3014d7614c3b5332dd6f40b22cf7c8c539595d93",
            "0a0c64248d25f52a74bf9ffbaa19b2529a363e1c",
            "c47d831e3b6d26bd867693428fde34055f385ce0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Breast-Cancer-Detection-using-Artificial-Neural-Tariq/b06a69cf5663829d4f4f8168d820b2f7baf88918",
        "ID": "b06a69cf5663829d4f4f8168d820b2f7baf88918",
        "Title": "Breast Cancer Detection using Artificial Neural Networks",
        "Abstract": "Breast cancer is very common and is considered as the second dangerous disease all over the world due to its death rate. Affected can survive if the disease diagnoses before the appearance of major physical changes in the body. Now a day, mammographic (X-ray of breast region) images are widely used for premature revealing of breast cancer. Aim of the proposed system is to design a Computer Aided Diagnosis system (CAD) used to distinguish between benign (non-cancerous) and malignant (cancerous\u2026\u00a0",
        "Publication Year": "2018",
        "Citation Count": "19",
        "Reference Count": "35",
        "Authors": [
            "Nadeem Tariq"
        ],
        "Related Topics": [
            "Medicine",
            "Computer Science"
        ],
        "References": [
            "95bb0ee471480da79e41ae196bb4da02abe52a27",
            "831a1e8106571d82f22cd8dac7725964852b0154",
            "083c262c4fede6e477326671086611ae53ec9223",
            "d54cb764ce7e132eef60b5eced8752fe7d19377c",
            "8fd20170a036d6f139a3b031058865b6c02ad65a",
            "2c5db1c44dddf0d8e6ea667f3f7afb13032ea386",
            "32c61f007f1753bcad773b1621c58521afa4822f",
            "5f20fd5be0cccdb7894938047b80f3394d4418c6",
            "58c70621b3d8bf0a525be9dd4a6718b53240c5df",
            "5e85666fd36c7d40a2aa31efc828496e62bec545"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Feature-Selection-Mammogram-based-on-Breast-Cancer-Uyun-Choridah/dd7282d139c163df0243f7cb508c7be979aa9fda",
        "ID": "dd7282d139c163df0243f7cb508c7be979aa9fda",
        "Title": "Feature Selection Mammogram based on Breast Cancer Mining",
        "Abstract": "The very dense breast of mammogram image makes the Radiologists often have difficulties in interpreting the mammography objectively and accurately. One of the key success factors of computer-aided diagnosis (CADx) system is the use of the right features. Therefore, this research emphasizes on the feature selection process by performing the data mining on the results of mammogram image feature extraction. There are two algorithms used to perform the mining, the decision tree and the rule\u2026\u00a0",
        "Publication Year": "1 February 2018",
        "Citation Count": "20",
        "Reference Count": "17",
        "Authors": [
            "Shofwatul Uyun",
            "Lina Choridah"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "a3a96903d95d34e1a2ec927dbc546f47a8297a63",
            "c833d192e61597b410a505cf44fa541a28ef8c33",
            "0d00c339c25448bbe38070466e4ebc19eef448bf",
            "ecb46bebaffce8b922aea05880253c95f9712212",
            "59a4101dfad5cd2cc6a673e52a309ae73a085789",
            "662702103356eb5f3d482b369a6e0bfe6a114d4e",
            "17e7276165300d4abb62d69eab776879418653aa",
            "05f423babe4761cb81745be397505ff299c7d885",
            "65a69968bb8c41aad0113cec4c2d981bddf50bc8",
            "4e1744db987f1beb5a7994623acd4d1432b28cea"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Classification-of-Breast-Tissues-in-Mammogram-Using-Martins-Junior/d592e7ed372adffd2d2d8f5c72565d71e911237e",
        "ID": "d592e7ed372adffd2d2d8f5c72565d71e911237e",
        "Title": "Classification of Breast Tissues in Mammogram Images Using Ripley's K Function and Support Vector Machine",
        "Abstract": "Female breast cancer is a major cause of death in western countries. Several computer techniques have been developed to aid radiologists to improve their performance in the detection and diagnosis of breast abnormalities. In Point Pattern Analysis, there is a statistic known as Ripley's K function that is frequently applied to Spatial Analysis in Ecology, like mapping specimens of plants. This paper proposes a new way in applying Ripley's K function in order to distinguish Mass and Non-Mass\u2026\u00a0",
        "Publication Year": "22 August 2007",
        "Citation Count": "6",
        "Reference Count": "18",
        "Authors": [
            "Leonardo de Oliveira Martins",
            "Geraldo Braz Junior",
            "Erick Corr{\\^e}a da Silva",
            "Arist{\\&#x27;o}fanes Corr{\\^e}a Silva",
            "Anselmo Cardoso de Paiva"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "f8b061df30fa1eb1ca444cedf2e9be9d091120f2",
            "766e0e5e79f0a192a07d89d51c025fc5c01cabf2",
            "c7e6befc438ff66c5bc18cf11926df155b580e85",
            "3a54399b141999271e49c652979f65fcd968daa9",
            "8933474a844f8e3744de1881a81ad4b01787e3d4",
            "30f0379489b0e24fa9f1530195689d16691e25a9",
            "83bd436d5c033ce50a5a2ac21e2296786d5a90d5",
            "4d949e8926a20273a7fc9dbfbce23a672c568d2d",
            "6c8292cd4a77cda88be1dda28c289ea4baedb1f5",
            "fe84db9e87a513b285ab32147cd901782e66616d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Identification-of-masses-in-digital-mammogram-using-Khuzi-Besar/1ca488cbbc84138e12e405661a2db7fcc9f2e4f1",
        "ID": "1ca488cbbc84138e12e405661a2db7fcc9f2e4f1",
        "Title": "Identification of masses in digital mammogram using gray level co-occurrence matrices",
        "Abstract": "Digital mammogram has become the most effective technique for early breast cancer detection modality. Digital mammogram takes an electronic image of the breast and stores it directly in a computer. The aim of this study is to develop an automated system for assisting the analysis of digital mammograms. Computer image processing techniques will be applied to enhance images and this is followed by segmentation of the region of interest (ROI). Subsequently, the textural features will be extracted\u2026\u00a0",
        "Publication Year": "1 July 2009",
        "Citation Count": "126",
        "Reference Count": "22",
        "Authors": [
            "A Mohd. Khuzi",
            "Rosli Besar",
            "W. M. D Wan Zaki",
            "N. Ahmad"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2985668aedc5c0aae15959dfa82bc71c064f418a",
            "a3b092bb1bc628713a8f666b30ffdf0c7ec52064",
            "3b508d62ee3549a6c3e8d44673ab40faff66fff4",
            "bf18528f44ac9731181829d576bc3db8a68d1516",
            "0ce1d2fb8309b8e54d192c74fe666e7e1c68adfe",
            "58fca857378da3a25c4ae10a9ad1a0cc6635d382",
            "d10fa706f2383510f8ecbf69a6c404fc4a5837f8",
            "5d5a2a6292c730b4a375aae3b545e81077bdd09b",
            "34c44883a6152c5298f2c452670c1127072400e6",
            "d7d5a4a3ec2d00e7b975a04640224bf6f69127cc"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-Enhancement-in-Cancer-Classification-Accuracy-a-Rahman-Muniyandi/ca30be76395ba443b24d20d7df5d3b5372df55ff",
        "ID": "ca30be76395ba443b24d20d7df5d3b5372df55ff",
        "Title": "An Enhancement in Cancer Classification Accuracy Using a Two-Step Feature Selection Method Based on Artificial Neural Networks with 15 Neurons",
        "Abstract": "An artificial neural network (ANN) is a tool that can be utilized to recognize cancer effectively. Nowadays, the risk of cancer is increasing dramatically all over the world. Detecting cancer is very difficult due to a lack of data. Proper data are essential for detecting cancer accurately. Cancer classification has been carried out by many researchers, but there is still a need to improve classification accuracy. For this purpose, in this research, a two-step feature selection (FS) technique\u2026\u00a0",
        "Publication Year": "10 February 2020",
        "Citation Count": "21",
        "Reference Count": "66",
        "Authors": [
            "Md Akizur Rahman",
            "Ravie Chandren Muniyandi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "74026767ab0182734dd4839262c49612a2b1f26c",
            "35539ef3df32e268603c13d2936facd4343a7ffd",
            "c4c3564b4c4100b2bbd1a3568407f345c7cfeb9e",
            "c8ec88dffe6bf708e71af63c28625eab65d8f152",
            "51598b2f25a5c660877305401a226d7ab65b477c",
            "a7f5a8fb71f6c939a876dcd2446ea4daeb00408e",
            "4dbb8936e67c03fc047c460053c21e7699302411",
            "1838e87e30b15c996409957f7cd9e600915efa9c",
            "d67b47aa0e7866e3e253544a9b214c040f852ea3",
            "0c6056c05e59a148f7d43710ff8bc6571466596e"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Shape-analysis-for-classification-of-breast-nodules-Nugroho-Yusufiyah/0fc4a247cce443bc2a3d64818d8981ab8586bb32",
        "ID": "0fc4a247cce443bc2a3d64818d8981ab8586bb32",
        "Title": "Shape analysis for classification of breast nodules on digital ultrasound images",
        "Abstract": "One of the imaging modalities for early detection of breast cancer malignancy is ultrasonography (USG).\u00a0 The malignancy can be analysed from the characteristic of nodule shape.\u00a0 This study aims to develop a method for classifying the shape of breast nodule into two classes, namely regular and irregular classes.\u00a0 The input image is pre-processed by using the combination of adaptive median filter and speckle reduction bilateral filtering (SRBF) to reduce speckle noises and to eliminate the image\u2026\u00a0",
        "Publication Year": "1 February 2019",
        "Citation Count": "2",
        "Reference Count": "19",
        "Authors": [
            "Hanung Adi Nugroho",
            "Hesti Khuzaimah Nurul Yusufiyah",
            "Teguh Bharata Adji",
            "Widhia K.Z Oktoeberza"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "7988c3f81a12c7e0efb5ed3977673f65b065b580",
            "5010ea77ccc01fb5046f4010f63a1c0a18a25368",
            "79298dfb343a4524c255ac734194065afddc4291",
            "f36451ac66440e719f2f0a8e1182cddb0e5770b8",
            "d81f6e4061d304633154d623968b5bf9080f620e",
            "46c409dd878e643271ef63f1817ded8b57abc01e",
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "acf3f915138d36369a5c033a6c413dd71c469499",
            "f23164bb0b370bdad835ba069854948f9b7db5f7",
            "b6a3e888a1310bd739601c4e6699f1cbb71ca3cd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Segmentation-of-malignant-tumours-in-mammogram-A-Roy-Singh/32320a5c9a49868b851ef6727cc3d0bd80f9f011",
        "ID": "32320a5c9a49868b851ef6727cc3d0bd80f9f011",
        "Title": "Segmentation of malignant tumours in mammogram images: A hybrid approach using convolutional neural networks and connected component analysis",
        "Abstract": "The segmentation of breast lesions is an important step in the computer\u2010aided analysis of the mammogram. The presence of noise in mammograms makes lesion detection challenging particularly for complex malignant lesions. Pre\u2010processing techniques can deal with the noise issue but distorts the important shape features. This motivates us to propose a novel hybrid approach by combining a convolution neural network (CNN) with connected component analysis (CCA) to segment malignant breast lesions\u2026\u00a0",
        "Publication Year": "24 September 2021",
        "Citation Count": "3",
        "Reference Count": "71",
        "Authors": [
            "Abhijit Roy",
            "Bikesh Kumar Singh",
            "Sumit K. Banchhor",
            "Kesari Verma"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "0e0de80f4ff66cd3aef5ff05fd30406fb85da0ea",
            "a4360f362168a6107e1014b7fc61bed32038fc70",
            "301fee6989cc75f84343836cab5a25691d58dc5c",
            "1220fbc61ec47d5978d42c8b5a48b7a33b3c8374",
            "7b3a3e1bd771b7f1ecf0ad0be49f0aed1a358049",
            "0650a2e55a41e154bb43f75ac2cf68d99fefcdda",
            "21b694ae64f12b5a372e9a48ce0896772037574e",
            "fc2ee21b2c625b2f480dcc6bc54bbc60c9a48d54",
            "f08551744f15848eecd645717c0071cd3839db13",
            "46ad856e44cd3b5314ebb785789a9d1b898c137c"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Identification-of-Breast-Malignancy-by-Watershed-Sadad-Hussain/a0bb41d54673d2e9c514620bbc8967f8d0d867be",
        "ID": "a0bb41d54673d2e9c514620bbc8967f8d0d867be",
        "Title": "Identification of Breast Malignancy by Marker-Controlled Watershed Transformation and Hybrid Feature Set for Healthcare",
        "Abstract": "Breast cancer is a highly prevalent disease in females that may lead to mortality in severe cases. The mortality can be subsided if breast cancer is diagnosed at an early stage. The focus of this study is to detect breast malignancy through computer-aided diagnosis (CADx). In the first phase of this work, Hilbert transform is employed to reconstruct B-mode images from the raw data followed by the marker-controlled watershed transformation to segment the lesion. The methods based only on texture\u2026\u00a0",
        "Publication Year": "11 March 2020",
        "Citation Count": "26",
        "Reference Count": "52",
        "Authors": [
            "Tariq Sadad",
            "Ayyaz Hussain",
            "Asim Munir",
            "Muhammad Habib",
            "Sajid Ali Khan",
            "Shariq Hussain",
            "Shunkun Yang",
            "Mohammed Alawairdhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "e90fe4688d07f58810aea31124035c629a46fae0",
            "9499e0322d1e50dd65a5d8511ce253531685f0b2",
            "301fee6989cc75f84343836cab5a25691d58dc5c",
            "951fbb632fd02fd57fb1d864bbd183ebb93172e0",
            "ae1db27518b5edfe36c65b23f31aef9584bf74e8",
            "d708ce13a35c29139e798d1779bf3629219b754b",
            "19ece439cbee920a7514b26487beb398bacc95e3",
            "1d0eb3fe75f2f343b753212e26351706b1a95c6f",
            "6842744e5309605489d2b5fa4bda0ce53cb72794",
            "28328289926fb23f9b687d2366141ea195691e63"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Detection-of-breast-cancer-using-the-infinite-with-Ittannavar-Havaldar/6931ca52d7504ae72ea3ddc0707e8231529665e9",
        "ID": "6931ca52d7504ae72ea3ddc0707e8231529665e9",
        "Title": "Detection of breast cancer using the infinite feature selection with genetic algorithm and deep neural network",
        "Abstract": "The breast cancer is a major health issue worldwide, so the early detection of abnormalities decreases the mortality rate. For the early detection of breast cancer, a new model is proposed in this research using mammogram images which is an effective technique used for screening and detecting the breast cancer. At first, the images are acquired from the digital database for screening mammography and mammographic image analysis society datasets. Then, the visual quality of the images is improved\u2026\u00a0",
        "Publication Year": "7 August 2021",
        "Citation Count": "One",
        "Reference Count": "41",
        "Authors": [
            "S. S. Ittannavar",
            "R. H. Havaldar"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "34599ec5ffe911a4350f6b89fcb6b11c0f9c2b79",
            "7c66be06a11210b10afe5dddde51f7c355b98b14",
            "68e98184ac29cb50df57b4cce8462debea8722ad",
            "09a81f37797ee12713b5ddec259bf5be1a1cc226",
            "b9e840bab3facd93db9bdf9f3872b987fe7b0e11",
            "635b1caa8371fdb9bc09d610fbe5ff2eefa3383b",
            "301fee6989cc75f84343836cab5a25691d58dc5c",
            "526ca602fb79bf5df20741567114fe55c2a52548",
            "2c5db1c44dddf0d8e6ea667f3f7afb13032ea386",
            "9960c18b3154090644c536905224ae90e521df64"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/TTCNN%3A-A-Breast-Cancer-Detection-and-Classification-Maqsood-Dama%C5%A1evi%C4%8Dius/4ed705bc9b8fdaf6a2cd4e0d6e35e9ef15569de5",
        "ID": "4ed705bc9b8fdaf6a2cd4e0d6e35e9ef15569de5",
        "Title": "TTCNN: A Breast Cancer Detection and Classification towards Computer-Aided Diagnosis Using Digital Mammography in Early Stages",
        "Abstract": "Breast cancer is a major research area in the medical image analysis field; it is a dangerous disease and a major cause of death among women. Early and accurate diagnosis of breast cancer based on digital mammograms can enhance disease detection accuracy. Medical imagery must be detected, segmented, and classified for computer-aided diagnosis (CAD) systems to help the radiologists for accurate diagnosis of breast lesions. Therefore, an accurate breast cancer detection and classification\u2026\u00a0",
        "Publication Year": "23 March 2022",
        "Citation Count": "27",
        "Reference Count": "54",
        "Authors": [
            "Sarmad Maqsood",
            "Robertas Dama{\\vs}evi{\\vc}ius",
            "Rytis Maskeli\u016bnas"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "f36b3ee8d83ec14808a268183e28f05f4b7b3bc3",
            "defb443060f269e0f0eb3630afe42e7928c6ee1d",
            "3f02ff7afca151f2abfe14a863ef0d4b5a8b1393",
            "34a91f535f841db560062e7266ac87069f282615",
            "0f3ca7895bebbad7a0f4b7ddcc3febeeff9811ef",
            "7c8c21129cccf09508de82dd9ea785163f3e7834",
            "f8408e114795d5195679c5dbfc46e8a587bcc2d4",
            "4cfea5ab26c5824d616fa8e2562c0666ecee55aa",
            "3cbe19d5e217d1bc27d45dd867a6e185db9970d3",
            "d075db2a61ed392da3641a1e60364eceaec42d0b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Automatic-Detection-of-Malignant-Masses-in-Digital-Rodr%C3%AD%C2%ADguez-Esparza-Zanella-Calzada/1c91ca81e779df5a5180e722f0fc0acd184a1ffc",
        "ID": "1c91ca81e779df5a5180e722f0fc0acd184a1ffc",
        "Title": "Automatic Detection of Malignant Masses in Digital Mammograms Based on a MCET-HHO Approach",
        "Abstract": "Digital image processing techniques have become an important process within medical images. These techniques allow the improvement of the images in order to facilitate their interpretation for specialists. Within these are the segmentation methods, which help to divide the images by regions based on different approaches, in order to identify details that may be complex to distinguish initially. In this work, it is proposed the implementation of a multilevel threshold segmentation technique\u2026\u00a0",
        "Publication Year": "28 March 2020",
        "Citation Count": "4",
        "Reference Count": "46",
        "Authors": [
            "Erick Rodr{\\&#x27;i}\u00adguez-Esparza",
            "Laura A. Zanella-Calzada",
            "Daniel Zald{\\&#x27;i}var",
            "Carlos Eric Galv{\\&#x27;a}n-Tejada"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "922f40dcad618dccffb2d42bfbcd58febcd0ad91",
            "4bddd3d031bf524202df3f83eb76ef5121f6c9a4",
            "5f0f6207844c6ef3df53dcfa21591d6359fbffe0",
            "5467b8e460ba7a44f3cd92c609899bd4f64c0035",
            "301fee6989cc75f84343836cab5a25691d58dc5c",
            "87062858d1b1d59a563be3ea53cd06685eba79b7",
            "fd7f3234a847f0ce8be891af5b2cd098764356a7",
            "93300ce12a55b616dfd539ffb934ccdb0d061059",
            "d3b354382fe19d37abbfc9db29918e34a5af985d",
            "ba285c33c4e7f5634291f3c795606b8bec197692"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Systematic-Review-of-Computing-Approaches-for-Based-Zebari-Ibrahim/9ee9eeed8fc56f600eb3ff07f6e38dff81957ff8",
        "ID": "9ee9eeed8fc56f600eb3ff07f6e38dff81957ff8",
        "Title": "Systematic Review of Computing Approaches for Breast Cancer Detection Based Computer Aided Diagnosis Using Mammogram Images",
        "Abstract": "ABSTRACT Breast cancer is one of the most prevalent types of cancer that plagues females. Mortality from breast cancer could be reduced by diagnosing and identifying it at an early stage. To detect breast cancer, various imaging modalities can be used, such as mammography. Computer-Aided Detection/Diagnosis (CAD) systems can assist an expert radiologist to diagnose breast cancer at an early stage. This paper introduces the findings of a systematic review that seeks to examine the state-of-the\u2026\u00a0",
        "Publication Year": "2 December 2021",
        "Citation Count": "30",
        "Reference Count": "167",
        "Authors": [
            "Dilovan Asaad Zebari",
            "Dheyaa Ahmed Ibrahim",
            "Diyar Qader Zeebaree",
            "Habibollah Haron",
            "Merdin Shamal Salih",
            "Robertas Dama{\\vs}evi{\\vc}ius",
            "Mazin Abed Mohammed"
        ],
        "Related Topics": [
            "Medicine",
            "Computer Science"
        ],
        "References": [
            "c6b2b7704f937ae5f967c0efc80771bb2a1b4127",
            "5a6f4d1742997c512f35155fbf8dd94331db5496",
            "44eb9aafb0d32bf9c8dfd2a4f0f4a418be779a08",
            "a2e059919db1dae0969c25c0c9de4847b15fd083",
            "8a7409d4b756f4f9bab9c52eba54bca66e3bbbe3",
            "8967ea71b194a28744c15a3be93fa6e32ddac1e9",
            "3ba8e598181ac75984f27e235c928a4d32cb3bd3",
            "b2b6030734286daf3ba7e6d921717fb763c900ed",
            "8621d05c23e1a4d7bc64caf663538c0f502079ab",
            "1c2555d1e13580bd809f058e12ac7dfa8490946a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Efficient-Breast-Cancer-Diagnosis-from-Complex-Deep-Rahman-Bukht/06e3c3353bf177212f3d968b36ca3ac2e13b2cd9",
        "ID": "06e3c3353bf177212f3d968b36ca3ac2e13b2cd9",
        "Title": "Efficient Breast Cancer Diagnosis from Complex Mammographic Images Using Deep Convolutional Neural Network",
        "Abstract": "Medical image analysis places a significant focus on breast cancer, which poses a significant threat to women's health and contributes to many fatalities. An early and precise diagnosis of breast cancer through digital mammograms can significantly improve the accuracy of disease detection. Computer-aided diagnosis (CAD) systems must analyze the medical imagery and perform detection, segmentation, and classification processes to assist radiologists with accurately detecting breast lesions\u2026\u00a0",
        "Publication Year": "2 March 2023",
        "Citation Count": "One",
        "Reference Count": "78",
        "Authors": [
            "Hameedur Rahman",
            "Tanvir Fatima Naik Bukht",
            "Rozilawati Ahmad",
            "Ahmad S. Almadhor",
            "Abdul Rehman Javed"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "9e4c5c8ace304341f30a774b0c71a34987adc2a5",
            "939749fe9a71d4bc80ba7ea062278857bca1f76c",
            "1a4a4e54df80764a9f79e40363d1f10e5a1f2609",
            "3f09e4926b6a437849f1372bbd91a4cf3435c741",
            "34a91f535f841db560062e7266ac87069f282615",
            "f8408e114795d5195679c5dbfc46e8a587bcc2d4",
            "cb8e1a712ab0604e2983351870eca10755a7df63",
            "f36b3ee8d83ec14808a268183e28f05f4b7b3bc3",
            "b14e81042a3d41dfcac1046149fae4bb1f64947d",
            "2a863a1ab6df3ca9a55573befcb89e1ed7b7df74"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Effective-mammogram-classification-based-on-center-Singh-Srivastava/d5abfbdef48c20ed124833024e61e4773e944966",
        "ID": "d5abfbdef48c20ed124833024e61e4773e944966",
        "Title": "Effective mammogram classification based on center symmetric-LBP features in wavelet domain using random forests.",
        "Abstract": "Mammogram classification is a crucial and challenging problem, because it helps in early diagnosis of breast cancer and supports radiologists in their decision to analyze similar mammograms out of a database by recognizing the classes of current mammograms. This paper proposes an effective method for classifying mammograms using random forests with wavelet based center-symmetric local binary pattern (WCS-LBP). To classify mammograms, multi-resolution CS-LBP texture characteristics from non\u2026\u00a0",
        "Publication Year": "9 August 2017",
        "Citation Count": "36",
        "Reference Count": "40",
        "Authors": [
            "Vibhav Prakash Singh",
            "Subodh Srivastava",
            "Rajeev Srivastava"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "c64ce73316d8deecc8245887bc8956e3b4914dd0",
            "241b3094b2cc3682df765ed3ed70f8a616358729",
            "7d4779127448e030f96a7afe4bee65bef460b8c9",
            "9ceb5334ead06800781f04bbe6843f2d78564558",
            "0003a45ae653fcccb568b90dbb339cf5811a18bf",
            "58c70621b3d8bf0a525be9dd4a6718b53240c5df",
            "9b5d0a48b0feb156a1270da54d90d0963a3f0404",
            "95bb0ee471480da79e41ae196bb4da02abe52a27",
            "db3101c7057d71ca42edc17e2c30353ff1b70120",
            "5992c015bf844e958bc78f09b46b39e80c903ac0"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Usefulness-of-Texture-Analysis-for-Computerized-of-Pereira-Marques/d10fa706f2383510f8ecbf69a6c404fc4a5837f8",
        "ID": "d10fa706f2383510f8ecbf69a6c404fc4a5837f8",
        "Title": "Usefulness of Texture Analysis for Computerized Classification of Breast Lesions on Mammograms",
        "Abstract": "This work presents the usefulness of texture features in the classification of breast lesions in 5518 images of regions of interest, which were obtained from the Digital Database for Screening Mammography that included microcalcifications, masses, and normal cases. Sixteen texture features were used, i.e., 13 were based on the spatial gray-level dependence matrix and 3 on the wavelet transform. The nonparametric K-NN classifier was used in the classification stage. The results obtained from\u2026\u00a0",
        "Publication Year": "1 September 2007",
        "Citation Count": "48",
        "Reference Count": "23",
        "Authors": [
            "Roberto Rodrigues Pereira",
            "P. M. A. Marques",
            "Marcelo Ossamu Honda",
            "S{\\&#x27;e}rgio Koodi Kinoshita",
            "Roger M. Engelmann",
            "Chisako Muramatsu",
            "Kunio Doi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "0aed632e3d576b6ab0945ac17a84cb008aae8ce2",
            "4bf55bc218922bf5f01a239f209af57ed9d7f365",
            "42af181c6ab39a6c6b6da82c52eff980f6c25b80",
            "b6cae985af240cc8cb6cb89658f5363064840cbd",
            "f2b80c6c49c43fc7248f5a84934dd4c4b038e4be",
            "0c5abfc65c6d8d74ffd2c6490724197e4322a2b9",
            "8706fa1f5aa5721a6c36c8ec088122e08dda20e7",
            "ea6d7923148a65372a539e686ec813d05233d5a8",
            "fce38045cbe7ea3189d3183f6fef55f64bbf4975",
            "1fdb62555eb650662dbe2a6f3985d390861597c2"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Application-of-texture-analysis-method-for-density-Nithya-Santhi/2537fbb22837de4c9f2b167d7905b2810d84e28f",
        "ID": "2537fbb22837de4c9f2b167d7905b2810d84e28f",
        "Title": "Application of texture analysis method for mammogram density classification",
        "Abstract": "Mammographic density is considered a major risk factor for developing breast cancer. This paper proposes an automated approach to classify breast tissue types in digital mammogram. The main objective of the proposed Computer-Aided Diagnosis (CAD) system is to investigate various feature extraction methods and classifiers to improve the diagnostic accuracy in mammogram density classification. Texture analysis methods are used to extract the features from the mammogram. Texture features are\u2026\u00a0",
        "Publication Year": "6 July 2017",
        "Citation Count": "12",
        "Reference Count": "80",
        "Authors": [
            "R. Nithya",
            "B. Santhi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "916dda5b93bbe83a239feb6cb9188b7e2ca1d734",
            "dda0dc40bc5cb79d5638d8cac955337362e6473e",
            "13950c4bf8d997c955956435075bc7e02755caab",
            "6b9d44eb8dfeb2f00005927fd87fb1af674bf172",
            "662d927da3c17bfde61da5dbc24c037dce30ce25",
            "58d8454eda57d8d296e10609cd9d2e0651d05e0f",
            "2a937dc9c5e24728bfee5e60045ca6d710930aa4",
            "8cdccadbb1362bdec46f28289804286e7ad584a1",
            "26b8feb26bd320ed98d7a5d811acc2b376280c5b",
            "4dda2a93bb3d505234efcc59917f7a9803cdaa6b"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Effect-of-Pixel-Resolution-on-Texture-Features-of-Rangayyan-Nguyen/9c204bc24341157f1dbd72fde781a4906d8f17cd",
        "ID": "9c204bc24341157f1dbd72fde781a4906d8f17cd",
        "Title": "Effect of Pixel Resolution on Texture Features of Breast Masses in Mammograms",
        "Abstract": "The effect of pixel resolution on texture features computed using the gray-level co-occurrence matrix (GLCM) was analyzed in the task of discriminating mammographic breast lesions as benign masses or malignant tumors. Regions in mammograms related to 111 breast masses, including 65 benign masses and 46 malignant tumors, were analyzed at pixel sizes of 50, 100, 200, 400, 600, 800, and 1,000\u00a0\u03bcm. Classification experiments using each texture feature individually provided accuracy, in terms of the\u2026\u00a0",
        "Publication Year": "1 October 2010",
        "Citation Count": "28",
        "Reference Count": "17",
        "Authors": [
            "Rangaraj M. Rangayyan",
            "Thanh Minh Nguyen",
            "F{\\&#x27;a}bio J. Ayres",
            "Asoke Kumar Nandi"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "f8b061df30fa1eb1ca444cedf2e9be9d091120f2",
            "ac0ca4295b0622e370c19716071614b6d2d723f9",
            "58fca857378da3a25c4ae10a9ad1a0cc6635d382",
            "a23937d6345c6e707cf17509ec27c76fef4ce7cc",
            "c0cdec8e8149ab2e7d185893e3f18eb0089a0f2f",
            "4020163982de288022b4e617b3fd9312e3ae0f15",
            "43404e9d55367bc1de3bd8832af9c2ce1157587d",
            "992d63ae94d698ac3a0d11ed1171ac06359fac1d",
            "4b55ab8d2d832744d983ea3d840fa8ebe5217578",
            "16f3cb52eb1f374aa037c4080ccbf68d2d7b8cd1"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Exploring-the-recent-trends-in-Big-Data-Analysis-Suresh-Ramachandran/42097772228e070b44f0af7c520a88e8656b9c53",
        "ID": "42097772228e070b44f0af7c520a88e8656b9c53",
        "Title": "Exploring the recent trends in Big Data Analysis",
        "Abstract": "Big Data is a collection of technologies developed to store, analyze and manage this data. It is a macro tool. Today it is used in fields as diverse as medicine, agriculture, gambling and environmental protection. Machine learning, forecasting Companies use big data to streamline their marketing campaigns and techniques. Modeling and other advanced analytics applications enable big data organizations to generate valuable insights. Companies use it in machine learning. Programs cannot balance\u2026\u00a0",
        "Publication Year": "1 July 2022",
        "Citation Count": "One",
        "Reference Count": "57",
        "Authors": [
            "Supreeth Suresh",
            "M. Ramachandran",
            "Chinnasami Sivaji"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "f7961fcfa4cf0d21c1fed4d827779770c26e2bf2",
            "17ed6e8d8b35cb4422d0f959e4ccb808f7bf5a3a",
            "cdc60c030cf44e920334cfaee947213de31fa294",
            "18b441dce3c40e6bff61e88c345752500f864a7f",
            "5ddbe916e203ed85d99828677133dbc6e29dd678",
            "b0150dd118ebedbc3ece68726e065f9afaaf3b18",
            "a8a40298b05466adf011b6f7f842427e6a1e5d02",
            "2467c80223843583462e8d587fa8fef39fff6074",
            "4413c60a668caade1c4c3bc6749f0f6dbb443673",
            "50a5d84937819cf68594082b577799c32e24c7ed"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Artificial-Intelligence-of-Things-for-Smarter-A-of-Baker-Xiang/8fcc6d8576911d34d4b2454a41685eea5408a93d",
        "ID": "8fcc6d8576911d34d4b2454a41685eea5408a93d",
        "Title": "Artificial Intelligence of Things for Smarter Healthcare: A Survey of Advancements, Challenges, and Opportunities",
        "Abstract": "Healthcare systems are under increasing strain due to a myriad of factors, from a steadily ageing global population to the current COVID-19 pandemic. In a world where we have needed to be connected but apart, the need for enhanced remote and at-home healthcare has become clear. The Internet of Things (IoT) offers a promising solution. The IoT has created a highly connected world, with billions of devices collecting and communicating data from a range of applications, including healthcare. Due\u2026\u00a0",
        "Publication Year": "2023",
        "Citation Count": "2",
        "Reference Count": "270",
        "Authors": [
            "Stephanie B. Baker",
            "Wei Xiang"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "efcc84bc5542453001483bc9c81c7d4c6c409b80",
            "a1bbaf9f1994b6dbfd509abe05358c0051b0afd5",
            "1afa1751e0e4670399f6004ef519d311132ba44d",
            "439bc1325a31a46bb8073993b8ba301f3d9a7818",
            "5bea4972e7b7562a4ed5ad9bd539323f9076c439",
            "32ed6e8770f643251aa93b8e457b22773221a666",
            "04f117ff8881378c1912e2c2102b5c0cfb3d79f7",
            "79b84a85a5efbdd6da8cb4d6d58000b96aa0cbe8",
            "bab96d024441faf4560d6b1c9a25847103f0caad",
            "f1d92f97c01d49ef0ccc422d7a0f6eb4eeb73b20"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Mechanical-and-Thermal-Properties-of-Poly-Butylene/77ab913d02d1f6094d6c70e21abae0837ca0b620",
        "ID": "77ab913d02d1f6094d6c70e21abae0837ca0b620",
        "Title": "Mechanical and Thermal Properties of Poly Butylene Succinct (PBS) Nano Composites",
        "Abstract": "The active substance of Catalyst TiCl4 and the microcrystalline is MgCl2. has been Polybutylene composites, Mechanical properties, Thermal properties, Nan composites, Biodegradability, Morphology; these catalysts contain organic compounds belonging to the class of special modifiers, esters or ethers. Pre-catalysts Organo-aluminum alloys and other types of organic or organ metallics are activated by a combination of converters. Two of the most important technologies of catalysts support the\u2026\u00a0",
        "Publication Year": "1 August 2022",
        "Citation Count": "2",
        "Reference Count": "81",
        "Authors": [
            ""
        ],
        "Related Topics": [
            "REST Journal on Emerging trends in Modelling and Manufacturing"
        ],
        "References": [
            "3eb34fdc3be8169abadcb204295e65cdc7287836",
            "f53c0bccfc079a6127c95e6fac9527ee06b1c418",
            "b442db650f80b653e94d53c1501c785138c73097",
            "3f6af52faa33c897767feb49390a9cecca05cc17",
            "1f03323dab96fa2a3044d70307bf0259eba1421a",
            "ad32c70ae7b8ed4a2620ec3e13f4192ca6f53aaf",
            "c3422be99b943ca35c692a488bcea3c6da3798fd",
            "10a60381c4f6211857110b5527efa595de1d7da8",
            "e630f8cb1a93fe4d9be3df37a33eb676964576d5",
            "0a022b3cd1f3afa3b3ca9845988b22b4c4b8b827"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Evaluation-of-Unreliable-Retrial-G-queue-Using-ARAS-Suresh-Ramachandran/87fea488cb66d2b610d4f10986640b8874febdb6",
        "ID": "87fea488cb66d2b610d4f10986640b8874febdb6",
        "Title": "Evaluation of Unreliable Retrial G-queue Using Fuzzy ARAS Method",
        "Abstract": "A Regular busy server crashes due to negative customer traffic, and holiday interruption is being considered. If the orbit empties at the end of a positive customer service, the server worked Going on vacation. A working vacation (WV) server at a low service rate works. If there are clients on the computer at the end of each holiday, the server the probability that a new visitor is inactive and on vacation is p (single WV) or with probability q (multiple WVs). Substantial variable technique\u2026\u00a0",
        "Publication Year": "1 August 2022",
        "Citation Count": "3",
        "Reference Count": "68",
        "Authors": [
            "Supreeth Suresh",
            "M Ramachandran",
            "Sathiyaraj Chinnasamy"
        ],
        "Related Topics": [
            "Mathematics"
        ],
        "References": [
            "d25ebe81f2b3892810c0b83225ad2a85ba0cfafe",
            "935981b067aabdfdb028cd8b594efb634307d599",
            "c034076fd8493f742b592cf7f62cb6944d9173e9",
            "aca51ad4c71c953a99b49f5d075ae0b9025e1790",
            "a1a0ef4a2bf48e5749cb1c38b0ff94c4a0ed48d0",
            "a287538a75199b7cd304395cb8cc0cbf76b85298",
            "cca96b1c2ae7282540c3b8c1c1b0376979caa9ee",
            "60d681811ba9fa93d6c4fd065ca02eee2ccb4110",
            "6915846d54f00a69fdbe5a40a2cecfa7bbca480f",
            "f8e1a6f58c206652fb738b9c24b89ae17928afcc"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Prediction-of-Hybrid-Wind-Farms-using-Fuzzy-TOPSIS-Sivaji-Ramachandran/b65c471e01f0687557efa52e5398a5384ec9eed8",
        "ID": "b65c471e01f0687557efa52e5398a5384ec9eed8",
        "Title": "Prediction of Hybrid Wind Farms using Fuzzy TOPSIS Analysis",
        "Abstract": "In this paper Hybrid air turbines One way to set up, Battery energy saving With systems (BESS)Is to increase the turbines. In such windmills Caused by the speed of the wind By contrast, the price of BESS Increases and battery Life expectancy decreases. BESS Fitted hybrid Operation of the wind mill to reduce costs Awareness management this paper proposes the technique. In the calculation of wind speed considering the error in Battery charging and Discharge forces are diagnosed. This\u2026\u00a0",
        "Publication Year": "1 August 2022",
        "Citation Count": "2",
        "Reference Count": "65",
        "Authors": [
            "Chinnasami Sivaji",
            "M. Ramachandran",
            "Vidhya Prasanth"
        ],
        "Related Topics": [
            "Engineering"
        ],
        "References": [
            "0e1d5288d62bb7710c8f3fcf6a8b8a3901b79659",
            "800acd30b76403a06048dba071498bed297b2654",
            "791d2d9ae0b49f48b87ce7a74290cc5c8e3c5c3f",
            "91c4eede454c3f3c47337727ea2e42f2d70a74fc",
            "11195e3a675a3f7e65b1dec57855b99226258090",
            "e468af5d3eebee630518c0db0b85bc15352899c1",
            "58783a27251e308db43604e3ed4605ec9c684149",
            "3842dbef6f41629b02b1f3476be853db9cb89e54",
            "9baee506ec9c22b3592232dab203cc6c8eee6a67",
            "5594b7702cbfd6f433e3f99068520479b0d8cec6"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Exploring-Various-Digital-Communication-and-its-Saravanan-Ramachandran/c1bc7d04620c32e8aca79c9c1b6f3b2258adcc1d",
        "ID": "c1bc7d04620c32e8aca79c9c1b6f3b2258adcc1d",
        "Title": "Exploring Various Digital Communication and its Classification",
        "Abstract": "Digital communication is the physical transfer of data through a point-to-point or point-to-point multidisciplinary communication channel. This is to exchange private messages. Digital communication plays an important role in today's world of electronics. The rate of data transfer in digital communication depends on its characteristics Digital communication provides a seamless experience to customers and partners direct communication and AI chat bots and automation Digital in various forms such\u2026\u00a0",
        "Publication Year": "1 July 2022",
        "Citation Count": "3",
        "Reference Count": "61",
        "Authors": [
            "Vimala Saravanan",
            "M. Ramachandran",
            "Sowmiya Soundharaj"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "50380ffa806cc321f4cb06486f491916ef714a49",
            "f3632ac3827a97a55844106a847a6bf60a476b49",
            "0783f34ba9cd8c846310638157c064f6cc61fd01",
            "7b8ba20be190e1159471782ef0122668d584eb03",
            "201c86c1d3149a738a6ba84f4b66ac5be7af3b3e",
            "201094f1ce42dcd7edc3b4168d4cdcb16e731c0e",
            "74f3f74863fbb834cd08bd5f67cf83d8d9c82998",
            "d35629fb163663d558444928e0b3c0b77ff187e9",
            "35c5a2fc4c6272e141195e2fdb08cfa3d520e974",
            "98c482b00da647f979b0e43148cc18300a9897b9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/BREAST-CANCER-DETECTION-USING-MARK-RCNN-AND-WITH-PrasathAliasSurendhar-Vasuki/95cdb70035d13910f2bb7d76ad29d67f619e01d2",
        "ID": "95cdb70035d13910f2bb7d76ad29d67f619e01d2",
        "Title": "BREAST CANCER DETECTION USING MARK RCNN SEGMENTATION AND ENSEMBLE CLASSIFICATION WITH FEATURE EXTRACTION",
        "Abstract": "Breast cancer continues to be the common cancer which causes more decease among women and about more than two million cases is identified every year and according to the record 523,000 deaths are caused per year due to breast cancer. Mammographic mass identification and segmentation are accomplished usually as sequential and distinct tasks, where in previous studies segmentation was often manually performed only on true positive cases. Machine learning (ML) approaches have been grown from\u2026\u00a0",
        "Publication Year": "20 February 2021",
        "Citation Count": "2",
        "Reference Count": "35",
        "Authors": [
            "S PrasathAliasSurendhar",
            "Rajaguru Vasuki"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "f4008deb11f6a2ec3d52dde72be48cd53c898a45",
            "f7a77b58cc75c43041681fa0c5d281c014de901b",
            "fb46d319a14ec8366943ee1c7db0ac309088a8fa",
            "603591b93184eecc483049d2330411f942ab6ff4",
            "e247423b6d191da75f8d6ce88b1698c1b9629f0f",
            "f895de8afa7242c43fe63a7bebfd4e103db87743",
            "542f7bd9c6853d69561e090a8ff82829bf1691f7",
            "8e1a85632e587e1b1fb180e3bdf8aebda0d9f91d",
            "1ceac9bc104329789cb92124ca2cc9a547339482",
            "8188c2bb92012b97bc3241b011c6e331636f8eae"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Automated-detection-of-breast-cancer-lesions-using-Sahar-Nugroho/18aed16d53bfd0570d40d0be0f3b35338d1c9ead",
        "ID": "18aed16d53bfd0570d40d0be0f3b35338d1c9ead",
        "Title": "Automated detection of breast cancer lesions using adaptive thresholding and morphological operation",
        "Abstract": "One of the imaging modalities for early detection of breast cancer is ultrasonography (USG). The detection is based on lesions identification. Radiologists still manually conduct early detection of the lesions. Hence, the detection results tend to be subjective and may cause different interpretations due to the different level of knowledge and experience of the radiologists. In this research, the proposed method for the detection of automatic lesions uses 30 images consisting of 20 images\u2026\u00a0",
        "Publication Year": "1 October 2016",
        "Citation Count": "11",
        "Reference Count": "26",
        "Authors": [
            "Muzni Sahar",
            "Hanung Adi Nugroho",
            "Tianur",
            "Igi Ardiyanto",
            "Lina Choridah"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "ef6eacba51a4edaa9d1b945da217d46dd75285ce",
            "f36451ac66440e719f2f0a8e1182cddb0e5770b8",
            "7988c3f81a12c7e0efb5ed3977673f65b065b580",
            "34659ffec52281c67a48440d048996b44409e18d",
            "af37929e2730c33ddf900173de57317c21971d52",
            "5e4b30620e019f6447037b1a8743598dd1f34576",
            "a302d047ec3c467951c7c6a520b25483b9220871",
            "34552d663ef85ebc89e0f35be45ba4432d43255f",
            "077f289357dd0243cfccafcc6541de2adeed5c58",
            "1203545e3cf6dc0c7e5240bfa95cc573ac10b382"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Transfer-learning-based-deep-CNN-for-segmentation-Wahab-Khan/160befefc99d88390d40910b8cd77a5b4d4e310a",
        "ID": "160befefc99d88390d40910b8cd77a5b4d4e310a",
        "Title": "Transfer learning based deep CNN for segmentation and detection of mitoses in breast cancer histopathological images.",
        "Abstract": "Segmentation and detection of mitotic nuclei is a challenging task. To address this problem, a Transfer Learning based fast and accurate system is proposed. To give the classifier a balanced dataset, this work exploits the concept of Transfer Learning by first using a pre-trained convolutional neural network (CNN) for segmentation, and then another Hybrid-CNN (with Weights Transfer and custom layers) for classification of mitoses. First, mitotic nuclei are automatically annotated, based on the\u2026\u00a0",
        "Publication Year": "1 June 2019",
        "Citation Count": "75",
        "Reference Count": "20",
        "Authors": [
            "Noorul Wahab",
            "Asifullah Khan",
            "Yeon Soo Lee"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "a2a0a65f654ea9422af688b20fd7766564d204ad",
            "c7900a7c6690444eb10b7db1c5b71c6e4316809a",
            "b61f0ad7b185fa23ae37b4cdbfa738d1af01671f",
            "b1544931434229563314ad5e80bbb5de71b3be3f",
            "1e76d194ac9bf96632db26345de3abe3f25a5176",
            "a50a047e202518f28b4012d74e3d94b2eeec1c9d",
            "07be044c675ac69cb5ce7982f337765a9d12fd78",
            "485f0c988c7a4f9bc0e976c65a5055837091fd39",
            "80b0a281c520581e474d178e4020721c61ab5667",
            "bf8090855e544864118b528e8755acf3f44a217a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Breast-cancer-classification-using-machine-learning-Amrane-Oukid/ea98b9481ec6943b799a89f0647becafa303066f",
        "ID": "ea98b9481ec6943b799a89f0647becafa303066f",
        "Title": "Breast cancer classification using machine learning",
        "Abstract": "During their life, among 8% of women are diagnosed with Breast cancer (BC), after lung cancer, BC is the second popular cause of death in both developed and undeveloped worlds. BC is characterized by the mutation of genes, constant pain, changes in the size, color(redness), skin texture of breasts. Classification of breast cancer leads pathologists to find a systematic and objective prognostic, generally the most frequent classification is binary (benign cancer/malign cancer). Today, Machine\u2026\u00a0",
        "Publication Year": "1 April 2018",
        "Citation Count": "163",
        "Reference Count": "23",
        "Authors": [
            "Meriem Amrane",
            "Saliha Oukid",
            "Ikram Gagaoua",
            "Tolga Ensari"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "fe83150bc326fd62d352cb2993ac91344f195e10",
            "3ac4456a6f5f729367b2e0d08e19b1c7fc649e76",
            "c90b4a8328c80cdfffc69fe686e691149e6acc10",
            "e90c52fc4099e2ad448563c1d368c97d78e0f086",
            "ed949b7b030ac8637d9cf7853c2ceca0839213f0",
            "3e2f4656ba2076b49047f6edaa7332f60156e98d",
            "56ccfcfc5e45ad9c010f2937aa4e998d110a63e1",
            "7e7b9f37ce280787075046727efbaf9b5a390729",
            "74b2828dfdf71f2462d88b90a9fc82b90a0f83ca",
            "71a7235b7236232942f96cddffb0b4f633a2e35a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Breast-cancer-diagnosis-using-GA-feature-selection-Alickovic-Subasi/542f7bd9c6853d69561e090a8ff82829bf1691f7",
        "ID": "542f7bd9c6853d69561e090a8ff82829bf1691f7",
        "Title": "Breast cancer diagnosis using GA feature selection and Rotation Forest",
        "Abstract": "Breast cancer is one of the primary causes of death among the women worldwide, and the accurate diagnosis is one of the most significant steps in breast cancer treatment. Data mining techniques can support doctors in diagnosis decision-making process. In this paper, we present different data mining techniques for diagnosis of breast cancer. Two different Wisconsin Breast Cancer datasets have been used to evaluate the system proposed in this study. The proposed system has two stages. In the\u2026\u00a0",
        "Publication Year": "1 April 2017",
        "Citation Count": "219",
        "Reference Count": "65",
        "Authors": [
            "Emina Alickovic",
            "Abdulhamit Subasi"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "0dfb7b7b58920b6a212caa284243bb1b4b8a1d7c",
            "51598b2f25a5c660877305401a226d7ab65b477c",
            "d4eb78de55ea28540b5692810e6fd7747847ae9a",
            "8d010ff9e88e89909ab18c385470418c5df9469a",
            "30fb9443d77c9c823505c80c25bc17b746061126",
            "742aa1ef75fa03e45d7fd341fe316df206050220",
            "8f95825572c4d3a1f2f368da586c6afce27153a1",
            "b2eeff8ee49a39a218a43c44d41afebecc408ec6",
            "e663fa59a758b945ed0e8e620a52022d617a9b03",
            "10ea1a358fecfd1623e230df98f11f967490c47a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Classifier-Based-Breast-Cancer-Segmentation-Kebede-Debelee/2af1310dd611857d8bd1b1374695fc9c8913a4c9",
        "ID": "2af1310dd611857d8bd1b1374695fc9c8913a4c9",
        "Title": "Classifier Based Breast Cancer Segmentation",
        "Abstract": "Breast cancer occurs as a result of erratic growth and proliferation cells that originate in the breast. In this paper, the classifiers were used to identify the abnormalities on mammograms to get the region of interest (ROI). Before classifier based segmentation, noise, pectoral muscles, and tags were removed for a successful segmentation process. Then the proposed approach extracted the brightest regions using modified k-means. From the extracted brightest regions, shape and texture features\u2026\u00a0",
        "Publication Year": "1 November 2020",
        "Citation Count": "10",
        "Reference Count": "34",
        "Authors": [
            "Samuel Rahimeto Kebede",
            "Taye Girma Debelee",
            "Friedhelm Schwenker",
            "Dereje Yohannes"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "156733fbf757d4e8a333537518c8961163c4fbf7",
            "4cf3911b8613a47c82bd58d2597822d5de70606d",
            "fa967eac78f47b283de80399a28f5d7c3ca09f20",
            "0837f79a0efa2180c7bd35a6792c0e3a3e8cd258",
            "c55550ff224ff080d95d93200aea8838267fc21c",
            "3978804d0824c3bf1e17a1d0cd2e9734060fa058",
            "6325f450237d437e2072ef4939da023b08a6f2f1",
            "b046bdd97715dfcd7eeaadb709fe081d4d72d8a3",
            "63b6557f0e49ae79574e6a62715d64264e2f8013",
            "ea5b27748ee154c978534505a177f280d87d52d4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Classification-of-Mammograms-Using-Texture-and-CNN-Debelee-Gebreselasie/4cf3911b8613a47c82bd58d2597822d5de70606d",
        "ID": "4cf3911b8613a47c82bd58d2597822d5de70606d",
        "Title": "Classification of Mammograms Using Texture and CNN Based Extracted Features",
        "Abstract": "In this paper, a modified adaptive K-means (MAKM) method is proposed to extract the region of interest (ROI) from the local and public datasets. The local image datasets are collected from Bethezata General Hospital (BGH) and the public datasets are from Mammographic Image Analysis Society (MIAS). The same image number is used for both datasets, 112 are abnormal and 208 are normal. Two texture features (GLCM and Gabor) from ROIs and one CNN based extracted features are considered in the\u2026\u00a0",
        "Publication Year": "1 July 2019",
        "Citation Count": "23",
        "Reference Count": "36",
        "Authors": [
            "Taye Girma Debelee",
            "Abrham Gebreselasie",
            "Friedhelm Schwenker",
            "Mohammadreza Amirian",
            "Dereje Yohannes"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "156733fbf757d4e8a333537518c8961163c4fbf7",
            "9f0a4c747466c43217c49439ce62d1ad8b30780d",
            "76825f26cadef0c2e80d19a0764dac94ccecff0b",
            "f247c2ef036dc00c72af2d10e767f18e48396d4e",
            "870d52e025216445bbc51434527f450c7be630fd",
            "eb8f6f8c48e6b61ea35e7294f26f7cfbbc3dd833",
            "95eb88e78a6e54fb31fbcbd7f9eda66ddef9e6b8",
            "6d8c60d47e2be4de763bb2f8044e09981016396e",
            "dfff650e5fc09244abf114827e18434d5bddd89e",
            "2f27a7b64c2223ebd922edb0b9644e76ffae0d14"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Computer-Aided-Breast-Cancer-Detection-Using-of-and-Roy-Das/577bfaf8c1797a1ce8c55f1bdb620eaa3b15f9db",
        "ID": "577bfaf8c1797a1ce8c55f1bdb620eaa3b15f9db",
        "Title": "Computer Aided Breast Cancer Detection Using Ensembling of Texture and Statistical Image Features",
        "Abstract": "Breast cancer, like most forms of cancer, is a fatal disease that claims more than half a million lives every year. In 2020, breast cancer overtook lung cancer as the most commonly diagnosed form of cancer. Though extremely deadly, the survival rate and longevity increase substantially with early detection and diagnosis. The treatment protocol also varies with the stage of breast cancer. Diagnosis is typically done using histopathological slides from which it is possible to determine whether\u2026\u00a0",
        "Publication Year": "23 May 2021",
        "Citation Count": "13",
        "Reference Count": "34",
        "Authors": [
            "Soumya Deep Roy",
            "Soham Das",
            "Devroop Kar",
            "Friedhelm Schwenker",
            "Ram Sarkar"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "d3d333de14acd1e07ee1ab9ffdbee65ae3509d23",
            "72ed83174a77c2cae15c91f4078daf8c422bd24e",
            "a74065b90c16130bc1a1d7ea82fdb0a2aed6cfe9",
            "156733fbf757d4e8a333537518c8961163c4fbf7",
            "2f11f86fd805807076b22317738c819484a8e21b",
            "37f65d98c5b5466b63c94a5c83c504b82786f23b",
            "4978d9ab6b70849b28dc44cf960111e6f851e9ad",
            "97c09bdd919fc139215c26366117697417b1006c",
            "d84bafd1fa5e28f41a1e6b0e7d7a36a61efc2fd8",
            "ea5b27748ee154c978534505a177f280d87d52d4"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-Survey-of-Convolutional-Neural-Network-in-Breast-Zhu-Wang/0295f85e0db918b26ff7e8d1d547f8d98eea7feb",
        "ID": "0295f85e0db918b26ff7e8d1d547f8d98eea7feb",
        "Title": "A Survey of Convolutional Neural Network in Breast Cancer",
        "Abstract": "Problems For people all over the world, cancer is one of the most feared diseases. Cancer is one of the major obstacles to improving life expectancy in countries around the world and one of the biggest causes of death before the age of 70 in 112 countries. Among all kinds of cancers, breast cancer is the most common cancer for women. The data showed that female breast cancer had become one of the most common cancers. Aims A large number of clinical trials have proved that if breast cancer is\u2026\u00a0",
        "Publication Year": "9 March 2023",
        "Citation Count": "2",
        "Reference Count": "197",
        "Authors": [
            "Ziquan Zhu",
            "Shuihua Wang",
            "Yudong Zhang"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "00b2c1394bb6195c00fd0fc895aeac26b65e9d5f",
            "1500a27efd9832beb0b92c34c5bb4e12009d9197",
            "a812ebb6761ff453a02d866e97295932153537e2",
            "1a19f55bc7f5d3d90bd5cb239c0202b3428b6aa2",
            "f4008deb11f6a2ec3d52dde72be48cd53c898a45",
            "7d4b1e7c47c02cc62705dce132e187cc53207ff3",
            "bb1beb57009f356e300ed2c83bb2fc4f8198daf3",
            "09a81f37797ee12713b5ddec259bf5be1a1cc226",
            "7b60621086e42a19354f88fd6bc3af85135a07fd",
            "d2638b1f9b86fb7edabc7a5e033bff366e35bb87"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Deep-Learning-in-Selected-Cancers%E2%80%99-Image-Analysis%E2%80%94A-Debelee-Kebede/abfb457caba5314466652825260c12da01a41e0f",
        "ID": "abfb457caba5314466652825260c12da01a41e0f",
        "Title": "Deep Learning in Selected Cancers\u2019 Image Analysis\u2014A Survey",
        "Abstract": "Deep learning algorithms have become the first choice as an approach to medical image analysis, face recognition, and emotion recognition. In this survey, several deep-learning-based approaches applied to breast cancer, cervical cancer, brain tumor, colon and lung cancers are studied and reviewed. Deep learning has been applied in almost all of the imaging modalities used for cervical and breast cancers and MRIs for the brain tumor. The result of the review process indicated that deep learning\u2026\u00a0",
        "Publication Year": "1 November 2020",
        "Citation Count": "34",
        "Reference Count": "159",
        "Authors": [
            "Taye Girma Debelee",
            "Samuel Rahimeto Kebede",
            "Friedhelm Schwenker",
            "Zemene Matewos Shewarega"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ea5b27748ee154c978534505a177f280d87d52d4",
            "d8c6761cb923a33170a3f5a1be30a09070e174d4",
            "2b18e8af1b9c007f1c04d93c0f0b1642c1c4e4f9",
            "70167247fe82408b27f34188c58a27cca698c690",
            "6005102d275c09b5d5ccd3495c55ae7f7c9aad54",
            "abb9b66bc548dbbf25ae242e0996f8a61027cf23",
            "63199437cf214b46fd4a9f6e43784d7d118065b8",
            "b8761df8782f81076930c00c97f5a9aeaa83116f",
            "66794ec56f19b226cb1b0ec7dca77c90ec8694ef",
            "d89c815eb2c79471bcc087d85856d0fcec7d9590"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Survey-of-deep-learning-in-breast-cancer-image-Debelee-Schwenker/ea5b27748ee154c978534505a177f280d87d52d4",
        "ID": "ea5b27748ee154c978534505a177f280d87d52d4",
        "Title": "Survey of deep learning in breast cancer image analysis",
        "Abstract": "Computer-aided image analysis for better understanding of images has been time-honored approaches in the medical computing field. In the conventional machine learning approach, the domain experts in medical images are mandatory for image annotation that subsequently to be used for feature engineering. However, in deep learning, a big jump has been made to help the researchers do segmentation, feature extraction, classification, and detection from raw medical images obtained using digital breast\u2026\u00a0",
        "Publication Year": "1 March 2020",
        "Citation Count": "67",
        "Reference Count": "156",
        "Authors": [
            "Taye Girma Debelee",
            "Friedhelm Schwenker",
            "Achim Ibenthal",
            "Dereje Yohannes"
        ],
        "Related Topics": [
            "Medicine",
            "Computer Science"
        ],
        "References": [
            "88a8401a7caa52aa94c2f0bc22e020dadec9044e",
            "8866a3f71098be5eccab69903cc248e75e8727be",
            "7ab0f0da686cd4094fd96f5a30e0b6072525fd09",
            "011763e5b4009bc9c8adc894af22af9902a6d4bc",
            "907ac4d30e4fc9fc5059b35647b3a853ad5085ea",
            "96b2bc59a36fea81681d782cffe00d942a481249",
            "198d308169e7b95aced6e6b65918a548be20235d",
            "002551e8eff3a53e004a69897937d75b7a046281",
            "cce2545c5d384bfa7eb55b06ea027b1b7c92d2bf",
            "e121a1e9c0b37c91beaf9f96af1ff71954faa7fc"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Deep-Learning-Based-Computer-Aided-Systems-for-%3A-A-Jim'enez-Gaona-Rodr'iguez-'Alvarez/44eb9aafb0d32bf9c8dfd2a4f0f4a418be779a08",
        "ID": "44eb9aafb0d32bf9c8dfd2a4f0f4a418be779a08",
        "Title": "Deep Learning Based Computer-Aided Systems for Breast Cancer Imaging : A Critical Review",
        "Abstract": "This paper provides a critical review of the literature on deep learning applications in breast tumor diagnosis using ultrasound and mammography images. It also summarizes recent advances in computer-aided diagnosis/detection (CAD) systems, which make use of new deep learning methods to automatically recognize breast images and improve the accuracy of diagnoses made by radiologists. This review is based upon published literature in the past decade (January 2010\u2013January 2020), where we obtained\u2026\u00a0",
        "Publication Year": "30 September 2020",
        "Citation Count": "35",
        "Reference Count": "213",
        "Authors": [
            "Yuliana Jim&#x27;enez-Gaona",
            "Mar&#x27;ia Jos&#x27;e Rodr&#x27;iguez-&#x27;Alvarez",
            "Vasudevan Lakshminarayanan"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "ea5b27748ee154c978534505a177f280d87d52d4",
            "4102d50123e3eba572fdcd310acefa551e191b4f",
            "951fbb632fd02fd57fb1d864bbd183ebb93172e0",
            "571f0c4b3a82cdf130effd545e5f17edac522a00",
            "7d8d6d30ce3bd383f947d6d88e22e00e809065f7",
            "831a1e8106571d82f22cd8dac7725964852b0154",
            "7d4b1e7c47c02cc62705dce132e187cc53207ff3",
            "e65e3aaa1d49b4f2cb1aac49230e6339a77290cc",
            "3f09e4926b6a437849f1372bbd91a4cf3435c741",
            "94da6a45acc2669b48fd06000313bdae05d6131a"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Classification-of-medical-images-based-on-deep-Ali-Ejbali/7fdbbe7c8f16dc47865c37acf834581b129a54a9",
        "ID": "7fdbbe7c8f16dc47865c37acf834581b129a54a9",
        "Title": "Classification of medical images based on deep stacked patched auto-encoders",
        "Abstract": "The concept of artificial intelligence is not new. Without going into details of the evolution of artificial intelligence, we can confess that recent techniques of deep neural networks have considerably relaunched the trend with a significant advance namely the ability to automatically learn high-level concepts. However, a great step has been taken in deep learning to help researchers perform segmentation, feature extraction, classification and detection from raw medical images. This paper\u2026\u00a0",
        "Publication Year": "1 July 2020",
        "Citation Count": "6",
        "Reference Count": "50",
        "Authors": [
            "Ramzi Ben Ali",
            "Ridha Ejbali",
            "Mourad Zaied"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3b0d33fc817d4a48fca1d0a11d114eb49e390b89",
            "4536de69054143f85bb5089a8957f16be1eb0c3a",
            "3cbe19d5e217d1bc27d45dd867a6e185db9970d3",
            "156733fbf757d4e8a333537518c8961163c4fbf7",
            "d4ae1b2b2ddebce822d883abe576f975cd5eb2d9",
            "9f1877ce4e986bf1d5eea3f9c0f7de7f8295e6f5",
            "7e7c35e311d5bcf3525ab788d72bb5f8f1797d4c",
            "6420bae0949cd9a2d0f31bb14fd20bce8071a6db",
            "2c5db1c44dddf0d8e6ea667f3f7afb13032ea386",
            "49f43a6047feccc3315c1fe4421723f17a7981c1"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/An-Efficient-Approach-for-Automated-Mass-and-in-Dong-Lu/8271f755d7cea799600e25662dd3f2ac8d23aeb1",
        "ID": "8271f755d7cea799600e25662dd3f2ac8d23aeb1",
        "Title": "An Efficient Approach for Automated Mass Segmentation and Classification in Mammograms",
        "Abstract": "Breast cancer is becoming a leading death of women all over the world; clinical experiments demonstrate that early detection and accurate diagnosis can increase the potential of treatment. In order to improve the breast cancer diagnosis precision, this paper presents a novel automated segmentation and classification method for mammograms. We conduct the experiment on both DDSM database and MIAS database, firstly extract the region of interests (ROIs) with chain codes and using the rough set (RS\u2026\u00a0",
        "Publication Year": "17 March 2015",
        "Citation Count": "73",
        "Reference Count": "42",
        "Authors": [
            "Min Dong",
            "Xiangyu Lu",
            "Yide Ma",
            "Yanan Guo",
            "Yurun Ma",
            "Keju Wang"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "0b4bbde8f766e84708a2e364af3940e283dc6641",
            "34007812641dba00e3aa18dfc21f35fce6604c69",
            "a142b69d0f77b73a88e22c4ac243321c95072c66",
            "8ea35a2467c81c3a4c1c4f8d74b376d0ce52703c",
            "995a9f5653e95ff874e39da5d2d0beeb36aaa950",
            "01da0f8ef03129f2fcb33cdbffc3cfa4babdf2c4",
            "b6cae985af240cc8cb6cb89658f5363064840cbd",
            "6e60e6c86762a1038399f9016184222b4e26f537",
            "0aed632e3d576b6ab0945ac17a84cb008aae8ce2",
            "001ec101a06cf8ce254db94a9c6130b5fe43aabe"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Local-Binary-Patterns-Applied-to-Breast-Cancer-in-Pereira-Eleut%C3%A9rio/d38eeb88a928c1a1c6e1fdd18d504669b112ed8b",
        "ID": "d38eeb88a928c1a1c6e1fdd18d504669b112ed8b",
        "Title": "Local Binary Patterns Applied to Breast Cancer Classification in Mammographies",
        "Abstract": "Among all cancer types, breast cancer is the one with the second highest incidence rate for women. Mammography is the most used method for breast cancer detection, as it reveals abnormalities such as masses, calcifications, asymmetries and architectural distortions. In this paper, we propose a classification method for breast cancer that has been tested for six different cancer types: CALC, CIRC, SPIC, MISC, ARCH, ASYM. The proposed approach is composed of a SVM classifier trained with LBP\u2026\u00a0",
        "Publication Year": "6 November 2014",
        "Citation Count": "8",
        "Reference Count": "25",
        "Authors": [
            "Eanes Torres Pereira",
            "Sidney Pimentel Eleut{\\&#x27;e}rio",
            "Jo{\\~a}o Marques de Carvalho"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "3d2203d7ee72a20608fb8474f41c405e812205ee",
            "8a1de195aa63e304b9ca688c79ccd592d1a3ca95",
            "0619a44fed00222f640f806a5b4ec4821dca690b",
            "059ac0aff72c91ff01a4c6281e787937ffa4216b",
            "4b460e2be2e756ba7259459cdfe57318c016d52d",
            "28a634cc15a1b8c8a6249a5b5f9e30241cd8187c",
            "29d3e96fb170728544f32da4483403c49cc67681",
            "9bf32a68edfea8b8c072bcd3ee0d696687bab403",
            "69df41bed27fa998c6372d4592e93ad0649b98f8",
            "10857554a87c62f2fb28f7ad2f9011362d9b5abf"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Breast-Masses-Identification-through-Pixel-Based-Torrents-Barrena-Puig/4592b296b02a97ce7c49e7ef53bfa5e809bb548e",
        "ID": "4592b296b02a97ce7c49e7ef53bfa5e809bb548e",
        "Title": "Breast Masses Identification through Pixel-Based Texture Classification",
        "Abstract": "Mammographic image analysis plays an important role in computer-aided breast cancer diagnosis. To improve the existing knowledge, this paper proposes a new efficient pixel-based methodology for tumor vs non-tumor classification. The proposed method firstly computes a Gabor feature pool from the mammogram. This feature set is calculated through multi-sized evaluation windows applied to the probabilistic distribution moments, in order to improve the accuracy of the whole system. To deal with a\u2026\u00a0",
        "Publication Year": "29 June 2014",
        "Citation Count": "9",
        "Reference Count": "10",
        "Authors": [
            "Jordina Torrents-Barrena",
            "Domenec Puig",
            "Maria Ferre",
            "Jaime Melendez",
            "Lorena Diez-Presa",
            "Meritxell Arenas",
            "Joan Mart{\\&#x27;i}"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "313b3088315d5596ba4cc52869a94092dfa425a8",
            "9b5d0a48b0feb156a1270da54d90d0963a3f0404",
            "5f7185900d61c1e308fe66094773ffa6c3cfc6a8",
            "bcf61644e672df7d74537794ebe68caeb0976a94",
            "f1df61fd00b701399b15222de3e1fe9d4e2b987c",
            "3e2f4656ba2076b49047f6edaa7332f60156e98d",
            "2989b07819dfd279222a3755d3b7862f1a1a7f53",
            "5f3f3b9db21f5f91a2e2f37bf6b95db48e620041",
            "273dfbcb68080251f5e9ff38b4413d7bd84b10a1",
            "0d02083f5e9206ff88ed1e284da8665d4bee81ba"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Classification-of-breast-masses-in-mammograms-using-Nandi-Nandi/c0cdec8e8149ab2e7d185893e3f18eb0089a0f2f",
        "ID": "c0cdec8e8149ab2e7d185893e3f18eb0089a0f2f",
        "Title": "Classification of breast masses in mammograms using genetic programming and feature selection",
        "Abstract": "Mammography is a widely used screening tool and is the gold standard for the early detection of breast cancer. The classification of breast masses into the benign and malignant categories is an important problem in the area of computer-aided diagnosis of breast cancer. A small dataset of 57 breast mass images, each with 22 features computed, was used in this investigation; the same dataset has been previously used in other studies. The extracted features relate to edge-sharpness, shape, and\u2026\u00a0",
        "Publication Year": "21 July 2006",
        "Citation Count": "89",
        "Reference Count": "36",
        "Authors": [
            "Robin J. Nandi",
            "Asoke Kumar Nandi",
            "Rangaraj M. Rangayyan",
            "Di Scutt"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "5fac84ef49bc6dcc4aeaf6c5623173f8c0e2a531",
            "f8b061df30fa1eb1ca444cedf2e9be9d091120f2",
            "ac0ca4295b0622e370c19716071614b6d2d723f9",
            "ba721e81d2ab8114bc9afcf78f8335c1f6475364",
            "f2f53333761f6badfa8cbc3aaf90c82455c4745e",
            "1060c5b534e53e213b9e3f9b8a75b54e3639cee8",
            "16f3cb52eb1f374aa037c4080ccbf68d2d7b8cd1",
            "66cb958c5fe045d9037724f38c5ca7b4728a13f1",
            "0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb",
            "13c5a81b319445f3e6bba16f4e76fcf0efd87354"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Computer-Aided-Diagnosis-of-Malignant-Mammograms-Sharma-Khanna/662d927da3c17bfde61da5dbc24c037dce30ce25",
        "ID": "662d927da3c17bfde61da5dbc24c037dce30ce25",
        "Title": "Computer-Aided Diagnosis of Malignant Mammograms using Zernike Moments and SVM",
        "Abstract": "This work is directed toward the development of a computer-aided diagnosis (CAD) system to detect abnormalities or suspicious areas in digital mammograms and classify them as malignant or nonmalignant. Original mammogram is preprocessed to separate the breast region from its background. To work on the suspicious area of the breast, region of interest (ROI) patches of a fixed size of 128\u00d7128 are extracted from the original large-sized digital mammograms. For training, patches are extracted\u2026\u00a0",
        "Publication Year": "1 February 2015",
        "Citation Count": "96",
        "Reference Count": "61",
        "Authors": [
            "Shubhi Sharma",
            "Pritee Khanna"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "5c84051b348beb94f07cec39f389b5c88146dec5",
            "7a16973606f2f34e06a6446f22105cc342576202",
            "e01f9f37c0b096990025b9b2861cd05d84ffa665",
            "46c409dd878e643271ef63f1817ded8b57abc01e",
            "db3101c7057d71ca42edc17e2c30353ff1b70120",
            "0c0ab9edfaa8c1f6cad563e41dc882c8de5514c7",
            "dda0dc40bc5cb79d5638d8cac955337362e6473e",
            "047947cfa21a45d9beea07cc2a2f579bb1c8a0da",
            "54ceeab87535d4048eb262dcc8cdbc46ae735ea4",
            "c5ac9c778de5186dc42e6052bb7f0d28e6b279e5"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Optimization-of-breast-mass-classification-using-a-Tan-Pu/da4237818523ea3e3d44dbe18c261afc6d6d404f",
        "ID": "da4237818523ea3e3d44dbe18c261afc6d6d404f",
        "Title": "Optimization of breast mass classification using sequential forward floating selection (SFFS) and a support vector machine (SVM) model",
        "Abstract": "PurposeImproving radiologists\u2019 performance in classification between malignant and benign breast lesions is important to increase cancer detection sensitivity and reduce false-positive recalls. For this purpose, developing computer-aided diagnosis schemes has been attracting research interest in recent years. In this study, we investigated a new feature selection method for the task of breast mass classification.MethodsWe initially computed 181 image features based on mass shape, spiculation\u2026\u00a0",
        "Publication Year": "25 March 2014",
        "Citation Count": "71",
        "Reference Count": "82",
        "Authors": [
            "Maxine Tan",
            "Jiantao Pu",
            "Bin Zheng"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "c0cdec8e8149ab2e7d185893e3f18eb0089a0f2f",
            "c1b8abebc968d811d1121b11145ee8bb360b9351",
            "1448eded35e963c7316f64f9c1b54abe519665fa",
            "dee6af9a0ad791e7bc76d1316b762b94218a6ae6",
            "a3825cafd02659229fb6a65b2c8c4be970f13726",
            "5fac84ef49bc6dcc4aeaf6c5623173f8c0e2a531",
            "f8b061df30fa1eb1ca444cedf2e9be9d091120f2",
            "841e4c4843c6fb70b1b631f471e24bbf1f52f7ae",
            "da6f9a25ebc31ae4572e4ec9b8bab37c7952af7a",
            "a277fe4df26e09a6c375e32d77472ae2c9a7632d"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Texture-features-for-classification-of-ultrasonic-Wu-Chen/037587b28682886bb02d87a150028ed931f967a4",
        "ID": "037587b28682886bb02d87a150028ed931f967a4",
        "Title": "Texture features for classification of ultrasonic liver images",
        "Abstract": "The classification of ultrasonic liver images is studied, making use of the spatial gray-level dependence matrices, the Fourier power spectrum, the gray-level difference statistics, and the Laws texture energy measures. Features of these types are used to classify three sets of ultrasonic liver images-normal liver, hepatoma, and cirrhosis (30 samples each). The Bayes classifier and the Hotelling trace criterion are employed to evaluate the performance of these features. From the viewpoint of\u2026\u00a0",
        "Publication Year": "1992",
        "Citation Count": "519",
        "Reference Count": "32",
        "Authors": [
            "Chung-Ming Wu",
            "Yung-Chang Chen",
            "Kai-Sheng Hsieh"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "2218c7e9c5d28a7e78bfdd28b77b31d6dbc4c824",
            "5265070d473215e690115e1cd39480d0bda3ca9b",
            "4ebd291ecd93bab330138d5791c0061a44dc769e",
            "45666cef42b1a6423a030cfc0581062a45641434",
            "7a8b47ca09ff2182fa905504dba4a72d0bec4808",
            "4c8accd5d2986e1991ddbc952531ee033e358ff2",
            "1fdb62555eb650662dbe2a6f3985d390861597c2",
            "02fc7d20332217f84f6e2217c0966f1adccac027",
            "9e8e2cd95bd8d879a608f20a133abd92fa988c31",
            "bd988ef4ac18856528bd12bc924bb83dcd5efdb6"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Measures-of-acutance-and-shape-for-classification-Rangayyan-El-Faramawy/0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb",
        "ID": "0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb",
        "Title": "Measures of acutance and shape for classification of breast tumors",
        "Abstract": "Most benign breast tumors possess well-defined, sharp boundaries that delineate them from surrounding tissues, as opposed to malignant tumors. Computer techniques proposed to date for tumor analysis have concentrated on shape factors of tumor regions and texture measures. While shape measures based on contours of tumor regions can indicate differences in shape complexities between circumscribed and spiculated tumors, they are not designed to characterize the density variations across the\u2026\u00a0",
        "Publication Year": "1 December 1997",
        "Citation Count": "355",
        "Reference Count": "57",
        "Authors": [
            "Rangaraj M. Rangayyan",
            "N. M. El-Faramawy",
            "J. E. Leo Desautels",
            "Onsy Abdel Alim"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "2c13b62db56cd2493b0a5cca029456e88e2ee400",
            "c67859df1a7a43409479b9d98ad3066263083365",
            "4a18fe753a3d4f6619928220fb23f7bdd3ba4cff",
            "057ac70ca12c96e90ccf461a8c6ad2c82e94e787",
            "747c6002686c66f2ef1b16a6d0142d0439ad050f",
            "e0f129157f3d08e77334af043bb2368f62b515c2",
            "5fac84ef49bc6dcc4aeaf6c5623173f8c0e2a531",
            "8f96c5e5097f8cdefbd2bd27e121d2e80ef68b0e",
            "e64595d320da91ac2640f7e2794c4fde9920b7c4",
            "5a568905f56d5c424c671757552afc03e70f73fd"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Automated-Analysis-of-Ultrasound-Videos-for-of-Movahedi-Zamani/5d5f2f44fa6f251f3a663b0be9abf09a75772ec9",
        "ID": "5d5f2f44fa6f251f3a663b0be9abf09a75772ec9",
        "Title": "Automated Analysis of Ultrasound Videos for Detection of Breast Lesions",
        "Abstract": "Background: Breast cancer is the second cause of death among women. Ultrasound (US) imaging is the most common technique for diagnosing breast cancer; however, detecting breast lesions in US images is a difficult task, mainly, because it provides low-quality images. Consequently, identifying lesions in US images is still a challenging task and an open problem in US image processing. This study aims to develop an automated system for the identification of lesions in US images \nMethod: We\u2026\u00a0",
        "Publication Year": "2020",
        "Citation Count": "3",
        "Reference Count": "43",
        "Authors": [
            "Mohammad Mehdi Movahedi",
            "Ali Zamani",
            "Hossein Parsaei",
            "Ali Tavakoli Golpaygani",
            "Mohammad Reza Haghighi Poya"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "ef6eacba51a4edaa9d1b945da217d46dd75285ce",
            "96b2bc59a36fea81681d782cffe00d942a481249",
            "4bd5f826fe1be284c2254743f58aaeb74af7b9f8",
            "bff4b9e8353c7225aa45414e6f837135032ebe2b",
            "7538b4982371f408a36151a9469f8ca21bf5a625",
            "c043dd7e15af7688a9297e78705cdf27d686c6fe",
            "3eb881c42e61699e87dceb26ff3eab8a28ae8a60",
            "bb3a0efa630275bfc1f59618593f55ed08d98df5",
            "4d7ef4f116a535750529e2853c181d5d3b678646",
            "c66e0bbbca30766b790a48010920002520fc56e9"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/A-review-on-recent-advancements-in-diagnosis-and-of-Ramesh-Karuppasamy/7fadf94a23758457e4808a6dca7aacc3a3f1b39f",
        "ID": "7fadf94a23758457e4808a6dca7aacc3a3f1b39f",
        "Title": "A review on recent advancements in diagnosis and classification of cancers using artificial intelligence",
        "Abstract": "Artificial intelligence has illustrated drastic changes in radiology and medical imaging techniques which in turn led to tremendous changes in screening patterns. In particular, advancements in these techniques led to the development of computer aided detection (CAD) strategy. These approaches provided highly accurate diagnostic reports which served as a \u201csecond-opinion\u201d to the radiologists. However, with significant advancements in artificial intelligence strategy, the diagnostic and\u2026\u00a0",
        "Publication Year": "11 September 2020",
        "Citation Count": "3",
        "Reference Count": "82",
        "Authors": [
            "Priyanka Ramesh",
            "Ramanathan Karuppasamy",
            "Shanthi Veerappapillai"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "0cf069583a096b4b60459b5379189f6938b11282",
            "7f16ab21a77040c52f97b76495b692363fd63fc6",
            "2bb6e1326069b22d5da8d52a6a38a4ad5ba4b507",
            "f4a8f1ba0c7e30c12a917a29b8b968e73564b602",
            "4955335096c038f2cf39fdb4cc2bc79edaf363f9",
            "dde843098cd0aaf15fccb307a64a96a77b9acfbd",
            "16d10e6fd7987d19d0f49f193c936a5a411218d6",
            "52c7b0d98995f189eaf6d775231b27bfa83ed194",
            "4d7ef4f116a535750529e2853c181d5d3b678646",
            "77b01422d4fa697454e1bec218433532d7c1e906"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Automatic-Diagnosis-of-Myocarditis-Disease-in-MRI-Jafari-Shoeibi/d7e180bf88a42c67357ff97ef88063c74ed6fac1",
        "ID": "d7e180bf88a42c67357ff97ef88063c74ed6fac1",
        "Title": "Automatic Diagnosis of Myocarditis Disease in Cardiac MRI Modality using Deep Transformers and Explainable Artificial Intelligence",
        "Abstract": "Myocarditis is among the most important cardiovascular diseases (CVDs), endangering the health of many individuals by damaging the myocardium. Microbes and viruses, such as HIV, play a vital role in myocarditis disease (MCD) incidence. Lack of MCD diagnosis in the early stages is associated with irreversible complications. Cardiac magnetic resonance imaging (CMRI) is highly popular among cardiologists to diagnose CVDs. In this paper, a deep learning (DL) based computer-aided diagnosis system\u2026\u00a0",
        "Publication Year": "26 October 2022",
        "Citation Count": "3",
        "Reference Count": "91",
        "Authors": [
            "Mahboobeh Jafari",
            "Afshin Shoeibi",
            "Navid Ghassemi",
            "J{\\&#x27;o}nathan Heras",
            "Abbas Khosravi",
            "Saiguang Ling",
            "Roohallah Alizadehsani",
            "Amin Beheshti",
            "Yudong Zhang",
            "Shuihua Wang",
            "Juan Manuel G{\\&#x27;o}rriz",
            "U. Rajendra Acharya",
            "Hamid Alinejad-Rokny"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "7b28c471d75cc75d5b14cc014be415a3814e669c",
            "571473504f43c6cb7d394dda927059efd95eaaa1",
            "3d31cc99490091d84e85b3218360c2b7e7b1f55b",
            "ad16242d6c394a65982624248429bf3ecdbc06b0",
            "da5bfc157a8b0a65dd24f8e8b936fab94ebd09c5",
            "850b01c04c130c281e04eb17d2f0fe46507cf632",
            "aa2bd5a6793280e99caf49351c54aa81d072506b",
            "1b4398125928ca07a1eebf093ddf51df3e62116d",
            "4f1a113795d64c23792b45ea7275fed6e0f69e62",
            "073b38067439253e5998fddfda740f0736d18e26"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Epileptic-Seizures-Detection-Using-Deep-Learning-A-Shoeibi-Ghassemi/52ec59c8579339d5f9637c54b4d36ffd95808912",
        "ID": "52ec59c8579339d5f9637c54b4d36ffd95808912",
        "Title": "Epileptic Seizures Detection Using Deep Learning Techniques: A Review",
        "Abstract": "A variety of screening approaches have been proposed to diagnose epileptic seizures, using electroencephalography (EEG) and magnetic resonance imaging (MRI) modalities. Artificial intelligence encompasses a variety of areas, and one of its branches is deep learning (DL). Before the rise of DL, conventional machine learning algorithms involving feature extraction were performed. This limited their performance to the ability of those handcrafting the features. However, in DL, the extraction of\u2026\u00a0",
        "Publication Year": "2 July 2020",
        "Citation Count": "126",
        "Reference Count": "184",
        "Authors": [
            "Afshin Shoeibi",
            "Navid Ghassemi",
            "Marjane Khodatars",
            "Mahboobeh Jafari",
            "Sadiq Hussain",
            "Roohallah Alizadehsani",
            "Parisa Moridian",
            "Abbas Khosravi",
            "Hossein Hosseini-Nejad",
            "Modjtaba Rouhani",
            "Assef Zare",
            "Ali Khadem",
            "Saeid Nahavandi",
            "Amir F. Atiya",
            "U. Rajendra Acharya"
        ],
        "Related Topics": [
            "Computer Science",
            "Medicine"
        ],
        "References": [
            "de059cc4cd9eeac8905853eb5aef3b808bc5a047",
            "8ec99d1174875dd25579e67fa409482a305e8b4a",
            "3a722f2e1058037c6d828c95630f59588f1a8641",
            "3e1e23b05b71acad0f389593dab1ca74b57bf358",
            "1d9899aaec76e91daff034280d1942a89b6e7f43",
            "0f0f8c5e671ea6f492de92c73b61fa8600febce0",
            "dc042a12ddc19afa7a5c82032f31d5482f34eb83",
            "90e966e446f99573f571af6e66c5181586a4606d",
            "ffb2362dadc8d16f8529fe71fb574a620691cf4c",
            "d124841a68e2ef11bdccc52089d0c2b2ae883501"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Automatic-autism-spectrum-disorder-detection-using-Moridian-Ghassemi/7d8d989194afb78158206b9803907e2c0bd228bb",
        "ID": "7d8d989194afb78158206b9803907e2c0bd228bb",
        "Title": "Automatic autism spectrum disorder detection using artificial intelligence methods with MRI neuroimaging: A review",
        "Abstract": "Autism spectrum disorder (ASD) is a brain condition characterized by diverse signs and symptoms that appear in early childhood. ASD is also associated with communication deficits and repetitive behavior in affected individuals. Various ASD detection methods have been developed, including neuroimaging modalities and psychological tests. Among these methods, magnetic resonance imaging (MRI) imaging modalities are of paramount importance to physicians. Clinicians rely on MRI modalities to diagnose\u2026\u00a0",
        "Publication Year": "20 June 2022",
        "Citation Count": "11",
        "Reference Count": "368",
        "Authors": [
            "Parisa Moridian",
            "Navid Ghassemi",
            "Mahboobeh Jafari",
            "Salam Salloum-Asfar",
            "Delaram Sadeghi",
            "Marjane Khodatars",
            "Afshin Shoeibi",
            "Abbas Khosravi",
            "Saiguang Ling",
            "Abdulhamit Subasi",
            "Sara A. Abdulla",
            "Roohallah Alizadehsani",
            "Juan Manuel G{\\&#x27;o}rriz",
            "U. Rajendra Acharya"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "01dc8eaf2ff0db81211b1b3c3b44a359bb684cfb",
            "a105e262a4aa967db4e9fa854a425a38ec27ba80",
            "cc0bcb8de07b7889e3410d1d29e99280c7f7247f",
            "a184c860d84eb77d3e630caea9b8c5999d82a997",
            "91473ee834ef27a513ca10a65ec2df4373dd818a",
            "314487e083e768964fdee7ffe57e9dde233e18c1",
            "bcc00b5cfdd6985bd774d6353cd634958465a13f",
            "1a85f8e4d74f3406f71ab7dc8d5b2aedd3077efb",
            "f6904babc1b054cdbd6284bcc8980a0668dd189d",
            "973d134a13fde46a74c8b9025b76d03465f60b72"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Breast-Cancer-Detection-Using-PCPCET-and-ADEWNN%3A-A-Singh-Urooj/ba6b8c2852be77702ff1765cefde34004da9d4b5",
        "ID": "ba6b8c2852be77702ff1765cefde34004da9d4b5",
        "Title": "Breast Cancer Detection Using PCPCET and ADEWNN: A Geometric Invariant Approach to Medical X-Ray Image Sensors",
        "Abstract": "In the field of radiology, mammographic screened images (i.e. X-ray image sensing) are very challenging and difficult to interpret. The expert radiologist visually hunts the mammograms for any specific abnormality. However, human factor causes a low degree of precision that often results in biopsy and anxiety for the patient involved. This paper proposes a novel computer-aided detection (CAD) system to reduce the human factor involvement and to help the radiologist in automatic diagnosis of\u2026\u00a0",
        "Publication Year": "15 June 2016",
        "Citation Count": "44",
        "Reference Count": "26",
        "Authors": [
            "Satya Prakash Singh",
            "Shabana Urooj",
            "Aime\u2019 Lay-Ekuakille"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "f49db5244038f08b5940e02d012dd1d5f7512f22",
            "662d927da3c17bfde61da5dbc24c037dce30ce25",
            "95bb0ee471480da79e41ae196bb4da02abe52a27",
            "951fbb632fd02fd57fb1d864bbd183ebb93172e0",
            "46c409dd878e643271ef63f1817ded8b57abc01e",
            "4a58defcda915eeeccc82d7e14e02daf54a40332",
            "4f325d8be07594c94f0d7568c80c91c55bdb3774",
            "c6db34ade32b3681a92068b22a354903b2953d52",
            "9215e06244536f80e5fedd1730faf1268170f442",
            "2dfb1fd3adfa58a3448251e03b1a5a78239958b3"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Association-Between-Changes-in-Mammographic-Image-Tan-Zheng/74b5ce5b484a5bd714cab5dd4424a26cbdabbb35",
        "ID": "74b5ce5b484a5bd714cab5dd4424a26cbdabbb35",
        "Title": "Association Between Changes in Mammographic Image Features and Risk for Near-Term Breast Cancer Development",
        "Abstract": "The purpose of this study is to develop and test a new computerized model for predicting near-term breast cancer risk based on quantitative assessment of bilateral mammographic image feature variations in a series of negative full-field digital mammography (FFDM) images. The retrospective dataset included series of four sequential FFDM examinations of 335 women. The last examination in each series (\u201ccurrent\u201d) and the three most recent \u201cprior\u201d examinations were obtained. All \u201cprior\u201d examinations\u2026\u00a0",
        "Publication Year": "1 July 2016",
        "Citation Count": "57",
        "Reference Count": "33",
        "Authors": [
            "Maxine Tan",
            "Bin Zheng",
            "Joseph Ken Leader",
            "David Gur"
        ],
        "Related Topics": [
            "Medicine"
        ],
        "References": [
            "89dd851f83fce7f01f2884e34326150e29c93a10",
            "83b51969235076b5698ffb9a63411836bdf4b679",
            "01fed31c148a9786a1ae1d29294eb7abb6740cc5",
            "282e94f32b75bf2a9a92585eae9527696b2c853b",
            "1b316d9a0e58be5d9899cb55f132ab8373609cef",
            "ed6a5d218279fdc66836eb257699a83742d61c17",
            "e1833a668dfbc47a5567686b71374410d392253a",
            "6bf47c9319bcf3e78f6a7cbd51145114008403ae",
            "519505664b7cca967371bf5d959edf322f143a5a",
            "637551683e01bf871be9563f52911ad95da804f7"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/AggNet%3A-Deep-Learning-From-Crowds-for-Mitosis-in-Albarqouni-Baur/8d7bc6a0af5c063c457a88561bcf8f895c9f7392",
        "ID": "8d7bc6a0af5c063c457a88561bcf8f895c9f7392",
        "Title": "AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images",
        "Abstract": "The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy\u2026\u00a0",
        "Publication Year": "11 February 2016",
        "Citation Count": "389",
        "Reference Count": "37",
        "Authors": [
            "Shadi Albarqouni",
            "Christoph Baur",
            "Felix Achilles",
            "Vasileios Belagiannis",
            "Stefanie Demirci",
            "Nassir Navab"
        ],
        "Related Topics": [
            "Computer Science"
        ],
        "References": [
            "3efb4b353fd2adab70aaf882401859542a0e2d10",
            "5b25e4cb5755907ab48e8cd9fa595a333647eb7d",
            "55d66a61ce28eae0a752dcc7b4b6f35625fc2ce7",
            "93c34f96347d06f20c79e6b1676830a3c78216e8",
            "412a78b2585af37e6474b0795e4830660c4cb83b",
            "dc88d84afc20fcc9d3f627eec537c903871f880e",
            "2f4df08d9072fc2ac181b7fced6a245315ce05c8",
            "6953420c593842697dd09bc2cf7ffbbaf67a6e8e",
            "317aee7fc081f2b137a85c4f20129007fd8e717e",
            "3d1513ae78f4e038b235d7b01a5331803ec98529"
        ]
    },
    {
        "URL": "https://www.semanticscholar.org/paper/Image-enhancement-with-Gaussian-filtering-in-system-Kwon-Lee/d2c0761e849f656a8933f2c75b8ff8a10713684f",
        "ID": "d2c0761e849f656a8933f2c75b8ff8a10713684f",
        "Title": "Image enhancement with Gaussian filtering in time-domain microwave imaging system for breast cancer detection",
        "Abstract": "A time-domain microwave imaging system with improved image quality is presented for early detection of breast cancer. The time-domain system has the advantage of short scan time compared with the frequency-domain system but suffers from low signal-to-noise ratio (SNR) due to high attenuation of the RF signal within the breast tissue. Signal averaging of repeated measurements can improve the SNR, but this method also smears the signal peaks due to the signal-averaged jitter, which adversely\u2026\u00a0",
        "Publication Year": "25 February 2016",
        "Citation Count": "19",
        "Reference Count": "13",
        "Authors": [
            "S. J. Kwon",
            "Hyesun Lee",
            "Soon-Nam Lee"
        ],
        "Related Topics": [
            "Physics"
        ],
        "References": [
            "a04ed30453a76119b75aa012f4ceb897ffb23ef1",
            "54fde5ed8ecd5ec997842da1d24d772b27e9811a",
            "03c372da3e0a6a2478691377ee280b3ae74297f0",
            "c1fef4f3c7c4c7d049770e59abe4ac5a60312c93",
            "bc25a12d4325026f9d8891db1590f78f44609684",
            "958e7d9a5feb6db119c64f55b9db8f568b51bbda",
            "971ea534722f49f93492c939bc958a545c0d2bcb",
            "c937a45e87ecc8172602e78f711a587747d3a3b0",
            "7680edd2cd541ef8ce26c776e8d1cc1cdbed8ada",
            "b72fdac24f519021dbb46cb1be0ccdc16943856b"
        ]
    }
]