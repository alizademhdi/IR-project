{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=6>\n",
    "<h1>مقدمه</h1>\n",
    "</font>\n",
    "<font face=\"XB Zar\" size=3>\n",
    "این تمرین به پیش‌پردازش متن، اصلاح پرسمان، ساخت نمایه، بازیابی boolean و فشرده‌سازی نمایه می‌پردازد.\n",
    "<br>\n",
    "دیتاستی که در اختبار شما قرار گرفته است شامل چکیده مقالات و id آن‌ها می‌باشد.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mhdi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mhdi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics import edit_distance\n",
    "import re\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from bitarray import bitarray\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h1> آماده‌سازی دیتاست</h1>\n",
    "<p>\n",
    "دیتاستی که در اختیار شما قرار گرفته است، دارای سطر‌هایی می‌باشد که دارای مقدار NaN می‌باشد. برای اینکه بتوانید با این دیتاست کار کنید، باید ابتدا این سطر‌ها را حذف کنید.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/data-v1.csv\"\n",
    "df = pd.read_csv(data_path).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6168</td>\n",
       "      <td>\"Emerging safety-critical real-time control sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6169</td>\n",
       "      <td>\"Based on the Cumulative Risk Model, a single ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6170</td>\n",
       "      <td>Parallel independent disks can enhance the per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6171</td>\n",
       "      <td>MUDs, or \"multi-user dungeons\", are multi-user...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6172</td>\n",
       "      <td>The GPUs are emerging as a general-purpose hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6173</td>\n",
       "      <td>Active research is ongoing in logic devices be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6174</td>\n",
       "      <td>With the development of autonomous driving and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6175</td>\n",
       "      <td>Deep neural networks provide unprecedented per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6176</td>\n",
       "      <td>This paper begins by giving a characterization...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6177</td>\n",
       "      <td>This document provides guidance on how to secu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6178</td>\n",
       "      <td>The authors investigate the effect of electrod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paperId                                           abstract\n",
       "0      6168  \"Emerging safety-critical real-time control sy...\n",
       "1      6169  \"Based on the Cumulative Risk Model, a single ...\n",
       "2      6170  Parallel independent disks can enhance the per...\n",
       "3      6171  MUDs, or \"multi-user dungeons\", are multi-user...\n",
       "4      6172  The GPUs are emerging as a general-purpose hig...\n",
       "5      6173  Active research is ongoing in logic devices be...\n",
       "6      6174  With the development of autonomous driving and...\n",
       "7      6175  Deep neural networks provide unprecedented per...\n",
       "8      6176  This paper begins by giving a characterization...\n",
       "9      6177  This document provides guidance on how to secu...\n",
       "10     6178  The authors investigate the effect of electrod..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h1> Preprocessing (پیش پردازش)</h1>\n",
    "<p>\n",
    "بسیاری از داده ‌ها دارای مقادیر زیادی اطلاعات اضافه هستند که در پردازش ها به آن نیازی نیست و یا باعث ایجاد خطا میشوند.\n",
    "دراین بخش داده را از دیتابیس مورد نظر خوانده\n",
    "  و سپس پیش پردازش های مورد نیاز را اعمال کنید تا متن پیش پردازش شده را تولید کنید.\n",
    "پس از اتمام پیش پردازش سایر عملیات گفته شده در ادامه را بر\n",
    "روی متن ایجاد شده انجام میدهیم.\n",
    "\n",
    "\n",
    "کلاس\n",
    "\"Preprocessor\"\n",
    "عملیات پیش پردازش را انجام میدهد. نام توابع عمل های مورد نظر نوشته شده است و که با توجه به آن باید کد مخصوص هر یک نوشته شود. تابع\n",
    "\"preprocessor\"\n",
    "تابع اصلی این کلاس است که متن بدون پیش پردازش را گرفته و پردازش های مورد نظر را در آن اعمال میکند و متن مورد نظر را ایجاد میکند.\n",
    "\n",
    "در این بخش میتوانید از کتابخانه های آماده مانند\n",
    "<a href=\"https://www.nltk.org/\">NLTK</a>\n",
    "و\n",
    "<a href=\"https://spacy.io/\">SpaCy</a>\n",
    "استفاده کنید.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Preprocessor:\n",
    "\n",
    "    def __init__(self, stopwords):\n",
    "        self.stopwords = stopwords\n",
    "        self.ps = PorterStemmer()\n",
    "\n",
    "\n",
    "    def preprocess(self, text, is_query=False):\n",
    "        text = self.remove_links(text)\n",
    "        text = self.remove_punctuations(text)\n",
    "        tokens = self.word_tokenize(text)\n",
    "        tokens = self.normalize(tokens)\n",
    "        if not is_query:\n",
    "            tokens = self.remove_stopwords(tokens)\n",
    "        return tokens\n",
    "\n",
    "    def normalize(self, tokens):\n",
    "        for i, token in enumerate(tokens):\n",
    "            tokens[i] = self.ps.stem(token)\n",
    "        return tokens\n",
    "    \n",
    "    def remove_links(self, text):\n",
    "        text = re.sub('http[s]?://\\S+', '', text)        \n",
    "        return text\n",
    "\n",
    "    def remove_punctuations(self, text):\n",
    "        regular_expression = r'[^\\w\\s]'\n",
    "        return re.sub(regular_expression, ' ', text.lower())\n",
    "\n",
    "    def word_tokenize(self, text):\n",
    "        tokenized_text = nltk.tokenize.word_tokenize(text)\n",
    "        return tokenized_text\n",
    "\n",
    "    def remove_stopwords(self, words):\n",
    "        return [word for word in words if word not in self.stopwords]\n",
    "\n",
    "preprocessor = Preprocessor(stopwords=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h1>ساخت نمایه</h1>\n",
    "<p>\n",
    "شما در حال توسعه یک موتور جستجوی سریع هستید که از نمایه سازی پویا پشتیبانی می کند. موتور جستجو اسناد جدید را در قالب دسته‌هایی کوچک‌تر   \n",
    "(batch) هندل می‌کند. در پایان هر روز، این دسته‌ها با استفاده از استراتژی ادغام لگاریتمی ادغام می شوند. هدف به حداقل رساندن هزینه ادغام است.  \n",
    "مراحلی که باید برای حل این مسئله انجام دهید عبارتند از:\n",
    "<li>توکن‌بندی و نرمال‌سازی متن از اسناد.</li>\n",
    "    <li>ایجاد یک index مرتب‌ شده برای هر دسته از اسناد.</li>\n",
    "    <li>ادغام بهینه چند دسته از indexها با استفاده از یک استراتژی ادغام لگاریتمی.</li>\n",
    "وظیفه شما این است که بخش‌های خالی <strong>(مشخص شده به‌صورت {TODO})</strong> کد را پر کنید تا موتور جستجو عملی شود.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h3> دستورات </h3>\n",
    "<li>متد <code>sort_based_index_construction</code> از <code>DocumentBatch</code>:</li>\n",
    "<p>هر سند را با استفاده از تابع‌هایی که در قسمت قبل نوشتید، عمل preprocessing را روی آن انجام دهید.</p>\n",
    "<p>برای هر توکن، شناسه سند را به فهرست معکوس (inverted index) برای آن توکن اضافه کنید.</p>\n",
    "<li>متد <code>add_batch</code> در <code>FastSearchEngine</code></li>\n",
    "<p>فهرست معکوس برای دسته (batch) را ایجاد کنید.</p>\n",
    "<p>این دسته را به فهرست‌های روزانه اضافه کنید.</p>\n",
    "<li>متد <code>end_of_day_merge</code> از <code>FastSearchEngine:</code></li>\n",
    "<p>استراتژی ادغام لگاریتمی را پیاده‌سازی کنید تا به صورت بهینه فهرست‌های روزانه را با فهرست اصلی ادغام کنید.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "class DocumentBatch:\n",
    "    def __init__(self, docs: dict):\n",
    "        self.documents = docs\n",
    "        self.index = defaultdict(set)\n",
    "\n",
    "    def sort_based_index_construction(self):\n",
    "        for doc_id, doc in self.documents.items():\n",
    "            tokens = preprocessor.preprocess(doc)\n",
    "            for token in tokens:\n",
    "                self.index[token].add(doc_id)\n",
    "            \n",
    "class FastSearchEngine:\n",
    "    def __init__(self):\n",
    "        self.main_index = defaultdict(set)\n",
    "        self.daily_indices = deque()\n",
    "\n",
    "    def add_batch(self, batch: DocumentBatch):\n",
    "        batch.sort_based_index_construction()\n",
    "        self.daily_indices.append(batch.index)\n",
    "    \n",
    "    def merge(self, first, second):\n",
    "        merged_index = defaultdict(set)\n",
    "        for token in first.keys() | second.keys():\n",
    "            merged_index[token] = first[token] | second[token]\n",
    "        return merged_index\n",
    "\n",
    "    def end_of_day_logarithmic_merge(self):\n",
    "        self.daily_indices.append(self.main_index)\n",
    "        while len(self.daily_indices) > 1:\n",
    "            first = self.daily_indices.popleft()\n",
    "            second = self.daily_indices.popleft()\n",
    "            self.daily_indices.append(self.merge(first, second))\n",
    "        self.main_index = self.daily_indices.pop()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'sample_16': {16}, 'sample_15': {15}, 'sample_1': {1}, 'sample_6': {6}, 'sample_3': {3}, 'sample_7': {7}, 'sample_4': {4}, 'sample_18': {18}, 'sample_14': {14}, 'sample_10': {10}, 'sample_2': {2}, 'sample_8': {8}, 'sample_5': {5}, 'sample_20': {20}, 'sample_17': {17}, 'sample_11': {11}, 'sample_19': {19}, 'sample_12': {12}, 'sample_9': {9}, 'sample_13': {13}})\n"
     ]
    }
   ],
   "source": [
    "# Divide the documents into groups to distribute them between servers. For example, let's consider two servers here.\n",
    "# Divide the documents of each server into batches, for instance, five batches.\n",
    "# Create an index for each batch and for each server, then merge them into the main index at the end of the day.\n",
    "# Repeat this process until all documents are processed.\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Usage example\n",
    "server_a_docs = {1: \"sample_1\", 2: \"sample_2\", 3: \"sample_3\", 4: \"sample_4\", 5: \"sample_5\", 6: \"sample_6\", 7: \"sample_7\", 8: \"sample_8\", 9: \"sample_9\", 10: \"sample_10\"}\n",
    "server_b_docs = {11: \"sample_11\", 12: \"sample_12\", 13: \"sample_13\", 14: \"sample_14\", 15: \"sample_15\", 16: \"sample_16\", 17: \"sample_17\", 18: \"sample_18\", 19: \"sample_19\", 20: \"sample_20\"}\n",
    "\n",
    "search_engine = FastSearchEngine()\n",
    "\n",
    "for i in range(5):\n",
    "    server_a_batch = DocumentBatch(dict(itertools.islice(server_a_docs.items(), i*2, i*2+2)))\n",
    "    server_b_batch = DocumentBatch(dict(itertools.islice(server_b_docs.items(), i*2, i*2+2)))\n",
    "\n",
    "    \n",
    "\n",
    "    search_engine.add_batch(server_a_batch)\n",
    "    search_engine.add_batch(server_b_batch)\n",
    "\n",
    "    search_engine.end_of_day_logarithmic_merge()\n",
    "\n",
    "# Note that the above was just an example demonstrating the general process.\n",
    "# but you can take two servers and five batches for each server as a constant and implement the process for them.\n",
    "print(search_engine.main_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'architectur': {6172}, 'may': {6169}, '2': {6173}, 'micromagnet': {6173}, 'materi': {6173}, '5': {6168}, 'independ': {6170, 6172}, 'larg': {6172}, 'magnitud': {6173}, 'element': {6170}, 'alon': {6173}, 'thorough': {6172}, 'satisfact': {6169}, 'dungeon': {6171}, 'idea': {6170}, 'ferromagnet': {6173}, 'core': {6168, 6169}, 'multihead': {6170}, 'across': {6173}, 'random': {6170}, 'mummergpu': {6172}, 'support': {6170}, 'howev': {6168, 6169, 6172}, 'recreat': {6171}, 'delay': {6173}, 'develop': {6170, 6173}, 'variat': {6172}, 'obviou': {6171}, 'divers': {6172}, 'complementari': {6173}, 'questionnair': {6169}, 'unrealist': {6170}, 'examin': {6170}, 'highli': {6168}, 'unpredict': {6168}, 'posit': {6169}, 'process': {6172}, 'implic': {6169, 6172}, 'make': {6170}, 'often': {6168, 6170}, 'world': {6171}, 'function': {6172}, 'wa': {6168, 6169}, 'parallel': {6170, 6172}, 'phenomena': {6173}, 'chiefli': {6168}, 'explor': {6169, 6172}, 'lower': {6173}, 'vocat': {6169}, 'intens': {6168}, 'adolesc': {6169}, 'neighbor': {6172}, 'astro': {6171}, 'report': {6168}, 'studi': {6169}, 'interfer': {6168}, 'block': {6172}, 'surfac': {6173}, 'achiev': {6169, 6173}, 'vr': {6171}, '7': {6168}, 'interconnect': {6173}, 'magnetoelectr': {6173}, 'mostli': {6171, 6173}, 'space': {6172}, 'diverg': {6172}, 'present': {6172}, 'ecolog': {6169}, 'befor': {6170}, 'broadli': {6168}, 'automot': {6168}, 'prototyp': {6171}, 'run': {6170}, 'beyond': {6173}, 'processor': {6168}, 'guarante': {6168}, 'best': {6168}, 'intern': {6169}, 'logic': {6173}, 'evid': {6168, 6170}, 'popular': {6171}, 'multicor': {6168}, 'text': {6171}, 'paradigm': {6170}, 'show': {6168, 6169, 6172}, 'techniqu': {6170}, 'data': {6168, 6170}, 'major': {6168}, 'rcd': {6170}, 'memori': {6168, 6170, 6172}, 'consist': {6168}, 'time': {6168, 6170, 6173}, 'activ': {6168, 6173}, 'sequenti': {6169}, 'non': {6171}, 'video': {6171}, 'pivot': {6169}, 'project': {6171}, 'especi': {6168, 6169}, 'mani': {6169}, 'two': {6169, 6170, 6171}, 'difficult': {6170}, 'disabl': {6168}, 'integr': {6168}, 'sort': {6169, 6170, 6172}, 'metaphor': {6171}, 'transpar': {6170}, 'class': {6170, 6173}, 'quit': {6171}, 'approach': {6172}, 'strict': {6168}, 'applic': {6168}, 'gener': {6170, 6172}, 'commun': {6168, 6171}, 'precaut': {6169}, 'magnetostrict': {6173}, 'electron': {6173}, 'oxid': {6173}, 'disk': {6170}, 'architect': {6172}, 'relat': {6169}, 'spl': {6171}, 'choic': {6172}, 'mud': {6171}, 'control': {6168}, 'due': {6168}, 'offer': {6170}, 'well': {6170}, 'school': {6169}, 'scheme': {6173}, 'certif': {6168}, 'still': {6172}, 'basic': {6169}, 'repres': {6172}, 'relationship': {6169}, 'ongo': {6173}, 'mean': {6172}, 'gpgpu': {6172}, 'problem': {6168, 6169}, 'seek': {6168}, 'experiment': {6170}, 'decis': {6169}, '50hz': {6168}, 'execut': {6168}, 'use': {6170, 6171, 6172}, 'astronomi': {6171}, 'analysi': {6170, 6172}, 'prove': {6170}, 'behavior': {6168, 6169, 6172}, 'energi': {6173}, 'variant': {6170}, 'suit': {6172}, 'supplier': {6168}, 'cycl': {6170}, 'agnost': {6172}, 'understand': {6168, 6172}, 'k': {6172}, 'promis': {6173}, 'known': {6170}, 'paramet': {6173}, 'practic': {6168, 6170}, 'parboil': {6172}, 'magnet': {6173}, 'conclud': {6173}, 'call': {6170}, 'semiconductor': {6173}, 'demonstr': {6173}, 'technolog': {6171}, 'challeng': {6168}, 'real': {6168, 6171}, 'made': {6172}, 'significantli': {6170}, 'improv': {6173}, 'profession': {6171}, 'multi': {6171}, '080': {6169}, 'environ': {6171}, 'incorpor': {6173}, 'determin': {6173}, 'upon': {6170}, 'choos': {6172}, 'shortcom': {6171}, 'addit': {6172}, 'research': {6168, 6171, 6172, 6173}, 'grow': {6172}, 'cuda': {6172}, 'switch': {6173}, 'current': {6168, 6171}, 'therein': {6169}, 'onli': {6169, 6171}, 'g': {6168, 6172}, 'virtual': {6171}, 'advantag': {6170}, 'simul': {6170, 6172, 6173}, 'correl': {6172}, 'spintron': {6173}, 'xerox': {6171}, 'array': {6172}, 'solut': {6168}, 'etx': {6171}, 'bosch': {6168}, 'thi': {6169, 6170, 6172}, 'characterist': {6172}, 'cumul': {6169}, 'therefor': {6169}, 'nvidia': {6172}, 'extern': {6169, 6170}, 'comput': {6168, 6170, 6171, 6172}, 'multipass': {6170}, 'nearest': {6172}, 'hierarchi': {6168}, 'purpos': {6172}, 'order': {6173}, 'interact': {6171}, 'e': {6168, 6172}, 'psycholog': {6169}, 'cluster': {6172}, 'interdepend': {6170}, 'play': {6169}, 'threshold': {6173}, '1': {6169, 6173}, 'provid': {6168, 6169, 6170, 6172}, 'analyz': {6168, 6172}, 'enhanc': {6170}, 'distribut': {6170}, 'high': {6168, 6172, 6173}, 'superposit': {6169}, 'keep': {6171}, 'also': {6169, 6170, 6172}, 'self': {6169}, 'pass': {6170}, 'aim': {6169}, 'adjac': {6173}, 'review': {6173}, 'spin': {6173}, 'set': {6171, 6172}, 'deep': {6168}, 'window': {6171}, 'model': {6169, 6170}, 'although': {6169}, 'field': {6173}, 'program': {6170}, 'role': {6169}, 'classifi': {6173}, 'branch': {6172}, 'rel': {6172, 6173}, 'score': {6172}, 'requir': {6168, 6173}, 'design': {6172}, 'social': {6171}, 'probabilist': {6170}, 'singl': {6169}, 'despit': {6171}, 'bound': {6168}, 'mechan': {6169}, 'similar': {6170, 6172}, 'critic': {6168}, 'task': {6168, 6170}, 'exhibit': {6172}, 'within': {6171}, 'ad': {6171}, 'neural': {6168}, 'st': {6173}, 'dimension': {6172}, 'experi': {6173}, 'meaning': {6172}, 'nanomagnet': {6173}, 'correct': {6171}, 'systemat': {6172}, 'base': {6169, 6170, 6171}, 'recent': {6173}, 'realist': {6170}, 'accord': {6173}, 'perform': {6168, 6170, 6172, 6173}, 'result': {6169, 6172, 6173}, 'simpl': {6170}, 'industri': {6168}, 'propos': {6170, 6172}, 'option': {6173}, 'numer': {6172}, 'avail': {6172}, 'sever': {6173}, 'valu': {6173}, 'expens': {6168}, 'appear': {6170}, 'scan': {6172}, 'system': {6168, 6171}, 'case': {6168}, 'benefit': {6172}, 'attract': {6173}, 'poor': {6168}, 'bia': {6173}, 'complex': {6169, 6170}, 'em': {6170}, 'reduct': {6170, 6172}, 'one': {6168, 6173}, 'novel': {6170}, 'seriou': {6168}, 'framework': {6173}, 'realiti': {6171}, 'user': {6171}, 'factor': {6169}, 'evalu': {6169, 6172}, 'mediat': {6169}, 'embed': {6168}, 'minu': {6171}, 'build': {6171}, 'influenc': {6169}, 'stress': {6172}, '8': {6168}, 'intervent': {6169}, 'second': {6170}, 'respect': {6169}, 'predict': {6168}, 'character': {6172}, 'devic': {6172, 6173}, 'oneout': {6168}, 'accur': {6172}, 'rodinia': {6172}, 'risk': {6169}, 'benchmark': {6172, 6173}, 'fewer': {6170}, 'emerg': {6168, 6172}, 'lack': {6172}, 'metal': {6173}, 'effect': {6169, 6173}, 'game': {6171}, 'differ': {6172}, 'survey': {6169}, 'power': {6171}, 'strength': {6171}, 'compar': {6172, 6173}, 'stand': {6173}, 'agil': {6168}, 'workload': {6168, 6172}, 'b': {6169}, 'optim': {6170}, 'safeti': {6168}, 'torqu': {6173}, 'audio': {6171}, 'metric': {6172}, 'goal': {6171}, 'number': {6168, 6172}, 'today': {6168}, 'parc': {6171}, 'extend': {6171}, 'kernel': {6172}, 'ani': {6170}, 'becaus': {6168}, 'algorithm': {6170}, 'expect': {6170}, 'import': {6168, 6170}, 'jupit': {6171}, 'investig': {6169}, 'exampl': {6168}, 'hard': {6168}, 'worst': {6168}, 'need': {6169}, 'ha': {6170, 6172}, 'hybrid': {6172}, 'secondari': {6169}, 'exchang': {6173}, 'share': {6168, 6171}, 'network': {6168, 6171}, 'complet': {6170}, 'extrem': {6168}, 'paper': {6170}, 'circuit': {6173}, 'coalesc': {6172}, 'dub': {6168}, 'subspac': {6172}, 'place': {6173}, 'aviat': {6168}, '6': {6168}, 'anisotropi': {6173}, '4': {6168}, 'platform': {6168}, 'specif': {6169, 6171}, 'microarchitectur': {6172}, 'intend': {6172}, 'underli': {6169}, 'previous': {6173}, 'gpu': {6172}, 'variou': {6173}, 'sdk': {6172}, 'access': {6170}})\n"
     ]
    }
   ],
   "source": [
    "search_engine = FastSearchEngine()\n",
    "all_docs = dict(zip(df.paperId,df.abstract))\n",
    "batch_size = 6\n",
    "docs_size = len(all_docs)\n",
    "\n",
    "for i in range(docs_size//batch_size):\n",
    "    batch = DocumentBatch(dict(itertools.islice(all_docs.items(), i*batch_size, (i+1)*batch_size)))\n",
    "    search_engine.add_batch(batch)\n",
    "    search_engine.end_of_day_logarithmic_merge()\n",
    "\n",
    "print(search_engine.main_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h1>Spell Correction (اصلاح پرسمان)</h1>\n",
    "<p>\n",
    "در بسیاری از اوقات پرسمان دادە شده توسط کاربر، ممکن است ناقص یا دارای غلط املایی باشد. برای رفع این مشکل در بسیاری از موتورهای جستجو راە حل هایی تدارک دیده شدە است. ابتدا این راە حل ها را شرح دهید و بیان کنید که یک موتور جست و جو بر چه اساسی پرسمان های اصلاح شده را به کاربر نمایش می دهد.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h2>پاسخ سوال بالا</h2>\n",
    "دو نوع اصلاح پرسمان وجود دارد. یکی  isolated word و دیگری contest-sensetive.\n",
    "\n",
    "حال ما در اینجا فقط از isolated word استفاده می‌کنیم. به این صورت که به ازای تک تک کلمات چک می‌کنیم که اگر آن کلمه در index وجود نداشته یا تعداد بسیار کمی وجود داشت با استفاده از روش k-gram لغات نزدیک به آن کلمه که دارای تعدادی بیشتری gram از حدی که مشخص کرده ایم داشت آن کلمات را به عنوان کاندیدا انتخاب می‌کنیم و سپس با روش edit distance آن کلماتی که ED کمتری داشتند را به کاربر معرفی می‌کنیم."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<p>\n",
    "    در این بخش، ابتدا با استفاده از روش bigram لغات نزدیک به لغات اصلی را پیدا کنید و در آخر با معیار minimum edit distance لغتی جایگزین را برای لغت مورد نظر پیدا کنید.  سپس برای هر پرسمان ورودی کاربر، در صورت اشتباه بودن آن، آن را تصحیح کنید. برای stopword‌ها نیز می‌توانید از لیست موجود که در قسمت‌های قبل ساختید استفاده کنید.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'$a': ['architectur', 'alon', 'across', 'adolesc', 'astro', 'achiev', 'automot', 'activ', 'approach', 'applic', 'architect', 'astronomi', 'analysi', 'agnost', 'addit', 'advantag', 'array', 'analyz', 'also', 'aim', 'adjac', 'although', 'ad', 'accord', 'avail', 'appear', 'attract', 'accur', 'agil', 'audio', 'ani', 'algorithm', 'aviat', 'anisotropi', 'access'], 'ar': ['architectur', 'larg', 'variat', 'complementari', 'parallel', 'guarante', 'popular', 'paradigm', 'transpar', 'architect', 'variant', 'paramet', 'parboil', 'research', 'array', 'characterist', 'nearest', 'hierarchi', 'similar', 'appear', 'character', 'benchmark', 'compar', 'parc', 'hard', 'secondari', 'share', 'microarchitectur', 'variou'], 'rc': ['architectur', 'interconnect', 'rcd', 'architect', 'research', 'hierarchi', 'parc', 'circuit', 'microarchitectur'], 'ch': ['architectur', 'chiefli', 'achiev', 'techniqu', 'approach', 'architect', 'choic', 'school', 'scheme', 'technolog', 'challeng', 'choos', 'research', 'switch', 'bosch', 'characterist', 'hierarchi', 'psycholog', 'branch', 'mechan', 'character', 'benchmark', 'exchang', 'microarchitectur'], 'hi': ['architectur', 'highli', 'chiefli', 'achiev', 'architect', 'relationship', 'thi', 'hierarchi', 'hierarchi', 'high', 'exhibit', 'within', 'microarchitectur'], 'it': ['architectur', 'magnitud', 'posit', 'quit', 'architect', 'suit', 'addit', 'switch', 'superposit', 'despit', 'critic', 'exhibit', 'within', 'benefit', 'realiti', 'algorithm', 'jupit', 'circuit', 'microarchitectur'], 'te': ['architectur', 'materi', 'often', 'intens', 'interfer', 'interconnect', 'guarante', 'intern', 'text', 'techniqu', 'integr', 'architect', 'technolog', 'determin', 'characterist', 'extern', 'interact', 'cluster', 'interdepend', 'systemat', 'system', 'intervent', 'character', 'extend', 'microarchitectur', 'intend'], 'ec': ['architectur', 'recreat', 'interconnect', 'magnetoelectr', 'ecolog', 'techniqu', 'project', 'especi', 'precaut', 'electron', 'architect', 'decis', 'execut', 'technolog', 'mechan', 'correct', 'recent', 'second', 'respect', 'effect', 'becaus', 'expect', 'secondari', 'specif', 'microarchitectur'], 'ct': ['architectur', 'satisfact', 'unpredict', 'function', 'interconnect', 'magnetoelectr', 'activ', 'project', 'strict', 'magnetostrict', 'electron', 'architect', 'practic', 'semiconductor', 'characterist', 'interact', 'correct', 'attract', 'reduct', 'factor', 'respect', 'predict', 'character', 'effect', 'expect', 'microarchitectur'], 'tu': ['architectur', 'magnitud', 'studi', 'virtual', 'microarchitectur'], 'ur': ['architectur', 'surfac', 'current', 'purpos', 'neural', 'accur', 'survey', 'microarchitectur'], 'r$': ['architectur', 'questionnair', 'explor', 'lower', 'neighbor', 'interfer', 'vr', 'magnetoelectr', 'befor', 'processor', 'popular', 'multicor', 'major', 'integr', 'metaphor', 'transpar', 'gener', 'offer', 'behavior', 'supplier', 'semiconductor', 'demonstr', 'incorpor', 'therefor', 'order', 'cluster', 'requir', 'similar', 'numer', 'sever', 'appear', 'poor', 'user', 'factor', 'character', 'accur', 'fewer', 'differ', 'power', 'compar', 'number', 'paper', 'microarchitectur'], '$m': ['may', 'micromagnet', 'materi', 'magnitud', 'multihead', 'mummergpu', 'make', 'magnetoelectr', 'mostli', 'multicor', 'major', 'memori', 'mani', 'metaphor', 'magnetostrict', 'mud', 'mean', 'magnet', 'made', 'multi', 'multipass', 'model', 'mechan', 'meaning', 'mediat', 'minu', 'metal', 'metric', 'microarchitectur'], 'ma': ['may', 'micromagnet', 'materi', 'magnitud', 'ferromagnet', 'make', 'magnetoelectr', 'major', 'mani', 'magnetostrict', 'magnet', 'made', 'nanomagnet', 'systemat', 'benchmark'], 'ay': ['may', 'delay', 'array', 'play', 'today'], 'y$': ['may', 'delay', 'array', 'play', 'survey', 'today'], '$2': ['2'], '2$': ['2'], 'mi': ['micromagnet', 'examin', 'astronomi', 'promis', 'semiconductor', 'determin', 'similar', 'minu', 'microarchitectur'], 'ic': ['micromagnet', 'unpredict', 'implic', 'logic', 'multicor', 'difficult', 'strict', 'applic', 'magnetostrict', 'choic', 'basic', 'practic', 'semiconductor', 'significantli', 'critic', 'predict', 'devic', 'metric', 'microarchitectur'], 'cr': ['micromagnet', 'across', 'recreat', 'critic', 'microarchitectur'], 'ro': ['micromagnet', 'thorough', 'ferromagnet', 'across', 'process', 'astro', 'broadli', 'prototyp', 'processor', 'project', 'approach', 'electron', 'control', 'problem', 'astronomi', 'prove', 'promis', 'improv', 'profession', 'environ', 'grow', 'spintron', 'xerox', 'provid', 'program', 'role', 'probabilist', 'propos', 'rodinia', 'anisotropi', 'microarchitectur'], 'om': ['micromagnet', 'ferromagnet', 'random', 'complementari', 'phenomena', 'automot', 'commun', 'astronomi', 'promis', 'shortcom', 'comput', 'nanomagnet', 'complex', 'compar', 'complet'], 'ag': ['micromagnet', 'magnitud', 'ferromagnet', 'magnetoelectr', 'magnetostrict', 'agnost', 'magnet', 'advantag', 'nanomagnet', 'agil'], 'gn': ['micromagnet', 'magnitud', 'ferromagnet', 'magnetoelectr', 'magnetostrict', 'agnost', 'magnet', 'significantli', 'design', 'nanomagnet'], 'ne': ['micromagnet', 'ferromagnet', 'neighbor', 'interconnect', 'magnetoelectr', 'gener', 'magnetostrict', 'energi', 'magnet', 'nearest', 'neural', 'nanomagnet', 'benefit', 'one', 'oneout', 'kernel', 'need', 'network'], 'et': ['micromagnet', 'ferromagnet', 'magnetoelectr', 'metaphor', 'magnetostrict', 'paramet', 'magnet', 'determin', 'etx', 'set', 'nanomagnet', 'metal', 'safeti', 'metric', 'network', 'complet'], 't$': ['micromagnet', 'element', 'satisfact', 'ferromagnet', 'support', 'recreat', 'variat', 'unrealist', 'unpredict', 'posit', 'vocat', 'report', 'interconnect', 'present', 'automot', 'best', 'text', 'consist', 'pivot', 'project', 'difficult', 'sort', 'quit', 'strict', 'precaut', 'magnetostrict', 'architect', 'relat', 'experiment', 'execut', 'variant', 'suit', 'agnost', 'paramet', 'magnet', 'addit', 'current', 'solut', 'characterist', 'comput', 'nearest', 'interact', 'distribut', 'superposit', 'set', 'probabilist', 'despit', 'exhibit', 'st', 'nanomagnet', 'correct', 'systemat', 'recent', 'realist', 'result', 'benefit', 'attract', 'reduct', 'mediat', 'intervent', 'respect', 'predict', 'oneout', 'effect', 'expect', 'import', 'jupit', 'worst', 'complet', 'circuit', 'aviat'], 'at': ['materi', 'satisfact', 'recreat', 'variat', 'vocat', 'data', 'relat', 'relationship', 'systemat', 'attract', 'mediat', 'aviat', 'platform'], 'er': ['materi', 'ferromagnet', 'mummergpu', 'divers', 'lower', 'interfer', 'interfer', 'interconnect', 'diverg', 'intern', 'gener', 'offer', 'certif', 'experiment', 'energi', 'supplier', 'understand', 'determin', 'therein', 'xerox', 'characterist', 'therefor', 'extern', 'hierarchi', 'order', 'interact', 'cluster', 'interdepend', 'superposit', 'experi', 'perform', 'numer', 'sever', 'seriou', 'user', 'intervent', 'character', 'fewer', 'emerg', 'differ', 'power', 'number', 'kernel', 'paper', 'underli'], 'ri': ['materi', 'variat', 'complementari', 'memori', 'strict', 'magnetostrict', 'experiment', 'variant', 'characterist', 'distribut', 'critic', 'experi', 'industri', 'seriou', 'risk', 'metric', 'algorithm', 'hybrid', 'secondari', 'variou'], 'i$': ['materi', 'complementari', 'highli', 'chiefli', 'studi', 'mostli', 'broadli', 'memori', 'sequenti', 'especi', 'mani', 'astronomi', 'analysi', 'energi', 'significantli', 'multi', 'onli', 'thi', 'hierarchi', 'classifi', 'experi', 'industri', 'realiti', 'safeti', 'ani', 'secondari', 'anisotropi', 'underli'], '$5': ['5', '50hz'], '5$': ['5'], '$i': ['independ', 'idea', 'implic', 'intens', 'interfer', 'interconnect', 'intern', 'integr', 'improv', 'incorpor', 'interact', 'interdepend', 'industri', 'influenc', 'intervent', 'import', 'investig', 'intend'], 'in': ['independ', 'examin', 'intens', 'interfer', 'interconnect', 'intern', 'integr', 'incorpor', 'determin', 'therein', 'spintron', 'interact', 'interdepend', 'spin', 'window', 'singl', 'within', 'meaning', 'industri', 'minu', 'influenc', 'intervent', 'rodinia', 'investig', 'intend'], 'nd': ['independ', 'independ', 'random', 'beyond', 'understand', 'understand', 'semiconductor', 'interdepend', 'window', 'bound', 'industri', 'second', 'stand', 'extend', 'secondari', 'intend', 'underli'], 'de': ['independ', 'idea', 'delay', 'develop', 'video', 'decis', 'understand', 'demonstr', 'made', 'determin', 'order', 'interdepend', 'deep', 'model', 'design', 'despit', 'devic', 'underli'], 'ep': ['independ', 'report', 'repres', 'interdepend', 'keep', 'deep'], 'pe': ['independ', 'especi', 'experiment', 'interdepend', 'superposit', 'experi', 'perform', 'expens', 'appear', 'respect', 'expect', 'paper', 'specif'], 'en': ['independ', 'element', 'complementari', 'often', 'phenomena', 'phenomena', 'intens', 'present', 'sequenti', 'gener', 'experiment', 'energi', 'challeng', 'environ', 'current', 'interdepend', 'enhanc', 'dimension', 'recent', 'expens', 'benefit', 'influenc', 'intervent', 'benchmark', 'strength', 'extend', 'intend'], 'd$': ['independ', 'magnitud', 'multihead', 'world', 'beyond', 'evid', 'rcd', 'oxid', 'mud', 'understand', 'conclud', 'interdepend', 'threshold', 'provid', 'field', 'bound', 'ad', 'accord', 'embed', 'build', 'second', 'stand', 'workload', 'extend', 'hard', 'need', 'hybrid', 'intend'], '$l': ['larg', 'lower', 'logic', 'lack'], 'la': ['larg', 'delay', 'popular', 'class', 'relat', 'relationship', 'play', 'classifi', 'similar', 'lack', 'place', 'platform'], 'rg': ['larg', 'mummergpu', 'diverg', 'energi', 'emerg'], 'g$': ['larg', 'diverg', 'ecolog', 'technolog', 'challeng', 'g', 'advantag', 'psycholog', 'meaning', 'emerg', 'investig', 'exchang'], 'ni': ['magnitud', 'techniqu', 'mani', 'significantli', 'meaning', 'rodinia', 'ani', 'anisotropi'], 'ud': ['magnitud', 'studi', 'mud', 'conclud', 'cuda', 'audio'], '$e': ['element', 'examin', 'explor', 'ecolog', 'evid', 'especi', 'electron', 'experiment', 'execut', 'energi', 'environ', 'etx', 'extern', 'e', 'enhanc', 'exhibit', 'experi', 'expens', 'em', 'evalu', 'embed', 'emerg', 'effect', 'extend', 'expect', 'exampl', 'exchang', 'extrem'], 'el': ['element', 'delay', 'develop', 'parallel', 'magnetoelectr', 'electron', 'relat', 'well', 'relationship', 'correl', 'self', 'model', 'field', 'rel', 'novel', 'kernel'], 'le': ['element', 'complementari', 'parallel', 'adolesc', 'magnetoelectr', 'electron', 'problem', 'challeng', 'role', 'complex', 'complet', 'coalesc'], 'em': ['element', 'complementari', 'memori', 'scheme', 'problem', 'semiconductor', 'demonstr', 'systemat', 'system', 'em', 'embed', 'emerg', 'extrem'], 'me': ['element', 'mummergpu', 'complementari', 'phenomena', 'memori', 'time', 'metaphor', 'scheme', 'mean', 'experiment', 'paramet', 'mechan', 'dimension', 'meaning', 'numer', 'framework', 'mediat', 'emerg', 'metal', 'game', 'metric'], 'nt': ['element', 'complementari', 'intens', 'interfer', 'interconnect', 'present', 'guarante', 'intern', 'sequenti', 'integr', 'control', 'experiment', 'variant', 'significantli', 'current', 'advantag', 'spintron', 'interact', 'interdepend', 'recent', 'intervent', 'intervent', 'intend'], 'al': ['alon', 'unrealist', 'parallel', 'analysi', 'call', 'challeng', 'real', 'virtual', 'analyz', 'also', 'although', 'social', 'neural', 'realist', 'valu', 'realiti', 'evalu', 'metal', 'goal', 'algorithm', 'coalesc'], 'lo': ['alon', 'develop', 'explor', 'lower', 'block', 'ecolog', 'logic', 'technolog', 'psycholog', 'workload'], 'on': ['alon', 'dungeon', 'questionnair', 'function', 'interconnect', 'beyond', 'consist', 'non', 'electron', 'control', 'relationship', 'ongo', 'astronomi', 'conclud', 'semiconductor', 'demonstr', 'profession', 'environ', 'upon', 'onli', 'spintron', 'dimension', 'option', 'one', 'second', 'oneout', 'secondari'], 'n$': ['alon', 'dungeon', 'examin', 'often', 'function', 'run', 'intern', 'non', 'commun', 'electron', 'mean', 'known', 'profession', 'environ', 'determin', 'upon', 'therein', 'spintron', 'extern', 'spin', 'design', 'mechan', 'within', 'dimension', 'option', 'scan'], '$t': ['thorough', 'text', 'techniqu', 'time', 'two', 'transpar', 'technolog', 'therein', 'thi', 'therefor', 'threshold', 'task', 'torqu', 'today'], 'th': ['thorough', 'therein', 'thi', 'therefor', 'threshold', 'although', 'within', 'strength', 'algorithm'], 'ho': ['thorough', 'howev', 'show', 'metaphor', 'choic', 'school', 'choos', 'shortcom', 'psycholog', 'threshold', 'although'], 'or': ['thorough', 'core', 'support', 'world', 'explor', 'neighbor', 'report', 'befor', 'processor', 'multicor', 'major', 'memori', 'sort', 'metaphor', 'behavior', 'semiconductor', 'incorpor', 'incorpor', 'shortcom', 'correl', 'therefor', 'order', 'score', 'correct', 'accord', 'perform', 'poor', 'framework', 'factor', 'workload', 'torqu', 'algorithm', 'import', 'worst', 'network', 'platform'], 'ou': ['thorough', 'obviou', 'although', 'bound', 'seriou', 'oneout', 'previous', 'variou'], 'ug': ['thorough', 'although'], 'gh': ['thorough', 'highli', 'neighbor', 'high', 'although'], 'h$': ['thorough', 'approach', 'research', 'switch', 'bosch', 'high', 'although', 'branch', 'strength'], '$s': ['satisfact', 'support', 'studi', 'surfac', 'space', 'show', 'sequenti', 'sort', 'strict', 'spl', 'school', 'scheme', 'still', 'seek', 'suit', 'supplier', 'semiconductor', 'significantli', 'shortcom', 'switch', 'simul', 'spintron', 'solut', 'superposit', 'self', 'spin', 'set', 'score', 'social', 'singl', 'similar', 'st', 'systemat', 'simpl', 'sever', 'scan', 'system', 'seriou', 'stress', 'second', 'survey', 'strength', 'stand', 'safeti', 'secondari', 'share', 'subspac', 'specif', 'sdk'], 'sa': ['satisfact', 'disabl', 'safeti'], 'ti': ['satisfact', 'multihead', 'questionnair', 'function', 'multicor', 'time', 'activ', 'sequenti', 'certif', 'still', 'relationship', 'practic', 'multi', 'multipass', 'critic', 'option', 'realiti', 'optim', 'safeti', 'investig'], 'is': ['satisfact', 'unrealist', 'consist', 'disabl', 'disk', 'decis', 'promis', 'characterist', 'distribut', 'probabilist', 'realist', 'risk', 'anisotropi'], 'sf': ['satisfact'], 'fa': ['satisfact', 'surfac', 'factor'], 'ac': ['satisfact', 'across', 'surfac', 'achiev', 'space', 'activ', 'approach', 'practic', 'characterist', 'interact', 'adjac', 'accord', 'attract', 'factor', 'character', 'accur', 'lack', 'subspac', 'place', 'access'], '$d': ['dungeon', 'delay', 'develop', 'divers', 'diverg', 'data', 'difficult', 'disabl', 'disk', 'due', 'decis', 'demonstr', 'determin', 'distribut', 'deep', 'design', 'despit', 'dimension', 'devic', 'differ', 'dub'], 'du': ['dungeon', 'due', 'semiconductor', 'industri', 'reduct', 'dub'], 'un': ['dungeon', 'unrealist', 'unpredict', 'function', 'run', 'commun', 'understand', 'bound', 'underli'], 'ng': ['dungeon', 'ongo', 'challeng', 'singl', 'meaning', 'strength', 'exchang'], 'ge': ['dungeon', 'gener'], 'eo': ['dungeon', 'video', 'oneout'], 'id': ['idea', 'evid', 'video', 'oxid', 'nvidia', 'provid', 'hybrid'], 'ea': ['idea', 'multihead', 'recreat', 'unrealist', 'mean', 'real', 'research', 'nearest', 'meaning', 'realist', 'appear', 'realiti'], 'a$': ['idea', 'wa', 'phenomena', 'data', 'cuda', 'nvidia', 'bia', 'rodinia', 'ha'], '$f': ['ferromagnet', 'function', 'field', 'framework', 'factor', 'fewer'], 'fe': ['ferromagnet', 'interfer', 'offer', 'profession', 'fewer', 'effect', 'differ', 'safeti'], 'rr': ['ferromagnet', 'current', 'correl', 'array', 'correct'], '$c': ['core', 'complementari', 'chiefli', 'consist', 'class', 'commun', 'choic', 'control', 'certif', 'cycl', 'conclud', 'call', 'challeng', 'choos', 'cuda', 'current', 'correl', 'characterist', 'cumul', 'comput', 'cluster', 'classifi', 'critic', 'correct', 'case', 'complex', 'character', 'compar', 'complet', 'circuit', 'coalesc'], 'co': ['core', 'complementari', 'interconnect', 'ecolog', 'multicor', 'consist', 'commun', 'control', 'conclud', 'semiconductor', 'incorpor', 'shortcom', 'correl', 'comput', 'score', 'correct', 'accord', 'complex', 'second', 'compar', 'secondari', 'complet', 'coalesc'], 're': ['core', 'recreat', 'recreat', 'unrealist', 'unpredict', 'report', 'present', 'precaut', 'relat', 'repres', 'repres', 'relationship', 'real', 'research', 'current', 'therein', 'correl', 'therefor', 'nearest', 'threshold', 'review', 'rel', 'score', 'requir', 'correct', 'recent', 'realist', 'result', 'reduct', 'realiti', 'stress', 'respect', 'predict', 'strength', 'share', 'extrem', 'previous'], 'e$': ['core', 'make', 'space', 'guarante', 'time', 'due', 'scheme', 'use', 'prove', 'made', 'e', 'role', 'score', 'base', 'case', 'one', 'game', 'share', 'place'], 'mu': ['multihead', 'mummergpu', 'multicor', 'commun', 'mud', 'multi', 'simul', 'cumul', 'multipass'], 'ul': ['multihead', 'popular', 'multicor', 'difficult', 'multi', 'simul', 'cumul', 'multipass', 'result'], 'lt': ['multihead', 'multicor', 'difficult', 'multi', 'multipass', 'although', 'result'], 'ih': ['multihead'], 'he': ['multihead', 'phenomena', 'scheme', 'therein', 'therefor'], 'ad': ['multihead', 'adolesc', 'broadli', 'paradigm', 'made', 'addit', 'advantag', 'adjac', 'ad', 'workload'], 'os': ['across', 'posit', 'mostli', 'magnetostrict', 'agnost', 'choos', 'bosch', 'purpos', 'superposit', 'propos'], 'ss': ['across', 'process', 'processor', 'class', 'profession', 'multipass', 'pass', 'classifi', 'stress', 'access'], 's$': ['across', 'divers', 'process', 'intens', 'class', 'repres', 'decis', 'promis', 'choos', 'multipass', 'purpos', 'pass', 'propos', 'expens', 'stress', 'becaus', 'previous', 'access'], '$r': ['random', 'recreat', 'report', 'run', 'rcd', 'relat', 'repres', 'relationship', 'real', 'research', 'review', 'role', 'rel', 'requir', 'recent', 'realist', 'result', 'reduct', 'realiti', 'respect', 'rodinia', 'risk'], 'ra': ['random', 'parallel', 'guarante', 'paradigm', 'transpar', 'paramet', 'practic', 'array', 'characterist', 'hierarchi', 'interact', 'program', 'branch', 'neural', 'attract', 'framework', 'character'], 'an': ['random', 'guarante', 'mani', 'transpar', 'mean', 'analysi', 'variant', 'understand', 'significantli', 'advantag', 'analyz', 'enhanc', 'branch', 'mechan', 'meaning', 'nanomagnet', 'scan', 'stand', 'ani', 'exchang', 'anisotropi'], 'do': ['random', 'adolesc', 'window'], 'm$': ['random', 'paradigm', 'problem', 'shortcom', 'aim', 'program', 'perform', 'system', 'em', 'optim', 'algorithm', 'extrem', 'platform'], 'um': ['mummergpu', 'cumul', 'numer', 'number'], 'mm': ['mummergpu', 'commun'], 'gp': ['mummergpu', 'gpgpu', 'gpgpu', 'gpu'], 'pu': ['mummergpu', 'popular', 'gpgpu', 'comput', 'purpos', 'gpu'], 'u$': ['mummergpu', 'obviou', 'techniqu', 'gpgpu', 'valu', 'seriou', 'evalu', 'minu', 'torqu', 'gpu', 'variou'], 'su': ['support', 'surfac', 'suit', 'supplier', 'superposit', 'result', 'survey', 'subspac'], 'up': ['support', 'supplier', 'upon', 'superposit', 'jupit'], 'pp': ['support', 'approach', 'applic', 'supplier', 'appear'], 'po': ['support', 'posit', 'report', 'popular', 'incorpor', 'upon', 'purpos', 'superposit', 'propos', 'poor', 'power', 'import'], 'rt': ['support', 'report', 'sort', 'certif', 'shortcom', 'virtual', 'import'], '$h': ['howev', 'highli', 'hierarchi', 'high', 'hard', 'ha', 'hybrid'], 'ow': ['howev', 'lower', 'show', 'known', 'grow', 'window', 'power'], 'we': ['howev', 'lower', 'well', 'fewer', 'power'], 'ev': ['howev', 'develop', 'achiev', 'evid', 'review', 'sever', 'evalu', 'devic', 'previous'], 'v$': ['howev', 'achiev', 'activ', 'improv'], 've': ['develop', 'divers', 'diverg', 'prove', 'sever', 'novel', 'intervent', 'survey', 'investig'], 'op': ['develop', 'popular', 'propos', 'option', 'optim', 'anisotropi'], 'p$': ['develop', 'prototyp', 'relationship', 'keep', 'deep'], '$v': ['variat', 'vocat', 'vr', 'video', 'variant', 'virtual', 'valu', 'variou'], 'va': ['variat', 'variant', 'advantag', 'avail', 'valu', 'evalu', 'variou'], 'ia': ['variat', 'variant', 'nvidia', 'social', 'bia', 'mediat', 'rodinia', 'aviat'], '$o': ['obviou', 'often', 'oxid', 'offer', 'ongo', 'onli', 'order', 'option', 'one', 'oneout', 'optim'], 'ob': ['obviou', 'problem', 'probabilist'], 'bv': ['obviou'], 'vi': ['obviou', 'evid', 'video', 'behavior', 'environ', 'virtual', 'nvidia', 'provid', 'review', 'devic', 'aviat', 'previous'], 'io': ['obviou', 'questionnair', 'function', 'relationship', 'behavior', 'profession', 'dimension', 'option', 'seriou', 'audio', 'previous', 'variou'], 'di': ['divers', 'unpredict', 'studi', 'diverg', 'paradigm', 'difficult', 'disabl', 'disk', 'addit', 'nvidia', 'distribut', 'dimension', 'mediat', 'predict', 'rodinia', 'differ', 'audio'], 'iv': ['divers', 'diverg', 'activ', 'pivot'], 'rs': ['divers', 'understand', 'worst'], 'mp': ['complementari', 'implic', 'improv', 'comput', 'simpl', 'complex', 'compar', 'import', 'exampl', 'complet'], 'pl': ['complementari', 'implic', 'explor', 'applic', 'spl', 'supplier', 'play', 'simpl', 'complex', 'exampl', 'complet', 'place', 'platform'], 'ta': ['complementari', 'data', 'metaphor', 'understand', 'advantag', 'task', 'metal', 'stand'], '$q': ['questionnair', 'quit'], 'qu': ['questionnair', 'techniqu', 'sequenti', 'quit', 'requir', 'torqu'], 'ue': ['questionnair', 'sequenti', 'due', 'influenc'], 'es': ['questionnair', 'process', 'adolesc', 'present', 'processor', 'best', 'especi', 'repres', 'profession', 'research', 'nearest', 'threshold', 'design', 'despit', 'result', 'stress', 'respect', 'investig', 'coalesc', 'access'], 'st': ['questionnair', 'unrealist', 'astro', 'studi', 'mostli', 'best', 'consist', 'strict', 'magnetostrict', 'still', 'astronomi', 'agnost', 'understand', 'demonstr', 'characterist', 'nearest', 'cluster', 'distribut', 'probabilist', 'st', 'systemat', 'realist', 'industri', 'system', 'stress', 'strength', 'stand', 'investig', 'worst'], 'nn': ['questionnair', 'interconnect'], 'na': ['questionnair', 'phenomena', 'analysi', 'analyz', 'nanomagnet'], 'ai': ['questionnair', 'aim', 'avail'], 'ir': ['questionnair', 'environ', 'virtual', 'requir', 'circuit'], '$u': ['unrealist', 'unpredict', 'use', 'understand', 'upon', 'user', 'underli'], 'nr': ['unrealist'], 'li': ['unrealist', 'highli', 'implic', 'chiefli', 'mostli', 'broadli', 'applic', 'supplier', 'significantli', 'onli', 'probabilist', 'realist', 'realiti', 'underli'], 'ex': ['examin', 'explor', 'text', 'experiment', 'execut', 'extern', 'exhibit', 'experi', 'expens', 'complex', 'extend', 'expect', 'exampl', 'exchang', 'extrem'], 'xa': ['examin', 'exampl'], 'am': ['examin', 'paramet', 'program', 'framework', 'game', 'exampl'], 'ig': ['highli', 'neighbor', 'paradigm', 'significantli', 'high', 'design', 'investig'], 'hl': ['highli'], 'np': ['unpredict'], 'pr': ['unpredict', 'process', 'present', 'prototyp', 'processor', 'project', 'approach', 'precaut', 'repres', 'problem', 'prove', 'promis', 'practic', 'improv', 'profession', 'provid', 'program', 'probabilist', 'propos', 'predict', 'previous'], 'ed': ['unpredict', 'reduct', 'mediat', 'embed', 'predict', 'need'], '$p': ['posit', 'process', 'parallel', 'phenomena', 'present', 'prototyp', 'processor', 'popular', 'paradigm', 'pivot', 'project', 'precaut', 'problem', 'prove', 'promis', 'paramet', 'practic', 'parboil', 'profession', 'purpos', 'psycholog', 'play', 'provid', 'pass', 'program', 'probabilist', 'perform', 'propos', 'poor', 'predict', 'power', 'parc', 'paper', 'place', 'platform', 'previous'], 'si': ['posit', 'consist', 'basic', 'analysi', 'significantli', 'profession', 'simul', 'superposit', 'classifi', 'design', 'singl', 'similar', 'dimension', 'simpl'], 'oc': ['process', 'vocat', 'block', 'processor', 'social'], 'ce': ['process', 'space', 'processor', 'certif', 'recent', 'place', 'access'], 'im': ['implic', 'time', 'experiment', 'improv', 'simul', 'aim', 'similar', 'dimension', 'simpl', 'optim', 'import'], 'c$': ['implic', 'adolesc', 'surfac', 'logic', 'applic', 'choic', 'basic', 'practic', 'enhanc', 'adjac', 'critic', 'influenc', 'devic', 'metric', 'parc', 'coalesc', 'subspac'], 'ak': ['make'], 'ke': ['make', 'keep', 'kernel'], 'of': ['often', 'offer', 'profession'], 'ft': ['often'], '$w': ['world', 'wa', 'well', 'window', 'within', 'workload', 'worst'], 'wo': ['world', 'two', 'framework', 'workload', 'worst', 'network'], 'rl': ['world', 'underli'], 'ld': ['world', 'threshold', 'field', 'build'], 'fu': ['function'], 'nc': ['function', 'conclud', 'incorpor', 'enhanc', 'branch', 'influenc', 'benchmark'], 'wa': ['wa'], 'pa': ['parallel', 'space', 'paradigm', 'transpar', 'paramet', 'parboil', 'multipass', 'pass', 'compar', 'parc', 'paper', 'subspac'], 'll': ['parallel', 'well', 'still', 'call', 'challeng'], 'l$': ['parallel', 'disabl', 'spl', 'control', 'well', 'school', 'still', 'cycl', 'parboil', 'call', 'real', 'virtual', 'simul', 'correl', 'cumul', 'model', 'rel', 'social', 'singl', 'neural', 'simpl', 'avail', 'novel', 'metal', 'agil', 'goal', 'kernel', 'exampl'], 'ph': ['phenomena', 'metaphor'], 'no': ['phenomena', 'non', 'astronomi', 'agnost', 'known', 'technolog', 'nanomagnet', 'novel'], 'ie': ['chiefli', 'achiev', 'supplier', 'hierarchi', 'review', 'field'], 'ef': ['chiefli', 'befor', 'therefor', 'benefit', 'effect'], 'fl': ['chiefli', 'influenc'], 'xp': ['explor', 'experiment', 'experi', 'expens', 'expect'], 'vo': ['vocat', 'pivot'], 'ca': ['vocat', 'precaut', 'call', 'significantli', 'scan', 'case', 'becaus'], 'ns': ['intens', 'consist', 'transpar', 'relationship', 'demonstr', 'dimension', 'expens'], 'ol': ['adolesc', 'ecolog', 'control', 'school', 'technolog', 'solut', 'psycholog', 'threshold', 'role'], 'sc': ['adolesc', 'school', 'scheme', 'bosch', 'score', 'scan', 'coalesc'], '$n': ['neighbor', 'non', 'nvidia', 'nearest', 'neural', 'nanomagnet', 'numer', 'novel', 'number', 'need', 'network'], 'ei': ['neighbor', 'therein'], 'hb': ['neighbor'], 'bo': ['neighbor', 'parboil', 'bosch', 'bound'], 'as': ['astro', 'class', 'basic', 'astronomi', 'multipass', 'pass', 'classifi', 'task', 'base', 'case'], 'tr': ['astro', 'magnetoelectr', 'transpar', 'strict', 'magnetostrict', 'electron', 'control', 'astronomi', 'demonstr', 'spintron', 'distribut', 'industri', 'attract', 'stress', 'strength', 'metric', 'extrem', 'anisotropi'], 'o$': ['astro', 'video', 'two', 'ongo', 'also', 'audio'], 'rf': ['interfer', 'surfac', 'perform'], '$b': ['block', 'befor', 'broadli', 'beyond', 'best', 'basic', 'behavior', 'bosch', 'branch', 'bound', 'base', 'benefit', 'bia', 'build', 'benchmark', 'b', 'becaus'], 'bl': ['block', 'disabl', 'problem'], 'ck': ['block', 'lack'], 'k$': ['block', 'disk', 'seek', 'k', 'task', 'framework', 'risk', 'benchmark', 'lack', 'network', 'sdk'], 'vr': ['vr'], '$7': ['7'], '7$': ['7'], 'to': ['magnetoelectr', 'automot', 'prototyp', 'magnetostrict', 'semiconductor', 'factor', 'torqu', 'today'], 'oe': ['magnetoelectr'], 'mo': ['mostli', 'automot', 'memori', 'demonstr', 'model'], 'tl': ['mostli', 'significantli'], 'sp': ['space', 'especi', 'transpar', 'spl', 'spintron', 'spin', 'despit', 'respect', 'subspac', 'specif'], 'se': ['present', 'sequenti', 'seek', 'use', 'semiconductor', 'research', 'self', 'set', 'base', 'sever', 'case', 'seriou', 'user', 'second', 'secondari'], 'og': ['ecolog', 'logic', 'technolog', 'psycholog', 'program'], 'be': ['befor', 'beyond', 'best', 'behavior', 'benefit', 'embed', 'benchmark', 'number', 'becaus'], 'fo': ['befor', 'therefor', 'perform', 'platform'], 'br': ['broadli', 'branch', 'hybrid'], 'oa': ['broadli', 'approach', 'workload', 'goal', 'coalesc', 'microarchitectur'], 'dl': ['broadli'], 'au': ['automot', 'precaut', 'audio', 'becaus'], 'ut': ['automot', 'precaut', 'execut', 'solut', 'comput', 'distribut', 'oneout'], 'ot': ['automot', 'prototyp', 'prototyp', 'pivot', 'anisotropi'], 'ty': ['prototyp'], 'yp': ['prototyp'], 'ru': ['run'], 'ey': ['beyond', 'survey'], 'yo': ['beyond'], 'so': ['processor', 'sort', 'solut', 'also', 'social', 'anisotropi'], '$g': ['guarante', 'gener', 'gpgpu', 'grow', 'g', 'game', 'goal', 'gpu'], 'gu': ['guarante'], 'ua': ['guarante', 'virtual'], 'rn': ['intern', 'extern', 'kernel'], 'gi': ['logic', 'energi', 'agil'], 'xt': ['text', 'extern', 'extend', 'extrem'], 'gm': ['paradigm'], 'sh': ['show', 'relationship', 'shortcom', 'threshold', 'share'], 'w$': ['show', 'grow', 'review', 'window'], 'hn': ['techniqu', 'technolog'], 'iq': ['techniqu'], 'da': ['data', 'cuda', 'today', 'secondari'], 'aj': ['major'], 'jo': ['major'], 'cd': ['rcd'], 'eq': ['sequenti', 'requir'], 'pi': ['pivot', 'spintron', 'spin', 'despit', 'jupit', 'anisotropi'], 'oj': ['project'], 'je': ['project'], 'ci': ['especi', 'decis', 'social', 'circuit', 'specif'], 'tw': ['two', 'network'], 'if': ['difficult', 'certif', 'significantli', 'classifi', 'differ', 'specif'], 'ff': ['difficult', 'offer', 'effect', 'differ'], 'fi': ['difficult', 'significantli', 'field', 'classifi', 'benefit'], 'cu': ['difficult', 'execut', 'cuda', 'current', 'cumul', 'accur', 'circuit'], 'ab': ['disabl', 'probabilist'], 'eg': ['integr'], 'gr': ['integr', 'grow', 'program'], 'ap': ['metaphor', 'approach', 'applic', 'appear', 'paper'], 'cl': ['class', 'cycl', 'conclud', 'cluster', 'classifi'], 'ui': ['quit', 'suit', 'requir', 'build', 'circuit'], 'ox': ['oxid', 'xerox'], 'xi': ['oxid'], 'sk': ['disk', 'task', 'risk'], 'oi': ['choic', 'parboil'], 'oo': ['school', 'choos', 'poor'], 'f$': ['certif', 'self', 'specif'], 'il': ['still', 'parboil', 'probabilist', 'similar', 'avail', 'build', 'agil'], 'ba': ['basic', 'probabilist', 'base'], 'ip': ['relationship', 'multipass'], 'go': ['ongo', 'goal', 'algorithm'], 'pg': ['gpgpu'], 'ee': ['seek', 'keep', 'deep', 'need'], 'ek': ['seek'], '50': ['50hz'], '0h': ['50hz'], 'hz': ['50hz'], 'z$': ['50hz', 'analyz'], 'xe': ['execut', 'xerox'], 'us': ['use', 'cluster', 'industri', 'user', 'becaus', 'previous'], 'ly': ['analysi', 'analyz'], 'ys': ['analysi', 'systemat', 'system'], 'ov': ['prove', 'improv', 'provid', 'novel'], 'eh': ['behavior'], 'ha': ['behavior', 'challeng', 'characterist', 'enhanc', 'mechan', 'character', 'hard', 'ha', 'exchang', 'share'], 'av': ['behavior', 'avail', 'aviat'], 'cy': ['cycl'], 'yc': ['cycl', 'psycholog'], '$k': ['k', 'known', 'keep', 'kernel'], 'kn': ['known'], 'wn': ['known'], 'rb': ['parboil'], 'lu': ['conclud', 'solut', 'cluster', 'valu', 'evalu', 'influenc'], 'uc': ['semiconductor', 'reduct'], '$0': ['080'], '08': ['080'], '80': ['080'], '0$': ['080'], 'nv': ['environ', 'nvidia', 'investig'], 'rp': ['incorpor', 'purpos', 'superposit'], 'rm': ['determin', 'perform', 'platform'], 'tc': ['shortcom', 'switch'], 'dd': ['addit'], 'sw': ['switch'], 'wi': ['switch', 'window', 'within'], 'nl': ['onli'], 'dv': ['advantag'], '$x': ['xerox'], 'x$': ['xerox', 'etx', 'complex'], 'tx': ['etx'], 'rd': ['order', 'interdepend', 'accord', 'hard'], 'ps': ['psycholog'], 'sy': ['psycholog', 'systemat', 'system'], 'hr': ['threshold'], '$1': ['1'], '1$': ['1'], 'yz': ['analyz'], 'nh': ['enhanc'], 'ib': ['distribut', 'exhibit'], 'bu': ['distribut', 'build'], 'ls': ['also'], 'lf': ['self'], 'dj': ['adjac'], 'ja': ['adjac'], 'ew': ['review', 'framework', 'fewer'], 'od': ['model', 'rodinia', 'today'], 'bi': ['probabilist', 'exhibit', 'bia'], 'gl': ['singl'], 'xh': ['exhibit'], 'eu': ['neural'], 'cc': ['accord', 'accur', 'access'], 'pt': ['option', 'optim'], 'nu': ['numer', 'minu', 'number'], 'tt': ['attract'], 'fr': ['framework'], 'rk': ['framework', 'benchmark', 'workload', 'network'], 'mb': ['embed', 'number'], 'nf': ['influenc'], '$8': ['8'], '8$': ['8'], 'rv': ['intervent', 'survey'], 'hm': ['benchmark', 'algorithm'], 'ga': ['game'], 'gt': ['strength'], 'kl': ['workload'], 'b$': ['b', 'dub'], 'af': ['safeti'], 'rq': ['torqu'], 'lg': ['algorithm'], '$j': ['jupit'], 'ju': ['jupit'], 'hy': ['hybrid'], 'yb': ['hybrid'], 'xc': ['exchang'], 'ub': ['dub', 'subspac'], 'bs': ['subspac'], '$6': ['6'], '6$': ['6'], '$4': ['4'], '4$': ['4'], 'tf': ['platform'], 'sd': ['sdk'], 'dk': ['sdk']}\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "def create_bigram_word(word):\n",
    "    if len(word) == 0:\n",
    "        return []\n",
    "\n",
    "    bigrams = ['$' + word[0]]\n",
    "    for i in range(len(word)-1):\n",
    "        bigrams.append(word[i:i+2])\n",
    "    bigrams.append(word[-1] + '$')\n",
    "    return bigrams\n",
    "\n",
    "def create_bigram_index(words: List[str]):\n",
    "    \"\"\"\n",
    "    Creates a bigram index for the spell correction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary of bigrams and their occurence\n",
    "    \"\"\"\n",
    "    bigrams = {}\n",
    "    for word in words:\n",
    "        word_bigram = create_bigram_word(word)\n",
    "        for bigram in word_bigram:\n",
    "            if bigram not in bigrams:\n",
    "                bigrams[bigram] = []\n",
    "            bigrams[bigram].append(word)\n",
    "\n",
    "    return bigrams\n",
    "\n",
    "bigram_index = create_bigram_index(search_engine.main_index.keys())\n",
    "print(bigram_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world is the most posit posit larg '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spell_correction(query):\n",
    "  \"\"\"\n",
    "    Correct the give query text, if it is misspelled\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    query: str\n",
    "        The query text\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    corrected_query: str\n",
    "        The corrected text\n",
    "    \"\"\"\n",
    "  query = preprocessor.preprocess(query, is_query=True)\n",
    "  corrected_query = \"\"\n",
    "  for word in query:\n",
    "    if word in search_engine.main_index or word in preprocessor.stopwords:\n",
    "      corrected_query += word + \" \"\n",
    "      continue\n",
    "\n",
    "    bigram_word = create_bigram_index([word])\n",
    "    min_diff = 1000\n",
    "    max_similarity_word = \"\"\n",
    "    for bigram in bigram_word:\n",
    "      if bigram in bigram_index:\n",
    "        for word in bigram_index[bigram]:\n",
    "          diff = edit_distance(word, word)\n",
    "          if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            max_similarity_word = word\n",
    "\n",
    "    corrected_query += max_similarity_word + \" \"\n",
    "  \n",
    "\n",
    "  return corrected_query\n",
    "\n",
    "# Example usage\n",
    "user_query = \"Wht is the most populr progarmming lanuage?\"\n",
    "spell_correction(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h1> Boolean Retrieval </h1>\n",
    "<p>\n",
    " در این قسمت هدف طراحی یک سامانەی بازیابی اطلاعات boolean می‌باشد. \n",
    "\n",
    "برای این کار ابتدا پیش پردازش‌های مورد نیاز را مانند بخش قبل بر روی متون انجام دهید و در مرحله بعد ماتریس doc−term را ایجاد کنید. در نهایت کلاس BooleanRetrievalModel را تکمیل کنید که شامل توابع preprocess_query و find_siⅿiⅼar_docs است که توضیحات هرکدام در قسمت کد موجود است. هدف نهایی این است که هرگاه کوئری به تابع find_siⅿiⅼar_docs از کلاس BooleanRetrievalModel داده شود، شناسه k تا از داک‌هایی که شامل کوئری داده شده هستند برگردانده شوند.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self, docs: pd.DataFrame):\n",
    "        self.docs = docs\n",
    "        self.index = self.create_index()\n",
    "        self.idf = {}\n",
    "\n",
    "    def create_index(self):\n",
    "        index = {}\n",
    "        for id, doc in self.docs.iterrows():\n",
    "            tokens = preprocessor.preprocess(doc['abstract'])\n",
    "            for token in tokens:\n",
    "                if token not in index:\n",
    "                    index[token] = {'frequensy': 0, 'postings': []}\n",
    "                index[token]['frequensy'] += 1\n",
    "                index[token]['postings'].append(doc['paperId'])\n",
    "        return index\n",
    "    \n",
    "    def calculate_idf(self):\n",
    "        for token in self.index.keys():\n",
    "            self.idf[token] = len(self.docs) / len(self.index[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanRetrievalModel:\n",
    "    def __init__(self, doc_term_matrix):\n",
    "        \"\"\"    \n",
    "        Set doc_term_matrix and initialize the model.\n",
    "        \"\"\"\n",
    "\n",
    "        self.index = doc_term_matrix\n",
    "    \n",
    "    def get_possible_docs(positional_index, query_terms, field):\n",
    "        possible_docs = set()\n",
    "        for term in query_terms:\n",
    "            if term not in positional_index:\n",
    "                continue\n",
    "            possible_docs.update(list(positional_index[term][field].keys()))\n",
    "        \n",
    "        return possible_docs\n",
    "\n",
    "    def preprocess_query(self, query):\n",
    "        \"\"\"\n",
    "        Do necessary preprocessing here before using the query to find k similar docs.\n",
    "        Use methods from Preprocess section.\n",
    "        \"\"\"\n",
    "        processed_query = ''\n",
    "        return processed_query\n",
    "    \n",
    "    def find_siⅿiⅼar_docs(self, query, k=20):\n",
    "        processed_query = self.preprocess_query(query)\n",
    "        \"\"\"\n",
    "        Find k similiar documents.\n",
    "        \"\"\"\n",
    "        similiar_docs = []\n",
    "        return similiar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "در این قسمت ۳ کوئری مختلف به دلخواه خود بزنید و لیست داکیومنت‌های مرتبط با آن‌ها را برگردانید. برای کوتاه‌تر شدن لیست جواب در هر کوئری می‌توانید از عملگر‌های منطقی مانند AND استفاده کنید.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 3 queries and find similar docs for each of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "\n",
    "# ذخیره و فشرده‌سازی نمایه\n",
    "در این بخش، در ابتدا دو الگوریتم فشرده‌سازی gamma code و variable byte را پیاده‌سازی کنید.  \n",
    "سپس نمایه را به سه شکل زیر ذخیره کنید:\n",
    "- نمایه‌ی اصلی بدون فشرده‌سازی\n",
    "- نمایه‌ای که با استفاده از gamma code فشرده شده است.\n",
    "- نمایه‌ای که با استفاده از variable byte فشرده شده است.\n",
    "\n",
    "در ادامه اندازه‌ی هر کدام از سه فایل بالا را با استفاده از یک تابع به دست آورده و چاپ کنید.  \n",
    "همچنین باید تابع‌هایی برای decompress کردن نمایه‌های فشرده‌شده پیاده‌سازی کنید.\n",
    "\n",
    "**نکته‌ی ۱:** تمامی نمایه‌ها را نیز در کوئرا ارسال کنید. اگر حجم‌شان بیش‌تر از محدودیت کوئرا است، آن‌ها را در یک مکان دیگر آپلود کرده و لینک آن را در این فایل قرار دهید.  \n",
    "**نکته‌ی ۲:** توابع زیر صرفاً پیشنهادی هستند و هر گونه تغییر تا زمانی که کاربردهای مورد نظر پیاده شود، آزاد است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_base_number(number, base=2):\n",
    "    if number == 0:\n",
    "        return [0]\n",
    "    digits = []\n",
    "    while number:\n",
    "        digits.append(int(number % base))\n",
    "        number //= base\n",
    "    return digits[::-1]\n",
    "\n",
    "def byte_to_binary(data):\n",
    "    return ''.join(format(x, '08b') for x in data)\n",
    "\n",
    "def convert_gap_to_real_numbers(gaps):\n",
    "    last = 0\n",
    "    result = []\n",
    "    for gap in gaps:\n",
    "        last += gap\n",
    "        result.append(last)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xa0'\n"
     ]
    }
   ],
   "source": [
    "def gamma_encode(number: int):\n",
    "    binary = change_base_number(number)\n",
    "    offset = binary[1:]\n",
    "    unary = len(offset)\n",
    "    return [1] * unary + [0] + offset\n",
    "\n",
    "def gamma_compression(docs, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        for word, posting in docs.items():\n",
    "            previous_docId = 0\n",
    "            sorted_posting = sorted(posting)\n",
    "            f.write(bytes(word, encoding='UTF-8'))\n",
    "            f.write(b'\\0')\n",
    "            line = []\n",
    "            for docId in sorted_posting:\n",
    "                line += gamma_encode(docId - previous_docId)\n",
    "                previous_docId = docId\n",
    "            line += [0 for i in range(len(line) % 8)]\n",
    "            arr = bitarray(line)\n",
    "            f.write(arr.tobytes())\n",
    "            f.write(b'\\0')\n",
    "\n",
    "        f.write(b'\\0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
      "{'hello': []}\n"
     ]
    }
   ],
   "source": [
    "def gamma_decoder_number(encoded: list[str]):\n",
    "    return int('1'+''.join(encoded), 2)\n",
    "\n",
    "def gamma_decoder(encoded):\n",
    "    result = []\n",
    "    start = 0\n",
    "    i = 0\n",
    "    while i < len(encoded):\n",
    "        if encoded[i] == '0':\n",
    "            result.append(gamma_decoder_number(encoded[i+1:i + (i-start) + 1]))\n",
    "            print(encoded[i+1:i + (i-start)+1])\n",
    "            start = i = i + (i-start) + 1\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def gamma_decompression(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    index = {}\n",
    "    i = 0\n",
    "    while True:\n",
    "        word = ''\n",
    "        while data[i] != 0:\n",
    "            word += chr(data[i])\n",
    "            i += 1\n",
    "        i += 1\n",
    "        index[word] = []\n",
    "        start = i\n",
    "        while True:\n",
    "            if data[i] == 0:\n",
    "                positions = gamma_decoder(bytes(data[start:i]))\n",
    "                index[word] = convert_gap_to_real_numbers(positions)\n",
    "                break\n",
    "            i += 1\n",
    "        i += 1\n",
    "        if data[i] == 0 or i > len(data):\n",
    "            break\n",
    "\n",
    "    return index\n",
    "\n",
    "gamma_compression({'hello': [1,2,128, 300]}, './test')\n",
    "print(gamma_decompression('./test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vb_encode_number(num, block_size):\n",
    "    result = change_base_number(num, 2 ** (block_size - 1))\n",
    "    result[-1] += 128\n",
    "    return bytes(result)\n",
    "\n",
    "def variable_byte_compression(docs, path, block_size=8):\n",
    "    with open(path, 'wb') as f:\n",
    "        for word, posting in docs.items():\n",
    "            previous_docId = 0\n",
    "            sorted_posting = sorted(posting)\n",
    "            f.write(bytes(word, encoding='UTF-8'))\n",
    "            f.write(b'\\0')\n",
    "            for docId in sorted_posting:\n",
    "                f.write(vb_encode_number(docId - previous_docId, block_size))\n",
    "                previous_docId = docId\n",
    "            f.write(b'\\0')\n",
    "\n",
    "        f.write(b'\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': [1, 2, 128, 300]}\n"
     ]
    }
   ],
   "source": [
    "def variable_byte_decoder_number(encoded, block_size, is_bit=True):\n",
    "    bits = encoded\n",
    "    if not is_bit:\n",
    "        bits = byte_to_binary(encoded)\n",
    "    result = ''.join([bits[i + 1:i + block_size] for i in range(0, len(bits), block_size)])\n",
    "    return int(result, 2)\n",
    "\n",
    "def variable_byte_decoder(encoded, block_size=8):\n",
    "    result = []\n",
    "    start = 0\n",
    "    bits = byte_to_binary(encoded)\n",
    "    byte_list = list(encoded)\n",
    "    for i in range(len(byte_list)):\n",
    "        if byte_list[i] >= 128:\n",
    "            result.append(variable_byte_decoder_number(bits[start:(i + 1) * block_size], block_size))\n",
    "            start = (i + 1) * block_size\n",
    "    return result\n",
    "\n",
    "\n",
    "def variable_byte_decompression(path, block_size=8):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    index = {}\n",
    "    i = 0\n",
    "    while True:\n",
    "        word = ''\n",
    "        while data[i] != 0:\n",
    "            word += chr(data[i])\n",
    "            i += 1\n",
    "        i += 1\n",
    "        index[word] = []\n",
    "        start = i\n",
    "        while True:\n",
    "            if data[i] == 0:\n",
    "                positions = variable_byte_decoder(bytes(data[start:i]), block_size)\n",
    "                index[word] = convert_gap_to_real_numbers(positions)\n",
    "                break\n",
    "            i += 1\n",
    "        i += 1\n",
    "        if data[i] == 0 or i > len(data):\n",
    "            break\n",
    "\n",
    "    return index\n",
    "\n",
    "variable_byte_compression({'hello': [1,2,128, 300]}, './test')\n",
    "print(variable_byte_decompression('./test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_COMRESS = \"no-compression\"\n",
    "GAMMA = \"gamma-code\"\n",
    "VB = \"varable-byte\"\n",
    "\n",
    "def save_index(index, path, method):\n",
    "    if method == NO_COMRESS:\n",
    "        pass\n",
    "    if method == GAMMA:\n",
    "        gamma_compression(index, path)\n",
    "    if method == VB:\n",
    "        variable_byte_compression(index, path)\n",
    "\n",
    "def load_index(path, method):\n",
    "    if method == NO_COMRESS:\n",
    "        pass\n",
    "    if method == GAMMA:\n",
    "        gamma_decompression(path)\n",
    "    if method == VB:\n",
    "        variable_byte_decompression(path)\n",
    "\n",
    "def get_size(file_path):\n",
    "    file_stats = os.stat(file_path)\n",
    "    print(f'File Size in MegaBytes is {file_stats.st_size / (1024 * 1024)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08ac30a6a1fd2e576b33e03f7d61c3a285d7ee0582c2dd23dde6343ef303ebe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
